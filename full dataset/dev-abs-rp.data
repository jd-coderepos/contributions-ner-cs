This	O
paper	O
describes	O
an	O
approach	O
to	O
the	O
treatment	O
of	O
nominal	O
compounds	O
in	O
a	O
machine	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
project	O
employing	O
a	O
modern	O
unification-based	O
system	O
.	O
General	O
problems	O
connected	O
with	O
the	O
analysis	O
of	O
compounds	O
are	O
briefly	O
reviewed	O
,	O
and	O
the	O
project	O
,	O
for	O
the	O
automatic	O
translation	S-RESEARCH_PROBLEM
of	O
Swiss	O
avalanche	O
bulletins	O
,	O
is	O
introduced	O
.	O
Avalanche	O
bulletins	O
deal	O
with	O
a	O
limited	O
semantic	O
domain	O
and	O
employ	O
a	O
sublanguage	O
in	O
which	O
nominal	O
compounds	O
occur	O
frequently	O
.	O
These	O
and	O
other	O
properties	O
of	O
the	O
texts	O
affect	O
the	O
treatment	O
of	O
compounds	O
,	O
permitting	O
certain	O
simplifications	O
,	O
while	O
leaving	O
a	O
number	O
of	O
possible	O
alternative	O
analyses	O
.	O
We	O
discuss	O
the	O
different	O
problems	O
involving	O
the	O
translation	S-RESEARCH_PROBLEM
of	O
compounds	O
between	O
German	O
and	O
French	O
,	O
and	O
show	O
how	O
the	O
computational	O
environment	O
in	O
use	O
permits	O
two	O
different	O
approaches	O
to	O
the	O
problem	O
:	O
an	O
interlingua-based	O
approach	O
and	O
a	O
transfer-based	O
approach	O
.	O
Finally	O
,	O
wc	O
evaluate	O
these	O
approaches	O
with	O
respect	O
to	O
linguistic	O
and	O
computational	O
considerations	O
applicable	O
in	O
a	O
MT-system	S-RESEARCH_PROBLEM
dealing	O
with	O
a	O
limited	O
semantic	O
domain	O
and	O
describe	O
the	O
solution	O
that	O
has	O
actually	O
been	O
implemented	O
.	O

Text	O
corpora	O
which	O
are	O
tagged	O
with	O
part-of-speech	S-RESEARCH_PROBLEM
information	O
are	O
useful	O
in	O
many	O
areas	O
of	O
linguistic	O
research	O
.	O
In	O
this	O
paper	O
,	O
a	O
new	O
part-of-speech	B-RESEARCH_PROBLEM
tagging	E-RESEARCH_PROBLEM
method	O
hased	O
on	O
neural	O
networks	O
-LRB-	O
Net-Tagger	O
-RRB-	O
is	O
presented	O
and	O
its	O
performance	O
is	O
compared	O
to	O
that	O
of	O
a	O
llMM-tagger	O
-LRB-	O
Cutting	O
et	O
al.	O
,	O
1992	O
-RRB-	O
and	O
a	O
trigrambased	O
tagger	O
-LRB-	O
Kempe	O
,	O
1993	O
-RRB-	O
.	O
It	O
is	O
shown	O
that	O
the	O
Net-Tagger	O
performs	O
as	O
well	O
as	O
the	O
trigram-based	O
tagger	O
and	O
better	O
than	O
the	O
iIMM-tagger	O
.	O

This	O
paper	O
describes	O
a	O
program	O
for	O
handling	O
``	O
scope	B-RESEARCH_PROBLEM
ambiguities	E-RESEARCH_PROBLEM
''	O
in	O
individual	O
English	O
sentences	O
.	O
The	O
program	O
operates	O
on	O
initial	O
logical	O
translations	O
,	O
generated	O
by	O
a	O
parser\/translator	O
,	O
in	O
which	O
``	O
unscoped	O
elements	O
''	O
such	O
as	O
quantifiers	O
,	O
coordinators	O
and	O
negation	O
are	O
left	O
in	O
place	O
to	O
be	O
extracted	O
and	O
positioned	O
by	O
the	O
scoping	S-RESEARCH_PROBLEM
program	O
.	O
The	O
program	O
produces	O
the	O
set	O
of	O
valid	O
scoped	O
readings	O
,	O
omitting	O
logically	O
redundant	O
readings	O
,	O
and	O
places	O
the	O
readings	O
in	O
an	O
approximate	O
order	O
of	O
preference	O
using	O
a	O
set	O
of	O
domain-independent	O
heuristics	O
.	O
The	O
heuristics	O
are	O
based	O
on	O
information	O
about	O
the	O
lexical	O
type	O
of	O
each	O
operator	O
and	O
on	O
``	O
structural	O
relations	O
''	O
between	O
pairs	O
of	O
operators	O
.	O
The	O
need	O
for	O
such	O
domain-independent	O
heuristics	O
is	O
emphasized	O
;	O
in	O
some	O
cases	O
they	O
can	O
be	O
decisive	O
and	O
in	O
general	O
they	O
will	O
serve	O
as	O
a	O
guide	O
to	O
the	O
use	O
of	O
further	O
heuristics	O
based	O
on	O
domain-specific	O
knowledge	O
and	O
on	O
the	O
context	O
of	O
discourse	O
.	O
The	O
emphasis	O
of	O
this	O
paper	O
is	O
on	O
discussing	O
several	O
of	O
the	O
more	O
problematic	O
aspects	O
of	O
the	O
scoping	S-RESEARCH_PROBLEM
protocol	O
which	O
wcre	O
encountered	O
during	O
the	O
design	O
of	O
the	O
scoping	S-RESEARCH_PROBLEM
program	O
.	O

This	O
paper	O
presents	O
a	O
new	O
active	O
learning	O
paradigm	O
which	O
considers	O
not	O
only	O
the	O
uncertainty	O
of	O
the	O
classifier	O
but	O
also	O
the	O
diversity	O
of	O
the	O
corpus	O
.	O
The	O
two	O
measures	O
for	O
uncertainty	O
and	O
diversity	O
were	O
combined	O
using	O
the	O
MMR	O
-LRB-	O
Maximal	O
Marginal	O
Relevance	O
-RRB-	O
method	O
to	O
give	O
the	O
sampling	O
scores	O
in	O
our	O
active	O
learning	O
strategy	O
.	O
We	O
incorporated	O
MMR-based	O
active	O
machinelearning	O
idea	O
into	O
the	O
biomedical	B-RESEARCH_PROBLEM
namedentity	I-RESEARCH_PROBLEM
recognition	E-RESEARCH_PROBLEM
system	O
.	O
Our	O
experimental	O
results	O
indicated	O
that	O
our	O
strategies	O
for	O
active-learning	O
based	O
sample	O
selection	O
could	O
significantly	O
reduce	O
the	O
human	O
effort	O
.	O

Partial	B-RESEARCH_PROBLEM
parsing	E-RESEARCH_PROBLEM
techniques	O
try	O
to	O
recover	O
syntactic	O
information	O
e?ciently	O
and	O
reliably	O
by	O
sacrificing	O
completeness	O
and	O
depth	O
of	O
analysis	O
.	O
One	O
of	O
the	O
di?culties	O
of	O
partial	B-RESEARCH_PROBLEM
parsing	E-RESEARCH_PROBLEM
is	O
finding	O
a	O
means	O
to	O
extract	O
the	O
grammar	O
involved	O
automatically	O
.	O
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
method	O
for	O
automatically	O
extracting	O
partial	B-RESEARCH_PROBLEM
parsing	I-RESEARCH_PROBLEM
rules	E-RESEARCH_PROBLEM
from	O
a	O
tree-annotated	O
corpus	O
using	O
decision	O
tree	O
induction	O
.	O
We	O
define	O
the	O
partial	B-RESEARCH_PROBLEM
parsing	I-RESEARCH_PROBLEM
rules	E-RESEARCH_PROBLEM
as	O
those	O
that	O
can	O
decide	O
the	O
structure	O
of	O
a	O
substring	O
in	O
an	O
input	O
sentence	O
deterministically	O
.	O
This	O
decision	O
can	O
be	O
considered	O
as	O
a	O
classification	O
;	O
as	O
such	O
,	O
for	O
a	O
substring	O
in	O
an	O
input	O
sentence	O
,	O
a	O
proper	O
structure	O
is	O
chosen	O
among	O
the	O
structures	O
occurred	O
in	O
the	O
corpus	O
.	O
For	O
the	O
classification	O
,	O
we	O
use	O
decision	O
tree	O
induction	O
,	O
and	O
induce	O
partial	B-RESEARCH_PROBLEM
parsing	I-RESEARCH_PROBLEM
rules	E-RESEARCH_PROBLEM
from	O
the	O
decision	O
tree	O
.	O
The	O
acquired	O
grammar	O
is	O
similar	O
to	O
a	O
phrase	O
structure	O
grammar	O
,	O
with	O
contextual	O
and	O
lexical	O
information	O
,	O
but	O
it	O
allows	O
building	O
structures	O
of	O
depth	O
one	O
or	O
more	O
.	O
Our	O
experiments	O
showed	O
that	O
the	O
proposed	O
partial	B-RESEARCH_PROBLEM
parser	E-RESEARCH_PROBLEM
using	O
the	O
automatically	O
extracted	O
rules	O
is	O
not	O
only	O
accurate	O
and	O
e?cient	O
,	O
but	O
also	O
achieves	O
reasonable	O
coverage	O
for	O
Korean	O
.	O

Grammatical	B-RESEARCH_PROBLEM
relationships	E-RESEARCH_PROBLEM
are	O
an	O
important	O
level	O
of	O
natural	O
language	O
processing	O
.	O
We	O
present	O
a	O
trainable	O
approach	O
to	O
find	O
these	O
relationships	O
through	O
transformation	O
sequences	O
and-error-driven	O
learning	O
.	O
Our	O
approach	O
finds	O
grammatical	B-RESEARCH_PROBLEM
relationships	E-RESEARCH_PROBLEM
between	O
core	O
syntax	O
groups	O
and	O
bypasses	O
much	O
of	O
the	O
parsing	O
phase	O
.	O
On	O
our	O
training	O
and	O
test	O
set	O
,	O
our	O
procedure	O
achieves	O
63.6	O
%	O
recall	O
and	O
77.3	O
%	O
precision	O
-LRB-	O
f-score	O
=	O
69.8	O
-RRB-	O
.	O

The	O
main	O
aim	O
of	O
this	O
paper	O
is	O
to	O
analyze	O
the	O
e	O
#	O
0Bects	O
of	O
applying	O
pronominal	O
anaphora	O
resolution	O
to	O
Question	B-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
#	O
28QA	O
#	O
29	O
systems	O
.	O
For	O
this	O
task	O
a	O
complete	O
QA	S-RESEARCH_PROBLEM
system	O
has	O
been	O
implemented	O
.	O
System	O
evaluation	O
measures	O
performance	O
improvements	O
obtained	O
when	O
information	O
that	O
is	O
referenced	O
anaphorically	O
in	O
documents	O
is	O
not	O
ignored	O
.	O

This	O
paper	O
presents	O
a	O
set	O
of	O
tools	O
and	O
methods	O
for	O
acquiring	O
,	O
manipulating	O
,	O
and	O
analyzing	O
machinereadable	B-RESEARCH_PROBLEM
dictionaries	E-RESEARCH_PROBLEM
.	O
We	O
give	O
several	O
detailed	O
examples	O
of	O
the	O
use	O
of	O
these	O
tools	O
and	O
methods	O
for	O
particular	O
analyses	O
.	O
A	O
novel	O
aspect	O
of	O
our	O
work	O
is	O
that	O
it	O
allows	O
the	O
combined	O
processing	O
of	O
multiple	O
machine-readable	B-RESEARCH_PROBLEM
dictionaries	E-RESEARCH_PROBLEM
.	O
Our	O
examples	O
describe	O
analyses	O
of	O
data	O
from	O
Webster	O
's	O
Seventh	O
Collegiate	O
Dictionary	O
,	O
the	O
Longman	O
Dictionary	O
of	O
Contemporary	O
English	O
,	O
the	O
Collins	O
bilingual	O
dictionaries	O
,	O
the	O
Collins	O
Thesaurus	O
,	O
and	O
the	O
Zingarelli	O
Italian	O
dictionary	O
.	O
We	O
describe	O
existing	O
facilities	O
and	O
results	O
they	O
have	O
produced	O
as	O
well	O
as	O
planned	O
enhancements	O
to	O
those	O
facilities	O
,	O
particularly	O
in	O
the	O
area	O
of	O
managing	O
associations	O
involving	O
the	O
senses	O
of	O
polysemous	O
words	O
.	O
We	O
show	O
how	O
these	O
enhancements	O
expand	O
the	O
ways	O
in	O
which	O
we	O
can	O
exploit	O
machine-readable	B-RESEARCH_PROBLEM
dictionaries	E-RESEARCH_PROBLEM
in	O
the	O
construction	O
of	O
large	O
lexicons	S-RESEARCH_PROBLEM
for	O
natural	O
language	O
processing	O
systems	O
.	O

Anaphora	B-RESEARCH_PROBLEM
resolution	E-RESEARCH_PROBLEM
has	O
proven	O
to	O
be	O
a	O
very	O
difficult	O
problem	O
;	O
it	O
requires	O
the	O
integrated	O
application	O
of	O
syntactic	O
,	O
semantic	O
,	O
and	O
pragmatic	O
knowledge	O
.	O
This	O
paper	O
examines	O
the	O
hypothesis	O
that	O
instead	O
of	O
attempting	O
to	O
construct	O
a	O
monolithic	O
method	O
for	O
resolving	B-RESEARCH_PROBLEM
anaphora	E-RESEARCH_PROBLEM
,	O
the	O
combination	O
of	O
multiple	O
strategies	O
,	O
each	O
exploiting	O
a	O
different	O
knowledge	O
source	O
,	O
proves	O
more	O
effective	O
,	O
theoretically	O
and	O
computationally	O
.	O
Cognitive	O
plausibility	O
is	O
established	O
in	O
that	O
human	O
judgements	O
of	O
the	O
optimal	O
anaphoric	O
referent	O
accord	O
with	O
those	O
of	O
the	O
strategy-based	O
method	O
,	O
and	O
human	O
inability	O
to	O
determine	O
a	O
unique	O
referent	O
corresponds	O
to	O
the	O
cases	O
where	O
different	O
strategies	O
offer	O
conflicting	O
candidates	O
for	O
the	O
anaphoric	O
referent	O
.	O

This	O
paper	O
describes	O
ETK	O
-LRB-	O
Ensemble	O
of	O
Transformation-based	O
Keys	O
-RRB-	O
a	O
new	O
algorithm	O
for	O
inducing	O
search	B-RESEARCH_PROBLEM
keys	I-RESEARCH_PROBLEM
for	I-RESEARCH_PROBLEM
name	I-RESEARCH_PROBLEM
filtering	E-RESEARCH_PROBLEM
.	O
ETK	O
has	O
the	O
low	O
computational	O
cost	O
and	O
ability	O
to	O
filter	S-RESEARCH_PROBLEM
by	O
phonetic	O
similarity	O
characteristic	O
of	O
phonetic	O
keys	O
such	O
as	O
Soundex	O
,	O
but	O
is	O
adaptable	O
to	O
alternative	O
similarity	O
models	O
.	O
The	O
accuracy	O
of	O
ETK	O
in	O
a	O
preliminary	O
empirical	O
evaluation	O
suggests	O
that	O
it	O
is	O
well-suited	O
for	O
phonetic	O
filtering	S-RESEARCH_PROBLEM
applications	O
such	O
as	O
recognizing	O
alternative	O
cross-lingual	B-RESEARCH_PROBLEM
transliterations	E-RESEARCH_PROBLEM
.	O

For	O
Information	B-RESEARCH_PROBLEM
Retrieval	E-RESEARCH_PROBLEM
,	O
users	O
are	O
more	O
concerned	O
about	O
the	O
precision	O
of	O
top	O
ranking	O
documents	O
in	O
most	O
practical	O
situations	O
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
method	O
to	O
improve	O
the	O
precision	O
of	O
top	O
N	O
ranking	B-RESEARCH_PROBLEM
documents	E-RESEARCH_PROBLEM
by	O
reordering	O
the	O
retrieved	O
documents	O
from	O
the	O
initial	O
retrieval	O
.	O
To	O
reorder	O
documents	O
,	O
we	O
first	O
automatically	O
extract	O
Global	O
Key	O
Terms	O
from	O
document	O
set	O
,	O
then	O
use	O
extracted	O
Global	O
Key	O
Terms	O
to	O
identify	O
Local	O
Key	O
Terms	O
in	O
a	O
single	O
document	O
or	O
query	O
topic	O
,	O
finally	O
we	O
make	O
use	O
of	O
Local	O
Key	O
Terms	O
in	O
query	O
and	O
documents	O
to	O
reorder	O
the	O
initial	O
ranking	O
documents	O
.	O
The	O
experiment	O
with	O
NTCIR3	O
CLIR	O
dataset	O
shows	O
that	O
an	O
average	O
10	O
%	O
-11	O
%	O
improvement	O
and	O
2	O
%	O
-5	O
%	O
improvement	O
in	O
precision	O
can	O
be	O
achieved	O
at	O
top	O
10	O
and	O
100	O
ranking	O
documents	O
level	O
respectively	O
.	O

Data	O
sparsity	O
is	O
one	O
of	O
the	O
main	O
factors	O
that	O
make	O
word	B-RESEARCH_PROBLEM
sense	I-RESEARCH_PROBLEM
disambiguation	E-RESEARCH_PROBLEM
-LRB-	O
WSD	S-RESEARCH_PROBLEM
-RRB-	O
difficult	O
.	O
To	O
overcome	O
this	O
problem	O
we	O
need	O
to	O
find	O
effective	O
ways	O
to	O
use	O
resources	O
other	O
than	O
sense	O
labeled	O
data	O
.	O
In	O
this	O
paper	O
I	O
describe	O
a	O
WSD	S-RESEARCH_PROBLEM
system	O
that	O
uses	O
a	O
statistical	O
language	O
model	O
based	O
on	O
a	O
large	O
unannotated	O
corpus	O
.	O
The	O
model	O
is	O
used	O
to	O
evaluate	O
the	O
likelihood	O
of	O
various	O
substitutes	O
for	O
a	O
word	O
in	O
a	O
given	O
context	O
.	O
These	O
likelihoods	O
are	O
then	O
used	O
to	O
determine	O
the	O
best	O
sense	O
for	O
the	O
word	O
in	O
novel	O
contexts	O
.	O
The	O
resulting	O
system	O
participated	O
in	O
three	O
tasks	O
in	O
the	O
SemEval	O
2007	O
workshop	O
.	O
The	O
WSD	O
of	O
prepositions	O
task	O
proved	O
to	O
be	O
challenging	O
for	O
the	O
system	O
,	O
possibly	O
illustrating	O
some	O
of	O
its	O
limitations	O
:	O
e.g.	O
not	O
all	O
words	O
have	O
good	O
substitutes	O
.	O
The	O
system	O
achieved	O
promising	O
results	O
for	O
the	O
English	O
lexical	O
sample	O
and	O
English	O
lexical	O
substitution	O
tasks	O
.	O

This	O
paper	O
describes	O
a	O
syntactic	O
representation	O
for	O
modeling	O
speech	B-RESEARCH_PROBLEM
repairs	E-RESEARCH_PROBLEM
.	O
This	O
representation	O
makes	O
use	O
of	O
a	O
right	O
corner	O
transform	O
of	O
syntax	O
trees	O
to	O
produce	O
a	O
tree	O
representation	O
in	O
which	O
speech	B-RESEARCH_PROBLEM
repairs	E-RESEARCH_PROBLEM
require	O
very	O
few	O
special	O
syntax	O
rules	O
,	O
making	O
better	O
use	O
of	O
training	O
data	O
.	O
PCFGs	O
trained	O
on	O
syntax	O
trees	O
using	O
this	O
model	O
achieve	O
high	O
accuracy	O
on	O
the	O
standard	O
Switchboard	O
parsing	S-RESEARCH_PROBLEM
task	O
.	O

We	O
discuss	O
Image	B-RESEARCH_PROBLEM
Sense	I-RESEARCH_PROBLEM
Discrimination	E-RESEARCH_PROBLEM
-LRB-	O
ISD	S-RESEARCH_PROBLEM
-RRB-	O
,	O
and	O
apply	O
a	O
method	O
based	O
on	O
spectral	O
clustering	O
,	O
using	O
multimodal	O
features	O
from	O
the	O
image	O
and	O
text	O
of	O
the	O
embedding	O
web	O
page	O
.	O
We	O
evaluate	O
our	O
method	O
on	O
a	O
new	O
data	O
set	O
of	O
annotated	O
web	O
images	O
,	O
retrieved	O
with	O
ambiguous	O
query	O
terms	O
.	O
Experiments	O
investigate	O
different	O
levels	O
of	O
sense	O
granularity	O
,	O
as	O
well	O
as	O
the	O
impact	O
of	O
text	O
and	O
image	O
features	O
,	O
and	O
global	O
versus	O
local	O
text	O
features	O
.	O

This	O
paper	O
describes	O
an	O
algorithm	O
for	O
computing	O
optimal	B-RESEARCH_PROBLEM
structural	I-RESEARCH_PROBLEM
descriptions	I-RESEARCH_PROBLEM
for	I-RESEARCH_PROBLEM
Optimality	I-RESEARCH_PROBLEM
Theory	I-RESEARCH_PROBLEM
grammars	E-RESEARCH_PROBLEM
with	O
context-free	O
position	O
structures	O
.	O
This	O
algorithm	O
extends	O
Tesar	O
's	O
dynamic	O
programming	O
approach	O
-LRB-	O
Tesar	O
,	O
1994	O
-RRB-	O
-LRB-	O
Tesar	O
,	O
1995	O
@	O
to	O
computing	O
optimal	B-RESEARCH_PROBLEM
structural	I-RESEARCH_PROBLEM
descriptions	E-RESEARCH_PROBLEM
from	O
regular	O
to	O
context-free	O
structures	O
.	O
The	O
generalization	O
to	O
contextfree	O
structures	O
creates	O
several	O
complications	O
,	O
all	O
of	O
which	O
are	O
overcome	O
without	O
compromising	O
the	O
core	O
dynamic	O
programming	O
approach	O
.	O
The	O
resulting	O
algorithm	O
has	O
a	O
time	O
complexity	O
cubic	O
in	O
the	O
length	O
of	O
the	O
input	O
,	O
and	O
is	O
applicable	O
to	O
grammars	O
with	O
universal	O
constraints	O
that	O
exhibit	O
context-free	O
locality	O
.	O

The	O
system	O
presented	O
in	O
this	O
paper	O
produces	O
bilingual	B-RESEARCH_PROBLEM
passages	I-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
text	E-RESEARCH_PROBLEM
from	O
an	O
original	O
-LRB-	O
source	O
-RRB-	O
text	O
and	O
one	O
-LRB-	O
or	O
more	O
-RRB-	O
of	O
its	O
translated	O
versions	O
.	O
The	O
source	O
text	O
passage	O
includes	O
words	O
or	O
word	O
compounds	O
which	O
a	O
translator	O
wants	O
to	O
retrieve	O
for	O
the	O
current	O
translating	O
of	O
another	O
text	O
.	O
The	O
target	O
text	O
passage	O
is	O
the	O
equivalent	O
version	O
of	O
the	O
source	O
text	O
passage	O
.	O
On	O
the	O
basis	O
of	O
a	O
comparison	O
of	O
the	O
contexts	O
of	O
these	O
words	O
in	O
the	O
concorded	O
passage	O
and	O
his	O
own	O
text	O
,	O
the	O
translator	O
has	O
to	O
decide	O
on	O
the	O
utility	O
of	O
the	O
translation	S-RESEARCH_PROBLEM
proposed	O
in	O
the	O
target	O
text	O
passage	O
.	O
The	O
program	O
might	O
become	O
a	O
component	O
of	O
translator	O
's	O
work	O
bench	O
.	O

Target	O
task	O
matched	O
parallel	O
corpora	O
are	O
required	O
for	O
statistical	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
model	O
training	O
.	O
However	O
,	O
training	O
corpora	O
sometimes	O
include	O
both	O
target	O
task	O
matched	O
and	O
unmatched	O
sentences	O
.	O
In	O
such	O
a	O
case	O
,	O
training	O
set	O
selection	O
can	O
reduce	O
the	O
size	O
of	O
the	O
translation	O
model	O
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
training	O
set	O
selection	O
method	O
for	O
translation	S-RESEARCH_PROBLEM
model	O
training	O
using	O
linear	O
translation	S-RESEARCH_PROBLEM
model	O
interpolation	O
and	O
a	O
language	O
model	O
technique	O
.	O
According	O
to	O
the	O
experimental	O
results	O
,	O
the	O
proposed	O
method	O
reduces	O
the	O
translation	O
model	O
size	O
by	O
50	O
%	O
and	O
improves	O
BLEU	O
score	O
by	O
1.76	O
%	O
in	O
comparison	O
with	O
a	O
baseline	O
training	O
corpus	O
usage	O
.	O

This	O
paper	O
explores	O
two	O
classes	O
of	O
model	B-RESEARCH_PROBLEM
adaptation	E-RESEARCH_PROBLEM
methods	O
for	O
Web	B-RESEARCH_PROBLEM
search	I-RESEARCH_PROBLEM
ranking	E-RESEARCH_PROBLEM
:	O
Model	O
Interpolation	O
and	O
error-driven	O
learning	O
approaches	O
based	O
on	O
a	O
boosting	O
algorithm	O
.	O
The	O
results	O
show	O
that	O
model	O
interpolation	O
,	O
though	O
simple	O
,	O
achieves	O
the	O
best	O
results	O
on	O
all	O
the	O
open	O
test	O
sets	O
where	O
the	O
test	O
data	O
is	O
very	O
different	O
from	O
the	O
training	O
data	O
.	O
The	O
tree-based	O
boosting	O
algorithm	O
achieves	O
the	O
best	O
performance	O
on	O
most	O
of	O
the	O
closed	O
test	O
sets	O
where	O
the	O
test	O
data	O
and	O
the	O
training	O
data	O
are	O
similar	O
,	O
but	O
its	O
performance	O
drops	O
significantly	O
on	O
the	O
open	O
test	O
sets	O
due	O
to	O
the	O
instability	O
of	O
trees	O
.	O
Several	O
methods	O
are	O
explored	O
to	O
improve	O
the	O
robustness	O
of	O
the	O
algorithm	O
,	O
with	O
limited	O
success	O
.	O

Machine	O
transliteration\/back-transliteration	O
plays	O
an	O
important	O
role	O
in	O
many	O
multilingual	O
speech	O
and	O
language	O
applications	O
.	O
In	O
this	O
paper	O
,	O
a	O
novel	O
framework	O
for	O
machine	O
transliteration\/backtransliteration	O
that	O
allows	O
us	O
to	O
carry	O
out	O
direct	O
orthographical	B-RESEARCH_PROBLEM
mapping	E-RESEARCH_PROBLEM
-LRB-	O
DOM	O
-RRB-	O
between	O
two	O
different	O
languages	O
is	O
presented	O
.	O
Under	O
this	O
framework	O
,	O
a	O
joint	O
source-channel	O
transliteration	O
model	O
,	O
also	O
called	O
n-gram	O
transliteration	O
model	O
-LRB-	O
ngram	O
TM	O
-RRB-	O
,	O
is	O
further	O
proposed	O
to	O
model	O
the	O
transliteration	S-RESEARCH_PROBLEM
process	O
.	O
We	O
evaluate	O
the	O
proposed	O
methods	O
through	O
several	O
transliteration\/backtransliteration	O
experiments	O
for	O
English\/Chinese	O
and	O
English\/Japanese	O
language	O
pairs	O
.	O
Our	O
study	O
reveals	O
that	O
the	O
proposed	O
method	O
not	O
only	O
reduces	O
an	O
extensive	O
system	O
development	O
effort	O
but	O
also	O
improves	O
the	O
transliteration	S-RESEARCH_PROBLEM
accuracy	O
significantly	O
.	O

When	O
a	O
lexical	O
item	O
is	O
selected	O
in	O
the	O
language	B-RESEARCH_PROBLEM
production	E-RESEARCH_PROBLEM
process	O
,	O
it	O
needs	O
to	O
be	O
explained	O
why	O
none	O
of	O
its	O
superordinates	O
gets	O
selected	O
instead	O
,	O
since	O
their	O
applicability	O
conditions	O
are	O
fulfilled	O
all	O
the	O
same	O
.	O
This	O
question	O
has	O
received	O
much	O
attention	O
in	O
cognitive	O
modelling	O
and	O
not	O
as	O
much	O
in	O
other	O
branches	O
of	O
NLG	O
.	O
This	O
paper	O
describes	O
the	O
various	O
approaches	O
taken	O
,	O
discusses	O
the	O
reasons	O
why	O
they	O
are	O
so	O
different	O
,	O
and	O
argues	O
that	O
production	S-RESEARCH_PROBLEM
models	O
using	O
symbolic	O
representations	O
should	O
make	O
a	O
distinction	O
between	O
conceptual	O
and	O
lexical	O
hierarchies	O
,	O
which	O
can	O
be	O
organized	O
along	O
fixed	O
levels	O
as	O
studied	O
in	O
-LRB-	O
some	O
branches	O
of	O
-RRB-	O
lexical	O
semantics	O
.	O

The	O
paper	O
illustrates	O
a	O
linguistic	B-RESEARCH_PROBLEM
knowledge	I-RESEARCH_PROBLEM
acquisition	E-RESEARCH_PROBLEM
model	O
making	O
use	O
of	O
data	O
types	O
,	O
infinite	O
nlenlory	O
,	O
and	O
an	O
inferential	O
mechanism	O
tbr	O
inducing	O
new	O
intbrmation	O
Dora	O
known	O
data	O
.	O
The	O
mode	O
-RRB-	O
is	O
colnpared	O
with	O
standard	O
stochastic	O
lnethods	O
applied	O
to	O
data	O
tokens	O
,	O
and	O
tested	O
on	O
a	O
task	O
of	O
lexico	B-RESEARCH_PROBLEM
semantic	I-RESEARCH_PROBLEM
classification	E-RESEARCH_PROBLEM
.	O

This	O
paper	O
describes	O
a	O
method	O
of	O
adapting	O
a	O
domain-independent	O
HPSG	O
parser	S-RESEARCH_PROBLEM
to	O
a	O
biomedical	S-RESEARCH_PROBLEM
domain	O
.	O
Without	O
modifying	O
the	O
grammar	O
and	O
the	O
probabilistic	O
model	O
of	O
the	O
original	O
HPSG	O
parser	S-RESEARCH_PROBLEM
,	O
we	O
develop	O
a	O
log-linear	O
model	O
with	O
additional	O
features	O
on	O
a	O
treebank	O
of	O
the	O
biomedical	S-RESEARCH_PROBLEM
domain	O
.	O
Since	O
the	O
treebank	O
of	O
the	O
target	O
domain	O
is	O
limited	O
,	O
we	O
need	O
to	O
exploit	O
an	O
original	O
disambiguation	O
model	O
that	O
was	O
trained	O
on	O
a	O
larger	O
treebank	O
.	O
Our	O
model	O
incorporates	O
the	O
original	O
model	O
as	O
a	O
reference	O
probabilistic	O
distribution	O
.	O
The	O
experimental	O
results	O
for	O
our	O
model	O
trained	O
with	O
a	O
small	O
amount	O
of	O
a	O
treebank	O
demonstrated	O
an	O
improvement	O
in	O
parsing	S-RESEARCH_PROBLEM
accuracy	O
.	O

We	O
present	O
a	O
novel	O
neural	O
network	O
for	O
processing	O
sequences	O
.	O
The	O
ByteNet	O
is	O
a	O
one-dimensional	O
convolutional	O
neural	O
network	O
that	O
is	O
composed	O
of	O
two	O
parts	O
,	O
one	O
to	O
encode	O
the	O
source	O
sequence	O
and	O
the	O
other	O
to	O
decode	O
the	O
target	O
sequence	O
.	O
The	O
two	O
network	O
parts	O
are	O
connected	O
by	O
stacking	O
the	O
decoder	O
on	O
top	O
of	O
the	O
encoder	O
and	O
preserving	O
the	O
temporal	O
resolution	O
of	O
the	O
sequences	O
.	O
To	O
address	O
the	O
differing	O
lengths	O
of	O
the	O
source	O
and	O
the	O
target	O
,	O
we	O
introduce	O
an	O
efficient	O
mechanism	O
by	O
which	O
the	O
decoder	O
is	O
dynamically	O
unfolded	O
over	O
the	O
representation	O
of	O
the	O
encoder	O
.	O
The	O
ByteNet	O
uses	O
dilation	O
in	O
the	O
convolutional	O
layers	O
to	O
increase	O
its	O
receptive	O
field	O
.	O
The	O
resulting	O
network	O
has	O
two	O
core	O
properties	O
:	O
it	O
runs	O
in	O
time	O
that	O
is	O
linear	O
in	O
the	O
length	O
of	O
the	O
sequences	O
and	O
it	O
sidesteps	O
the	O
need	O
for	O
excessive	O
memorization	O
.	O
The	O
ByteNet	O
decoder	O
attains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
character	B-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
level	I-RESEARCH_PROBLEM
language	I-RESEARCH_PROBLEM
modelling	E-RESEARCH_PROBLEM
and	O
outperforms	O
the	O
previous	O
best	O
results	O
obtained	O
with	O
recurrent	O
networks	O
.	O

The	O
dominant	O
sequence	O
transduction	O
models	O
are	O
based	O
on	O
complex	O
recurrent	O
or	O
convolutional	O
neural	O
networks	O
that	O
include	O
an	O
encoder	O
and	O
a	O
decoder	O
.	O
The	O
best	O
performing	O
models	O
also	O
connect	O
the	O
encoder	O
and	O
decoder	O
through	O
an	O
attention	O
mechanism	O
.	O
We	O
propose	O
a	O
new	O
simple	O
network	O
architecture	O
,	O
the	O
Transformer	O
,	O
based	O
solely	O
on	O
attention	B-RESEARCH_PROBLEM
mechanisms	E-RESEARCH_PROBLEM
,	O
dispensing	O
with	O
recurrence	O
and	O
convolutions	O
entirely	O
.	O
Experiments	O
on	O
two	O
machine	O
translation	O
tasks	O
show	O
these	O
models	O
to	O
be	O
superior	O
in	O
quality	O
while	O
being	O
more	O
parallelizable	O
and	O
requiring	O
significantly	O
less	O
time	O
to	O
train	O
.	O
Our	O
model	O
achieves	O
28.4	O
BLEU	O
on	O
the	O
WMT	O
2014	O
Englishto	O
-	O
German	O
translation	O
task	O
,	O
improving	O
over	O
the	O
existing	O
best	O
results	O
,	O
including	O
ensembles	O
,	O
by	O
over	O
2	O
BLEU	O
.	O
On	O
the	O
WMT	O
2014	O
English	O
-	O
to	O
-	O
French	O
translation	O
task	O
,	O
our	O
model	O
establishes	O
a	O
new	O
single	O
-	O
model	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
BLEU	O
score	O
of	O
41.8	O
after	O
training	O
for	O
3.5	O
days	O
on	O
eight	O
GPUs	O
,	O
a	O
small	O
fraction	O
of	O
the	O
training	O
costs	O
of	O
the	O
best	O
models	O
from	O
the	O
literature	O
.	O
We	O
show	O
that	O
the	O
Transformer	O
generalizes	O
well	O
to	O
other	O
tasks	O
by	O
applying	O
it	O
successfully	O
to	O
English	O
constituency	O
parsing	O
both	O
with	O
large	O
and	O
limited	O
training	O
data	O
.	O

Neural	B-RESEARCH_PROBLEM
machine	I-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
(	O
NT12	O
)	O
aims	O
at	O
solving	O
machine	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
(	O
MT	S-RESEARCH_PROBLEM
)	O
problems	O
using	O
neural	O
networks	O
and	O
has	O
exhibited	O
promising	O
results	O
in	O
recent	O
years	O
.	O
However	O
,	O
most	O
of	O
the	O
existing	O
NMT	S-RESEARCH_PROBLEM
models	O
are	O
shallow	O
and	O
there	O
is	O
still	O
a	O
performance	O
gap	O
between	O
a	O
single	O
NMT	S-RESEARCH_PROBLEM
model	O
and	O
the	O
best	O
conventional	O
MT	S-RESEARCH_PROBLEM
system	O
.	O
In	O
this	O
work	O
,	O
we	O
introduce	O
a	O
new	O
type	O
of	O
linear	O
connections	O
,	O
named	O
fastforward	O
connections	O
,	O
based	O
on	O
deep	O
Long	O
Short	O
-	O
Term	O
Memory	O
(	O
LSTM	O
)	O
networks	O
,	O
and	O
an	O
interleaved	O
bi-directional	O
architecture	O
for	O
stacking	O
the	O
LSTM	O
layers	O
.	O
Fast	O
-	O
forward	O
connections	O
play	O
an	O
essential	O
role	O
in	O
propagating	O
the	O
gradients	O
and	O
building	O
a	O
deep	O
topology	O
of	O
depth	O
16	O
.	O
On	O
the	O
WMT	O
'	O
14	O
Englishto	O
-	O
French	O
task	O
,	O
we	O
achieve	O
BLEU	O
=	O
37.7	O
with	O
a	O
single	O
attention	O
model	O
,	O
which	O
outperforms	O
the	O
corresponding	O
single	O
shallow	O
model	O
by	O
6.2	O
BLEU	O
points	O
.	O
This	O
is	O
the	O
first	O
time	O
that	O
a	O
single	O
NMT	S-RESEARCH_PROBLEM
model	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
and	O
outperforms	O
the	O
best	O
conventional	O
model	O
by	O
0.7	O
BLEU	O
points	O
.	O
We	O
can	O
still	O
achieve	O
BLEU	O
=	O
36.3	O
even	O
without	O
using	O
an	O
attention	O
mechanism	O
.	O

Unsupervised	B-RESEARCH_PROBLEM
neural	I-RESEARCH_PROBLEM
machine	I-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
(	O
NMT	S-RESEARCH_PROBLEM
)	O
is	O
a	O
recently	O
proposed	O
approach	O
for	O
machine	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
which	O
aims	O
to	O
train	O
the	O
model	O
without	O
using	O
any	O
labeled	O
data	O
.	O
The	O
models	O
proposed	O
for	O
unsupervised	B-RESEARCH_PROBLEM
NMT	E-RESEARCH_PROBLEM
often	O
use	O
only	O
one	O
shared	O
encoder	O
to	O
map	O
the	O
pairs	O
of	O
sentences	O
from	O
different	O
languages	O
to	O
a	O
shared	O
-	O
latent	O
space	O
,	O
which	O
is	O
weak	O
in	O
keeping	O
the	O
unique	O
and	O
internal	O
characteristics	O
of	O
each	O
language	O
,	O
such	O
as	O
the	O
style	O
,	O
terminology	O
,	O
and	O
sentence	O
structure	O
.	O
To	O
address	O
this	O
issue	O
,	O
we	O
introduce	O
an	O
extension	O
by	O
utilizing	O
two	O
independent	O
encoders	O
but	O
sharing	O
some	O
partial	O
weights	O
which	O
are	O
responsible	O
for	O
extracting	O
high	O
-	O
level	O
representations	O
of	O
the	O
input	O
sentences	O
.	O
Besides	O
,	O
two	O
different	O
generative	O
adversarial	O
networks	O
(	O
GANs	O
)	O
,	O
namely	O
the	O
local	O
GAN	O
and	O
global	O
GAN	O
,	O
are	O
proposed	O
to	O
enhance	O
the	O
cross	O
-	O
language	O
translation	O
.	O
With	O
this	O
new	O
approach	O
,	O
we	O
achieve	O
significant	O
improvements	O
on	O
English	O
-	O
German	O
,	O
English	O
-	O
French	O
and	O
Chinese	O
-	O
to	O
-	O
English	O
translation	O
tasks	O
.	O

The	O
paper	O
describes	O
the	O
development	O
process	O
of	O
the	O
Tilde	O
's	O
NMT	S-RESEARCH_PROBLEM
systems	O
that	O
were	O
submitted	O
for	O
the	O
WMT	O
2018	O
shared	O
task	O
on	O
news	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
.	O
We	O
describe	O
the	O
data	O
filtering	O
and	O
pre-processing	O
workflows	O
,	O
the	O
NMT	S-RESEARCH_PROBLEM
system	O
training	O
architectures	O
,	O
and	O
automatic	O
evaluation	O
results	O
.	O
For	O
the	O
WMT	O
2018	O
shared	O
task	O
,	O
we	O
submitted	O
seven	O
systems	O
(	O
both	O
constrained	O
and	O
unconstrained	O
)	O
for	O
English	O
-	O
Estonian	O
and	O
Estonian	O
-	O
English	O
translation	O
directions	O
.	O
The	O
submitted	O
systems	O
were	O
trained	O
using	O
Transformer	O
models	O
.	O

Continuous	O
word	O
representation	O
(	O
aka	O
word	O
embedding	O
)	O
is	O
a	O
basic	O
building	O
block	O
in	O
many	O
neural	O
network	O
-	O
based	O
models	O
used	O
in	O
natural	O
language	O
processing	O
tasks	O
.	O
Although	O
it	O
is	O
widely	O
accepted	O
that	O
words	O
with	O
similar	O
semantics	O
should	O
be	O
close	O
to	O
each	O
other	O
in	O
the	O
embedding	O
space	O
,	O
we	O
find	O
that	O
word	B-RESEARCH_PROBLEM
embeddings	I-RESEARCH_PROBLEM
learned	I-RESEARCH_PROBLEM
in	I-RESEARCH_PROBLEM
several	I-RESEARCH_PROBLEM
tasks	I-RESEARCH_PROBLEM
are	I-RESEARCH_PROBLEM
biased	I-RESEARCH_PROBLEM
towards	I-RESEARCH_PROBLEM
word	I-RESEARCH_PROBLEM
frequency	E-RESEARCH_PROBLEM
:	O
the	O
embeddings	O
of	O
highfrequency	O
and	O
low	O
-	O
frequency	O
words	O
lie	O
in	O
different	O
subregions	O
of	O
the	O
embedding	O
space	O
,	O
and	O
the	O
embedding	O
of	O
a	O
rare	O
word	O
and	O
a	O
popular	O
word	O
can	O
be	O
far	O
from	O
each	O
other	O
even	O
if	O
they	O
are	O
semantically	O
similar	O
.	O
This	O
makes	O
learned	O
word	O
embeddings	O
ineffective	O
,	O
especially	O
for	O
rare	O
words	O
,	O
and	O
consequently	O
limits	O
the	O
performance	O
of	O
these	O
neural	O
network	O
models	O
.	O
In	O
this	O
paper	O
,	O
we	O
develop	O
a	O
neat	O
,	O
simple	O
yet	O
effective	O
way	O
to	O
learn	O
FRequency	O
-	O
AGnostic	O
word	O
Embedding	O
(	O
FRAGE	O
)	O
using	O
adversarial	O
training	O
.	O
We	O
conducted	O
comprehensive	O
studies	O
on	O
ten	O
datasets	O
across	O
four	O
natural	O
language	O
processing	O
tasks	O
,	O
including	O
word	O
similarity	O
,	O
language	O
modeling	O
,	O
machine	O
translation	O
and	O
text	O
classification	O
.	O
Results	O
show	O
that	O
with	O
FRAGE	O
,	O
we	O
achieve	O
higher	O
performance	O
than	O
the	O
baselines	O
in	O
all	O
tasks	O
.	O

The	O
capacity	O
of	O
a	O
neural	O
network	O
to	O
absorb	O
information	O
is	O
limited	O
by	O
its	O
number	O
of	O
parameters	O
.	O
Conditional	B-RESEARCH_PROBLEM
computation	E-RESEARCH_PROBLEM
,	O
where	O
parts	O
of	O
the	O
network	O
are	O
active	O
on	O
a	O
per-example	O
basis	O
,	O
has	O
been	O
proposed	O
in	O
theory	O
as	O
away	O
of	O
dramatically	O
increasing	B-RESEARCH_PROBLEM
model	I-RESEARCH_PROBLEM
capacity	I-RESEARCH_PROBLEM
without	I-RESEARCH_PROBLEM
a	I-RESEARCH_PROBLEM
proportional	I-RESEARCH_PROBLEM
increase	I-RESEARCH_PROBLEM
in	I-RESEARCH_PROBLEM
computation	E-RESEARCH_PROBLEM
.	O
In	O
practice	O
,	O
however	O
,	O
there	O
are	O
significant	O
algorithmic	O
and	O
performance	O
challenges	O
.	O
In	O
this	O
work	O
,	O
we	O
address	O
these	O
challenges	O
and	O
finally	O
realize	O
the	O
promise	O
of	O
conditional	O
computation	O
,	O
achieving	O
greater	O
than	O
1000x	O
improvements	O
in	O
model	O
capacity	O
with	O
only	O
minor	O
losses	O
in	O
computational	O
efficiency	O
on	O
modern	O
GPU	O
clusters	O
.	O
We	O
introduce	O
a	O
Sparsely	O
-	O
Gated	O
Mixture	O
-	O
of	O
-	O
Experts	O
layer	O
(	O
MoE	O
)	O
,	O
consisting	O
of	O
up	O
to	O
thousands	O
of	O
feed	O
-	O
forward	O
sub	O
-	O
networks	O
.	O
A	O
trainable	O
gating	O
network	O
determines	O
a	O
sparse	O
combination	O
of	O
these	O
experts	O
to	O
use	O
for	O
each	O
example	O
.	O
We	O
apply	O
the	O
MoE	O
to	O
the	O
tasks	O
of	O
language	O
modeling	O
and	O
machine	O
translation	O
,	O
where	O
model	O
capacity	O
is	O
critical	O
for	O
absorbing	O
the	O
vast	O
quantities	O
of	O
knowledge	O
available	O
in	O
the	O
training	O
corpora	O
.	O

Neural	O
machine	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
is	O
a	O
recently	O
proposed	O
approach	O
to	O
machine	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
.	O
Unlike	O
the	O
traditional	O
statistical	O
machine	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
,	O
the	O
neural	O
machine	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
aims	O
at	O
building	O
a	O
single	O
neural	O
network	O
that	O
can	O
be	O
jointly	O
tuned	O
to	O
maximize	O
the	O
translation	O
performance	O
.	O
The	O
models	O
proposed	O
recently	O
for	O
neural	O
machine	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
often	O
belong	O
to	O
a	O
family	O
of	O
encoder	O
-	O
decoders	O
and	O
encode	O
a	O
source	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
from	O
which	O
a	O
decoder	O
generates	O
a	O
translation	O
.	O
In	O
this	O
paper	O
,	O
we	O
conjecture	O
that	O
the	O
use	B-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
a	I-RESEARCH_PROBLEM
fixed	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
length	I-RESEARCH_PROBLEM
vector	I-RESEARCH_PROBLEM
is	I-RESEARCH_PROBLEM
a	I-RESEARCH_PROBLEM
bottleneck	I-RESEARCH_PROBLEM
in	I-RESEARCH_PROBLEM
improving	I-RESEARCH_PROBLEM
the	I-RESEARCH_PROBLEM
performance	I-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
this	I-RESEARCH_PROBLEM
basic	I-RESEARCH_PROBLEM
encoder	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
decoder	I-RESEARCH_PROBLEM
architecture	E-RESEARCH_PROBLEM
,	O
and	O
propose	O
to	O
extend	O
this	O
by	O
allowing	O
a	O
model	O
to	O
automatically	O
(	O
soft	O
-	O
)	O
search	O
for	O
parts	O
of	O
a	O
source	O
sentence	O
that	O
are	O
relevant	O
to	O
predicting	O
a	O
target	O
word	O
,	O
without	O
having	O
to	O
form	O
these	O
parts	O
as	O
a	O
hard	O
segment	O
explicitly	O
.	O
With	O
this	O
new	O
approach	O
,	O
we	O
achieve	O
a	O
translation	O
performance	O
comparable	O
to	O
the	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
phrase	O
-	O
based	O
system	O
on	O
the	O
task	O
of	O
English	O
-	O
to	O
-	O
French	O
translation	O
.	O
Furthermore	O
,	O
qualitative	O
analysis	O
reveals	O
that	O
the	O
(	O
soft	O
-	O
)	O
alignments	O
found	O
by	O
the	O
model	O
agree	O
well	O
with	O
our	O
intuition	O
.	O
INTRODUCTION	O

Natural	O
language	O
processing	O
(	O
NLP	O
)	O
models	O
often	O
require	O
a	O
massive	O
number	O
of	O
parameters	O
for	O
word	O
embeddings	O
,	O
resulting	O
in	O
a	O
large	O
storage	O
or	O
memory	O
footprint	O
.	O
Deploying	O
neural	O
NLP	O
models	O
to	O
mobile	O
devices	O
requires	O
compressing	B-RESEARCH_PROBLEM
the	I-RESEARCH_PROBLEM
word	I-RESEARCH_PROBLEM
embeddings	I-RESEARCH_PROBLEM
without	I-RESEARCH_PROBLEM
any	I-RESEARCH_PROBLEM
significant	I-RESEARCH_PROBLEM
sacrifices	I-RESEARCH_PROBLEM
in	I-RESEARCH_PROBLEM
performance	E-RESEARCH_PROBLEM
.	O
For	O
this	O
purpose	O
,	O
we	O
propose	O
to	O
construct	O
the	O
embeddings	O
with	O
few	O
basis	O
vectors	O
.	O
For	O
each	O
word	O
,	O
the	O
composition	O
of	O
basis	O
vectors	O
is	O
determined	O
by	O
a	O
hash	O
code	O
.	O
To	O
maximize	O
the	O
compression	O
rate	O
,	O
we	O
adopt	O
the	O
multi-codebook	O
quantization	O
approach	O
instead	O
of	O
binary	O
coding	O
scheme	O
.	O
Each	O
code	O
is	O
composed	O
of	O
multiple	O
discrete	O
numbers	O
,	O
such	O
as	O
(	O
3	O
,	O
2	O
,	O
1	O
,	O
8	O
)	O
,	O
where	O
the	O
value	O
of	O
each	O
component	O
is	O
limited	O
to	O
a	O
fixed	O
range	O
.	O
We	O
propose	O
to	O
directly	O
learn	O
the	O
discrete	O
codes	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
neural	O
network	O
by	O
applying	O
the	O
Gumbel	O
-	O
softmax	O
trick	O
.	O

Subset	B-RESEARCH_PROBLEM
selection	I-RESEARCH_PROBLEM
from	I-RESEARCH_PROBLEM
massive	I-RESEARCH_PROBLEM
data	E-RESEARCH_PROBLEM
with	O
noised	O
information	O
is	O
increasingly	O
popular	O
for	O
various	O
applications	O
.	O
This	O
problem	O
is	O
still	O
highly	O
challenging	O
as	O
current	O
methods	O
are	O
generally	O
slow	O
in	O
speed	O
and	O
sensitive	O
to	O
outliers	O
.	O
To	O
address	O
the	O
above	O
two	O
issues	O
,	O
we	O
propose	O
an	O
accelerated	O
robust	O
subset	B-RESEARCH_PROBLEM
selection	E-RESEARCH_PROBLEM
(	O
ARSS	O
)	O
method	O
.	O
Specifically	O
in	O
the	O
subset	B-RESEARCH_PROBLEM
selection	E-RESEARCH_PROBLEM
area	O
,	O
this	O
is	O
the	O
first	O
attempt	O
to	O
employ	O
the	O
p	O
(	O
0	O
<	O
p	O
?	O
1	O
)	O
-	O
norm	O
based	O
measure	O
for	O
the	O
representation	O
loss	O
,	O
preventing	O
large	O
errors	O
from	O
dominating	O
our	O
objective	O
.	O
As	O
a	O
result	O
,	O
the	O
robustness	O
against	O
outlier	O
elements	O
is	O
greatly	O
enhanced	O
.	O
Actually	O
,	O
data	O
size	O
is	O
generally	O
much	O
larger	O
than	O
feature	O
length	O
,	O
i.e.	O
N	O
L.	O
Based	O
on	O
this	O
observation	O
,	O
we	O
propose	O
a	O
speedup	O
solver	O
(	O
via	O
ALM	O
and	O
equivalent	O
derivations	O
)	O
to	O
highly	O
reduce	O
the	O
computational	O
cost	O
,	O
theoretically	O
from	O
ON	O
4	O
to	O
ON	O
2	O
L	O
.	O
Extensive	O
experiments	O
on	O
ten	O
benchmark	O
datasets	O
verify	O
that	O
our	O
method	O
not	O
only	O
outperforms	O
state	O
of	O
the	O
art	O
methods	O
,	O
but	O
also	O
runs	O
10,000	O
+	O
times	O
faster	O
than	O
the	O
most	O
related	O
method	O
.	O

State	O
-	O
of	O
-	O
the	O
-	O
art	O
named	O
entity	O
recognition	O
systems	O
rely	O
heavily	O
on	O
hand	O
-	O
crafted	O
features	O
and	O
domain	O
-	O
specific	O
knowledge	O
in	O
order	O
to	O
learn	O
effectively	O
from	O
the	O
small	O
,	O
supervised	O
training	O
corpora	O
thatare	O
available	O
.	O
In	O
this	O
paper	O
,	O
we	O
introduce	O
two	O
new	O
neural	O
architectures	O
-	O
one	O
based	O
on	O
bidirectional	O
LSTMs	O
and	O
conditional	O
random	O
fields	O
,	O
and	O
the	O
other	O
that	O
constructs	O
and	O
labels	O
segments	O
using	O
a	O
transition	O
-	O
based	O
approach	O
inspired	O
by	O
shift	O
-	O
reduce	O
parsers	O
.	O
Our	O
models	O
rely	O
on	O
two	O
sources	O
of	O
information	O
about	O
words	O
:	O
character	O
-	O
based	O
word	O
representations	O
learned	O
from	O
the	O
supervised	O
corpus	O
and	O
unsupervised	O
word	O
representations	O
learned	O
from	O
unannotated	O
corpora	O
.	O
Our	O
models	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
NER	S-RESEARCH_PROBLEM
in	O
four	O
languages	O
without	O
resorting	O
to	O
any	O
language	O
-	O
specific	O
knowledge	O
or	O
resources	O
such	O
as	O
gazetteers	O
.	O
1	O

Today	O
when	O
many	O
practitioners	O
run	O
basic	O
NLP	O
on	O
the	O
entire	O
web	O
and	O
large	O
-	O
volume	O
traffic	O
,	O
faster	O
methods	O
are	O
paramount	O
to	O
saving	O
time	O
and	O
energy	O
costs	O
.	O
Recent	O
advances	O
in	O
GPU	O
hardware	O
have	O
led	O
to	O
the	O
emergence	O
of	O
bi-directional	O
LSTMs	O
as	O
a	O
standard	O
method	O
for	O
obtaining	O
pertoken	O
vector	O
representations	O
serving	O
as	O
input	O
to	O
labeling	O
tasks	O
such	O
as	O
NER	O
(	O
often	O
followed	O
by	O
prediction	O
in	O
a	O
linear	O
-	O
chain	O
CRF	O
)	O
.	O
Though	O
expressive	O
and	O
accurate	O
,	O
these	O
models	O
fail	O
to	O
fully	O
exploit	O
GPU	O
parallelism	O
,	O
limiting	O
their	O
computational	O
efficiency	O
.	O
This	O
paper	O
proposes	O
a	O
faster	B-RESEARCH_PROBLEM
alternative	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
Bi	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
LSTMs	I-RESEARCH_PROBLEM
for	I-RESEARCH_PROBLEM
NER	E-RESEARCH_PROBLEM
:	O
Iterated	O
Dilated	O
Convolutional	O
Neural	O
Networks	O
(	O
ID	O
-	O
CNNs	O
)	O
,	O
which	O
have	O
better	O
capacity	O
than	O
traditional	O
CNNs	O
for	O
large	O
context	O
and	O
structured	O
prediction	O
.	O
Unlike	O
LSTMs	O
whose	O
sequential	O
processing	O
on	O
sentences	O
of	O
length	O
N	O
requires	O
O(N	O
)	O
time	O
even	O
in	O
the	O
face	O
of	O
parallelism	O
,	O
ID	O
-	O
CNNs	O
permit	O
fixed	O
-	O
depth	O
convolutions	O
to	O
run	O
in	O
parallel	O
across	O
entire	O
documents	O
.	O
We	O
describe	O
a	O
distinct	O
combination	O
of	O
network	O
structure	O
,	O
parameter	O
sharing	O
and	O
training	O
procedures	O
that	O
enable	O
dramatic	O
14	O
-	O
20x	O
testtime	O
speedups	O
while	O
retaining	O
accuracy	O
comparable	O
to	O
the	O
Bi	O
-	O
LSTM	O
-	O
CRF	O
.	O
Moreover	O
,	O
ID	O
-	O
CNNs	O
trained	O
to	O
aggregate	O
context	O
from	O
the	O
entire	O
document	O
are	O
even	O
more	O
accurate	O
while	O
maintaining	O
8	O
x	O
faster	O
test	O
time	O
speeds	O
.	O

Pre-trained	O
word	O
embeddings	O
learned	O
from	O
unlabeled	O
text	O
have	O
become	O
a	O
standard	O
component	O
of	O
neural	O
network	O
architectures	O
for	O
NLP	O
tasks	O
.	O
However	O
,	O
in	O
most	O
cases	O
,	O
the	O
recurrent	O
network	O
that	O
operates	O
on	O
word	O
-	O
level	O
representations	O
to	O
produce	O
context	O
sensitive	O
representations	O
is	O
trained	O
on	O
relatively	O
little	O
labeled	O
data	O
.	O
In	O
this	O
paper	O
,	O
we	O
demonstrate	O
a	O
general	B-RESEARCH_PROBLEM
semi-supervised	I-RESEARCH_PROBLEM
approach	I-RESEARCH_PROBLEM
for	I-RESEARCH_PROBLEM
adding	I-RESEARCH_PROBLEM
pretrained	I-RESEARCH_PROBLEM
context	I-RESEARCH_PROBLEM
embeddings	I-RESEARCH_PROBLEM
from	I-RESEARCH_PROBLEM
bidirectional	I-RESEARCH_PROBLEM
language	I-RESEARCH_PROBLEM
models	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
NLP	I-RESEARCH_PROBLEM
systems	E-RESEARCH_PROBLEM
and	O
apply	O
it	O
to	O
sequence	O
labeling	O
tasks	O
.	O
We	O
evaluate	O
our	O
model	O
on	O
two	O
standard	O
datasets	O
for	O
named	O
entity	O
recognition	O
(	O
NER	O
)	O
and	O
chunking	O
,	O
and	O
in	O
both	O
cases	O
achieve	O
state	O
of	O
the	O
art	O
results	O
,	O
surpassing	O
previous	O
systems	O
that	O
use	O
other	O
forms	O
of	O
transfer	O
or	O
joint	O
learning	O
with	O
additional	O
labeled	O
data	O
and	O
task	O
specific	O
gazetteers	O
.	O

Bi-directional	O
LSTMs	O
are	O
a	O
powerful	O
tool	O
for	O
text	O
representation	O
.	O
On	O
the	O
other	O
hand	O
,	O
they	O
have	O
been	O
shown	O
to	O
suffer	O
various	O
limitations	O
due	O
to	O
their	O
sequential	O
nature	O
.	O
We	O
investigate	O
an	O
alternative	B-RESEARCH_PROBLEM
LSTM	I-RESEARCH_PROBLEM
structure	I-RESEARCH_PROBLEM
for	I-RESEARCH_PROBLEM
encoding	I-RESEARCH_PROBLEM
text	E-RESEARCH_PROBLEM
,	O
which	O
consists	O
of	O
a	O
parallel	O
state	O
for	O
each	O
word	O
.	O
Recurrent	O
steps	O
are	O
used	O
to	O
perform	O
local	O
and	O
global	O
information	O
exchange	O
between	O
words	O
simultaneously	O
,	O
rather	O
than	O
incremental	O
reading	O
of	O
a	O
sequence	O
of	O
words	O
.	O
Results	O
on	O
various	O
classification	O
and	O
sequence	O
labelling	O
benchmarks	O
show	O
that	O
the	O
proposed	O
model	O
has	O
strong	O
representation	O
power	O
,	O
giving	O
highly	O
competitive	O
performances	O
compared	O
to	O
stacked	O
BiLSTM	O
models	O
with	O
similar	O
parameter	O
numbers	O
.	O

Neural	B-RESEARCH_PROBLEM
network	I-RESEARCH_PROBLEM
approaches	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
Named	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
reduce	O
the	O
need	O
for	O
carefully	O
handcrafted	O
features	O
.	O
While	O
some	O
features	O
do	O
remain	O
in	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
,	O
lexical	O
features	O
have	O
been	O
mostly	O
discarded	O
,	O
with	O
the	O
exception	O
of	O
gazetteers	O
.	O
In	O
this	O
work	O
,	O
we	O
show	O
that	O
this	O
is	O
unfair	O
:	O
lexical	O
features	O
are	O
actually	O
quite	O
useful	O
.	O
We	O
propose	O
to	O
embed	O
words	O
and	O
entity	O
types	O
into	O
a	O
lowdimensional	O
vector	O
space	O
we	O
train	O
from	O
annotated	O
data	O
produced	O
by	O
distant	O
supervision	O
thanks	O
to	O
Wikipedia	O
.	O
From	O
this	O
,	O
we	O
compute	O
-	O
offline	O
-	O
a	O
feature	O
vector	O
representing	O
each	O
word	O
.	O
When	O
used	O
with	O
a	O
vanilla	O
recurrent	O
neural	O
network	O
model	O
,	O
this	O
representation	O
yields	O
substantial	O
improvements	O
.	O
We	O
establish	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
F1	O
score	O
of	O
87.95	O
on	O
ONTONOTES	O
5.0	O
,	O
while	O
matching	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
with	O
a	O
F	O
1	O
score	O
of	O
91.73	O
on	O
the	O
over	O
-	O
studied	O
CONLL	O
-	O
2003	O
dataset	O
.	O

It	O
is	O
common	O
that	O
entity	O
mentions	O
can	O
contain	O
other	O
mentions	O
recursively	O
.	O
This	O
paper	O
introduces	O
a	O
scalable	O
transition	O
-	O
based	O
method	O
to	O
model	B-RESEARCH_PROBLEM
the	I-RESEARCH_PROBLEM
nested	I-RESEARCH_PROBLEM
structure	I-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
mentions	E-RESEARCH_PROBLEM
.	O
We	O
first	O
map	O
a	O
sentence	O
with	O
nested	O
mentions	O
to	O
a	O
designated	O
forest	O
where	O
each	O
mention	O
corresponds	O
to	O
a	O
constituent	O
of	O
the	O
forest	O
.	O
Our	O
shiftreduce	O
based	O
system	O
then	O
learns	O
to	O
construct	O
the	O
forest	O
structure	O
in	O
a	O
bottom	O
-	O
up	O
manner	O
through	O
an	O
action	O
sequence	O
whose	O
maximal	O
length	O
is	O
guaranteed	O
to	O
be	O
three	O
times	O
of	O
the	O
sentence	O
length	O
.	O
Based	O
on	O
Stack	O
-	O
LSTM	O
which	O
is	O
employed	O
to	O
efficiently	O
and	O
effectively	O
represent	O
the	O
states	O
of	O
the	O
system	O
in	O
a	O
continuous	O
space	O
,	O
our	O
system	O
is	O
further	O
incorporated	O
with	O
a	O
character	O
-	O
based	O
component	O
to	O
capture	O
letterlevel	O
patterns	O
.	O
Our	O
model	O
achieves	O
the	O
stateof	O
-	O
the	O
-	O
art	O
results	O
on	O
ACE	O
datasets	O
,	O
showing	O
its	O
effectiveness	O
in	O
detecting	O
nested	O
mentions	O
.	O
1	O

We	O
introduce	O
a	O
new	O
language	B-RESEARCH_PROBLEM
representation	I-RESEARCH_PROBLEM
model	E-RESEARCH_PROBLEM
called	O
BERT	O
,	O
which	O
stands	O
for	O
Bidirectional	O
Encoder	O
Representations	O
from	O
Transformers	O
.	O
Unlike	O
recent	O
(	O
Peters	O
et	O
al.	O
,	O
2018	O
a	O
;	O
Radford	O
et	O
al.	O
,	O
2018	O
)	O
,	O
BERT	O
is	O
designed	O
to	O
pretrain	O
deep	O
bidirectional	O
representations	O
from	O
unlabeled	O
text	O
by	O
jointly	O
conditioning	O
on	O
both	O
left	O
and	O
right	O
context	O
in	O
all	O
layers	O
.	O
As	O
a	O
result	O
,	O
the	O
pre-trained	O
BERT	O
model	O
can	O
be	O
finetuned	O
with	O
just	O
one	O
additional	O
output	O
layer	O
to	O
create	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
a	O
wide	O
range	O
of	O
tasks	O
,	O
such	O
as	O
question	O
answering	O
and	O
language	O
inference	O
,	O
without	O
substantial	O
taskspecific	O
architecture	O
modifications	O
.	O
BERT	O
is	O
conceptually	O
simple	O
and	O
empirically	O
powerful	O
.	O
It	O
obtains	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
eleven	O
natural	O
language	O
processing	O
tasks	O
,	O
including	O
pushing	O
the	O
GLUE	O
score	O
to	O
80.5	O
%	O
(	O
7.7	O
%	O
point	O
absolute	O
improvement	O
)	O
,	O
MultiNLI	O
accuracy	O
to	O
86.7	O
%	O
(	O
4.6	O
%	O
absolute	O
improvement	O
)	O
,	O
SQ	O
u	O
AD	O
v	O
1.1	O
question	O
answering	O
Test	O
F1	O
to	O
93.2	O
(	O
1.5	O
point	O
absolute	O
improvement	O
)	O
and	O
SQ	O
u	O
AD	O
v2.0	O
Test	O
F1	O
to	O
83.1	O
(	O
5.1	O
point	O
absolute	O
improvement	O
)	O
.	O
Jeremy	O
Howard	O
and	O
Sebastian	O
Ruder	O
.	O
2018	O
.	O
Universal	O
language	O
model	O
fine	O
-	O
tuning	O
for	O
text	O
classification	O
.	O

Motivation	O
:	O
Biomedical	O
text	O
mining	O
is	O
becoming	O
increasingly	O
important	O
as	O
the	O
number	O
of	O
biomedical	O
documents	O
rapidly	O
grows	O
.	O
With	O
the	O
progress	O
in	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
,	O
extracting	B-RESEARCH_PROBLEM
valuable	I-RESEARCH_PROBLEM
information	I-RESEARCH_PROBLEM
from	I-RESEARCH_PROBLEM
biomedical	I-RESEARCH_PROBLEM
literature	E-RESEARCH_PROBLEM
has	O
gained	O
popularity	O
among	O
researchers	O
,	O
and	O
deep	O
learning	O
has	O
boosted	O
the	O
development	O
of	O
effective	O
biomedical	O
text	O
mining	O
models	O
.	O
However	O
,	O
directly	O
applying	O
the	O
advancements	O
in	O
NLP	O
to	O
biomedical	B-RESEARCH_PROBLEM
text	I-RESEARCH_PROBLEM
mining	I-RESEARCH_PROBLEM
often	I-RESEARCH_PROBLEM
yields	I-RESEARCH_PROBLEM
unsatisfactory	I-RESEARCH_PROBLEM
results	I-RESEARCH_PROBLEM
due	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
a	I-RESEARCH_PROBLEM
word	I-RESEARCH_PROBLEM
distribution	I-RESEARCH_PROBLEM
shift	I-RESEARCH_PROBLEM
from	I-RESEARCH_PROBLEM
general	I-RESEARCH_PROBLEM
domain	I-RESEARCH_PROBLEM
corpora	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
biomedical	I-RESEARCH_PROBLEM
corpora	E-RESEARCH_PROBLEM
.	O
In	O
this	O
article	O
,	O
we	O
investigate	O
how	O
the	O
recently	O
introduced	O
pre-trained	B-RESEARCH_PROBLEM
language	I-RESEARCH_PROBLEM
model	I-RESEARCH_PROBLEM
BERT	I-RESEARCH_PROBLEM
can	I-RESEARCH_PROBLEM
be	I-RESEARCH_PROBLEM
adapted	I-RESEARCH_PROBLEM
for	I-RESEARCH_PROBLEM
biomedical	I-RESEARCH_PROBLEM
corpora	E-RESEARCH_PROBLEM
.	O
Results	O
:	O
We	O
introduce	O
BioBERT	O
(	O
Bidirectional	O
Encoder	O
Representations	O
from	O
Transformers	O
for	O
Biomedical	O
Text	O
Mining	O
)	O
,	O
which	O
is	O
a	O
domain	O
-	O
specific	O
language	O
representation	O
model	O
pre-trained	O
on	O
large	O
-	O
scale	O
biomedical	O
corpora	O
.	O

Building	B-RESEARCH_PROBLEM
computers	I-RESEARCH_PROBLEM
able	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
answer	I-RESEARCH_PROBLEM
questions	I-RESEARCH_PROBLEM
on	I-RESEARCH_PROBLEM
any	I-RESEARCH_PROBLEM
subject	E-RESEARCH_PROBLEM
is	O
along	O
standing	O
goal	O
of	O
artificial	O
intelligence	O
.	O
Promising	O
progress	O
has	O
recently	O
been	O
achieved	O
by	O
methods	O
that	O
learn	O
to	O
map	O
questions	O
to	O
logical	O
forms	O
or	O
data	O
base	O
queries	O
.	O
Such	O
approaches	O
can	O
be	O
effective	O
but	O
at	O
the	O
cost	O
of	O
either	O
large	O
amounts	O
of	O
human	O
-	O
labeled	O
data	O
or	O
by	O
defining	O
lexicons	O
and	O
grammars	O
tailored	O
by	O
practitioners	O
.	O
In	O
this	O
paper	O
,	O
we	O
instead	O
take	O
the	O
radical	O
approach	O
of	O
learning	O
to	O
map	O
questions	O
to	O
vectorial	O
feature	O
representations	O
.	O
By	O
mapping	O
answers	O
into	O
the	O
same	O
space	O
one	O
can	O
query	O
any	O
knowledge	O
base	O
independent	O
of	O
its	O
schema	O
,	O
without	O
requiring	O
any	O
grammar	O
or	O
lexicon	O
.	O
Our	O
method	O
is	O
trained	O
with	O
a	O
new	O
optimization	O
procedure	O
combining	O
stochastic	O
gradient	O
descent	O
followed	O
by	O
a	O
fine	O
-	O
tuning	O
step	O
using	O
the	O
weak	O
supervision	O
provided	O
by	O
blending	O
automatically	O
and	O
collaboratively	O
generated	O
resources	O
.	O
We	O
empirically	O
demonstrate	O
that	O
our	O
model	O
can	O
capture	O
meaningful	O
signals	O
from	O
its	O
noisy	O
supervision	O
leading	O
to	O
major	O
improvements	O
over	O
paralex	O
,	O
the	O
only	O
existing	O
method	O
able	O
to	O
be	O
trained	O
on	O
similar	O
weakly	O
labeled	O
data	O
.	O

Semantic	B-RESEARCH_PROBLEM
matching	E-RESEARCH_PROBLEM
is	O
of	O
central	O
importance	O
to	O
many	O
natural	O
language	O
tasks	O
[	O
2,28	O
]	O
.	O
A	O
successful	O
matching	O
algorithm	O
needs	O
to	O
adequately	O
model	O
the	O
internal	O
structures	O
of	O
language	O
objects	O
and	O
the	O
interaction	O
between	O
them	O
.	O
As	O
a	O
step	O
toward	O
this	O
goal	O
,	O
we	O
propose	O
convolutional	O
neural	O
network	O
models	O
for	O
matching	O
two	O
sentences	O
,	O
by	O
adapting	O
the	O
convolutional	O
strategy	O
in	O
vision	O
and	O
speech	O
.	O
The	O
proposed	O
models	O
not	O
only	O
nicely	O
represent	O
the	O
hierarchical	O
structures	O
of	O
sentences	O
with	O
their	O
layerby	O
-	O
layer	O
composition	O
and	O
pooling	O
,	O
but	O
also	O
capture	O
the	O
rich	O
matching	O
patterns	O
at	O
different	O
levels	O
.	O
Our	O
models	O
are	O
rather	O
generic	O
,	O
requiring	O
no	O
prior	O
knowledge	O
on	O
language	O
,	O
and	O
can	O
hence	O
be	O
applied	O
to	O
matching	O
tasks	O
of	O
different	O
nature	O
and	O
in	O
different	O
languages	O
.	O
The	O
empirical	O
study	O
on	O
a	O
variety	O
of	O
matching	O
tasks	O
demonstrates	O
the	O
efficacy	O
of	O
the	O
proposed	O
model	O
on	O
a	O
variety	O
of	O
matching	O
tasks	O
and	O
its	O
superiority	O
to	O
competitor	O
models	O
.	O

Training	B-RESEARCH_PROBLEM
large	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
scale	I-RESEARCH_PROBLEM
question	I-RESEARCH_PROBLEM
answering	I-RESEARCH_PROBLEM
systems	E-RESEARCH_PROBLEM
is	O
complicated	O
because	O
training	O
sources	O
usually	O
cover	O
a	O
small	O
portion	O
of	O
the	O
range	O
of	O
possible	O
questions	O
.	O
This	O
paper	O
studies	O
the	O
impact	O
of	O
multitask	O
and	O
transfer	O
learning	O
for	O
simple	B-RESEARCH_PROBLEM
question	I-RESEARCH_PROBLEM
answering	E-RESEARCH_PROBLEM
;	O
a	O
setting	O
for	O
which	O
the	O
reasoning	O
required	O
to	O
answer	O
is	O
quite	O
easy	O
,	O
as	O
long	O
as	O
one	O
can	O
retrieve	O
the	O
correct	O
evidence	O
given	O
a	O
question	O
,	O
which	O
can	O
be	O
difficult	O
in	O
large	O
-	O
scale	O
conditions	O
.	O
To	O
this	O
end	O
,	O
we	O
introduce	O
a	O
new	O
dataset	O
of	O
100	O
k	O
questions	O
that	O
we	O
use	O
in	O
conjunction	O
with	O
existing	O
benchmarks	O
.	O
We	O
conduct	O
our	O
study	O
within	O
the	O
framework	O
of	O
Memory	O
Networks	O
(	O
Weston	O
et	O
al.	O
,	O
2015	O
)	O
because	O
this	O
perspective	O
allows	O
us	O
to	O
eventually	O
scale	O
up	O
to	O
more	O
complex	O
reasoning	O
,	O
and	O
show	O
that	O
Memory	O
Networks	O
can	O
be	O
successfully	O
trained	O
to	O
achieve	O
excellent	O
performance	O
.	O

Most	O
conventional	O
sentence	B-RESEARCH_PROBLEM
similarity	E-RESEARCH_PROBLEM
methods	O
only	O
focus	O
on	O
similar	O
parts	O
of	O
two	O
input	O
sentences	O
,	O
and	O
simply	O
ignore	O
the	O
dissimilar	O
parts	O
,	O
which	O
usually	O
give	O
us	O
some	O
clues	O
and	O
semantic	O
meanings	O
about	O
the	O
sentences	O
.	O
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
model	O
to	O
take	O
into	O
account	O
both	O
the	O
similarities	O
and	O
dissimilarities	O
by	O
decomposing	O
and	O
composing	O
lexical	O
semantics	O
over	O
sentences	O
.	O
The	O
model	O
represents	O
each	O
word	O
as	O
a	O
vector	O
,	O
and	O
calculates	O
a	O
semantic	O
matching	O
vector	O
for	O
each	O
word	O
based	O
on	O
all	O
words	O
in	O
the	O
other	O
sentence	O
.	O
Then	O
,	O
each	O
word	O
vector	O
is	O
decomposed	O
into	O
a	O
similar	O
component	O
and	O
a	O
dissimilar	O
component	O
based	O
on	O
the	O
semantic	O
matching	O
vector	O
.	O
After	O
this	O
,	O
a	O
two	O
-	O
channel	O
CNN	O
model	O
is	O
employed	O
to	O
capture	O
features	O
by	O
composing	O
the	O
similar	O
and	O
dissimilar	O
components	O
.	O
Finally	O
,	O
a	O
similarity	O
score	O
is	O
estimated	O
over	O
the	O
composed	O
feature	O
vectors	O
.	O
Experimental	O
results	O
show	O
that	O
our	O
model	O
gets	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
answer	O
sentence	O
selection	O
task	O
,	O
and	O
achieves	O
a	O
comparable	O
result	O
on	O
the	O
paraphrase	O
identification	O
task	O
.	O

Understanding	B-RESEARCH_PROBLEM
unstructured	I-RESEARCH_PROBLEM
text	E-RESEARCH_PROBLEM
is	O
a	O
major	O
goal	O
within	O
natural	O
language	O
processing	O
.	O
Comprehension	O
tests	O
pose	O
questions	O
based	O
on	O
short	O
text	O
passages	O
to	O
evaluate	O
such	O
understanding	O
.	O
In	O
this	O
work	O
,	O
we	O
investigate	O
machine	O
comprehension	O
on	O
the	O
challenging	O
benchmark	O
.	O
Partly	O
because	O
of	O
its	O
limited	O
size	O
,	O
prior	O
work	O
on	O
MCTest	O
has	O
focused	O
mainly	O
on	O
engineering	O
better	O
features	O
.	O
We	O
tackle	O
the	O
dataset	O
with	O
a	O
neural	O
approach	O
,	O
harnessing	O
simple	O
neural	O
networks	O
arranged	O
in	O
a	O
parallel	O
hierarchy	O
.	O
The	O
parallel	O
hierarchy	O
enables	O
our	O
model	O
to	O
compare	O
the	O
passage	O
,	O
question	O
,	O
and	O
answer	O
from	O
a	O
variety	O
of	O
trainable	O
perspectives	O
,	O
as	O
opposed	O
to	O
using	O
a	O
manually	O
designed	O
,	O
rigid	O
feature	O
set	O
.	O
Perspectives	O
range	O
from	O
the	O
word	O
level	O
to	O
sentence	O
fragments	O
to	O
sequences	O
of	O
sentences	O
;	O
the	O
networks	O
operate	O
only	O
on	O
word	O
-	O
embedding	O
representations	O
of	O
text	O
.	O

We	O
propose	O
a	O
novel	O
neural	O
attention	O
architecture	O
to	O
tackle	O
machine	B-RESEARCH_PROBLEM
comprehension	E-RESEARCH_PROBLEM
tasks	O
,	O
such	O
as	O
answering	B-RESEARCH_PROBLEM
Cloze	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
style	I-RESEARCH_PROBLEM
queries	I-RESEARCH_PROBLEM
with	I-RESEARCH_PROBLEM
respect	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
a	I-RESEARCH_PROBLEM
document	E-RESEARCH_PROBLEM
.	O
Unlike	O
previous	O
models	O
,	O
we	O
do	O
not	O
collapse	O
the	O
query	O
into	O
a	O
single	O
vector	O
,	O
instead	O
we	O
deploy	O
an	O
iterative	O
alternating	O
attention	O
mechanism	O
that	O
allows	O
a	O
fine	O
-	O
grained	O
exploration	O
of	O
both	O
the	O
query	O
and	O
the	O
document	O
.	O
Our	O
model	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
baselines	O
in	O
standard	O
machine	B-RESEARCH_PROBLEM
comprehension	E-RESEARCH_PROBLEM
benchmarks	O
such	O
as	O
CNN	O
news	O
articles	O
and	O
the	O
Children	O
's	O
Book	O
Test	O
(	O
CBT	O
)	O
dataset	O
.	O

In	O
this	O
paper	O
,	O
we	O
study	O
the	O
problem	O
of	O
question	B-RESEARCH_PROBLEM
answering	I-RESEARCH_PROBLEM
when	I-RESEARCH_PROBLEM
reasoning	I-RESEARCH_PROBLEM
over	I-RESEARCH_PROBLEM
multiple	I-RESEARCH_PROBLEM
facts	I-RESEARCH_PROBLEM
is	I-RESEARCH_PROBLEM
required	E-RESEARCH_PROBLEM
.	O
We	O
propose	O
Query	O
-	O
Reduction	O
Network	O
(	O
QRN	O
)	O
,	O
a	O
variant	O
of	O
Recurrent	O
Neural	O
Network	O
(	O
RNN	O
)	O
that	O
effectively	O
handles	O
both	O
short	O
-	O
term	O
(	O
local	O
)	O
and	O
long	O
-	O
term	O
(	O
global	O
)	O
sequential	O
dependencies	O
to	O
reason	O
over	O
multiple	O
facts	O
.	O
QRN	O
considers	O
the	O
context	O
sentences	O
as	O
a	O
sequence	O
of	O
state	O
-	O
changing	O
triggers	O
,	O
and	O
reduces	O
the	O
original	O
query	O
to	O
a	O
more	O
informed	O
query	O
as	O
it	O
observes	O
each	O
trigger	O
(	O
context	O
sentence	O
)	O
through	O
time	O
.	O
Our	O
experiments	O
show	O
that	O
QRN	O
produces	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
bAbI	O
QA	O
and	O
dialog	O
tasks	O
,	O
and	O
in	O
are	O
al	O
goal	O
-	O
oriented	O
dialog	O
dataset	O
.	O
In	O
addition	O
,	O
QRN	O
formulation	O
allows	O
parallelization	O
on	O
RNN	O
's	O
time	O
axis	O
,	O
saving	O
an	O
order	O
of	O
magnitude	O
in	O
time	O
complexity	O
for	O
training	O
and	O
inference	O
.	O
INTRODUCTION	O
In	O
this	O
paper	O
,	O
we	O
address	O
the	O
problem	O
of	O
question	O
answering	O
(	O
QA	O
)	O
when	O
reasoning	O
over	O
multiple	O
facts	O
is	O
required	O
.	O

We	O
present	O
a	O
memory	O
augmented	O
neural	O
network	O
for	O
natural	B-RESEARCH_PROBLEM
language	I-RESEARCH_PROBLEM
understanding	E-RESEARCH_PROBLEM
:	O
Neural	O
Semantic	O
Encoders	O
.	O
NSE	O
is	O
equipped	O
with	O
a	O
novel	O
memory	O
update	O
rule	O
and	O
has	O
a	O
variable	O
sized	O
encoding	O
memory	O
that	O
evolves	O
overtime	O
and	O
maintains	O
the	O
understanding	O
of	O
input	O
sequences	O
through	O
read	O
,	O
compose	O
and	O
write	O
operations	O
.	O
NSE	O
can	O
also	O
access	O
1	O
multiple	O
and	O
shared	O
memories	O
.	O
In	O
this	O
paper	O
,	O
we	O
demonstrated	O
the	O
effectiveness	O
and	O
the	O
flexibility	O
of	O
NSE	O
on	O
five	O
different	O
natural	O
language	O
tasks	O
:	O
natural	O
language	O
inference	O
,	O
question	O
answering	O
,	O
sentence	O
classification	O
,	O
document	O
sentiment	O
analysis	O
and	O
machine	O
translation	O
where	O
NSE	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
when	O
evaluated	O
on	O
publically	O
available	O
benchmarks	O
.	O
For	O
example	O
,	O
our	O
shared	O
-	O
memory	O
model	O
showed	O
an	O
encouraging	O
result	O
on	O
neural	O
machine	O
translation	O
,	O
improving	O
an	O
attention	O
-	O
based	O
baseline	O
by	O
approximately	O
1.0	O
BLEU	O
.	O
Recurrent	O
neural	O
networks	O
(	O
RNNs	O
)	O
have	O
been	O
successful	O
for	O
modeling	O
sequences	O
[	O
1	O
]	O
.	O

Machine	B-RESEARCH_PROBLEM
comprehension	I-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
text	E-RESEARCH_PROBLEM
is	O
an	O
important	O
problem	O
in	O
natural	O
language	O
processing	O
.	O
A	O
recently	O
released	O
dataset	O
,	O
the	O
Stanford	O
Question	O
Answering	O
Dataset	O
(	O
SQuAD	O
)	O
,	O
offers	O
a	O
large	O
number	O
of	O
real	O
questions	O
and	O
their	O
answers	O
created	O
by	O
humans	O
through	O
crowdsourcing	O
.	O
SQuAD	O
provides	O
a	O
challenging	O
testbed	O
for	O
evaluating	O
machine	O
comprehension	O
algorithms	O
,	O
partly	O
because	O
compared	O
with	O
previous	O
datasets	O
,	O
in	O
SQuAD	O
the	O
answers	O
do	O
not	O
come	O
from	O
a	O
small	O
set	O
of	O
candidate	O
answers	O
and	O
they	O
have	O
variable	O
lengths	O
.	O
We	O
propose	O
an	O
end	O
-	O
to	O
-	O
end	O
neural	O
architecture	O
for	O
the	O
task	O
.	O
The	O
architecture	O
is	O
based	O
on	O
match	O
-	O
LSTM	O
,	O
a	O
model	O
we	O
proposed	O
previously	O
for	O
textual	O
entailment	O
,	O
and	O
Pointer	O
Net	O
,	O
a	O
sequence	O
-	O
to	O
-	O
sequence	O
model	O
proposed	O
by	O
Vinyals	O
et	O
al.	O
(	O
2015	O
)	O
to	O
constrain	O
the	O
output	O
tokens	O
to	O
be	O
from	O
the	O
input	O
sequences	O
.	O
We	O
propose	O
two	O
ways	O
of	O
using	O
Pointer	O
Net	O
for	O
our	O
task	O
.	O
Our	O
experiments	O
show	O
that	O
both	O
of	O
our	O
two	O
models	O
substantially	O
outperform	O
the	O
best	O
results	O
obtained	O
by	O
Rajpurkar	O
et	O
al.	O
(	O
2016	O
)	O
using	O
logistic	O
regression	O
and	O
manually	O
crafted	O
features	O
.	O

The	O
reading	B-RESEARCH_PROBLEM
comprehension	E-RESEARCH_PROBLEM
task	O
,	O
that	O
asks	O
questions	O
about	O
a	O
given	O
evidence	O
document	O
,	O
is	O
a	O
central	O
problem	O
in	O
natural	O
language	O
understanding	O
.	O
Recent	O
formulations	O
of	O
this	O
task	O
have	O
typically	O
focused	O
on	O
answer	O
selection	O
from	O
a	O
set	O
of	O
candidates	O
pre-defined	O
manually	O
or	O
through	O
the	O
use	O
of	O
an	O
external	O
NLP	O
pipeline	O
.	O
However	O
,	O
Rajpurkar	O
et	O
al	O
.	O
(	O
2016	O
)	O
recently	O
released	O
the	O
SQUAD	O
dataset	O
in	O
which	O
the	O
answers	O
can	O
be	O
arbitrary	O
strings	O
from	O
the	O
supplied	O
text	O
.	O
In	O
this	O
paper	O
,	O
we	O
focus	O
on	O
this	O
answer	O
extraction	O
task	O
,	O
presenting	O
a	O
novel	O
model	O
architecture	O
that	O
efficiently	O
builds	O
fixed	O
length	O
representations	O
of	O
all	O
spans	O
in	O
the	O
evidence	O
document	O
with	O
a	O
recurrent	O
network	O
.	O
We	O
show	O
that	O
scoring	O
explicit	O
span	O
representations	O
significantly	O
improves	O
performance	O
over	O
other	O
approaches	O
that	O
factor	O
the	O
prediction	O
into	O
separate	O
predictions	O
about	O
words	O
or	O
start	O
and	O
end	O
markers	O
.	O
Our	O
approach	O
improves	O
upon	O
the	O
best	O
published	O
results	O
of	O
Wang	O
&	O
Jiang	O
(	O
2016	O
)	O
by	O
5	O
%	O
and	O
decreases	O
the	O
error	O
of	O
Rajpurkar	O
et	O
al.	O
's	O
baseline	O
by	O
>	O
50	O
%.	O
Recently	O
,	O
Rajpurkar	O
et	O
al.	O
(	O
2016	O
)	O
released	O
the	O
less	O
restricted	O
SQUAD	O
dataset	O
1	O
that	O
does	O
not	O
place	O
any	O
constraints	O
on	O
the	O
set	O
of	O
allowed	O
answers	O
,	O
other	O
than	O
that	O
they	O
should	O
be	O
drawn	O
from	O
the	O
evidence	O
document	O
.	O

We	O
present	O
a	O
novel	O
end	B-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
end	I-RESEARCH_PROBLEM
neural	I-RESEARCH_PROBLEM
model	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
extract	I-RESEARCH_PROBLEM
entities	I-RESEARCH_PROBLEM
and	I-RESEARCH_PROBLEM
relations	I-RESEARCH_PROBLEM
between	I-RESEARCH_PROBLEM
them	E-RESEARCH_PROBLEM
.	O
Our	O
recurrent	O
neural	O
network	O
based	O
model	O
captures	O
both	O
word	O
sequence	O
and	O
dependency	O
tree	O
substructure	O
information	O
by	O
stacking	O
bidirectional	O
treestructured	O
LSTM	O
-	O
RNNs	O
on	O
bidirectional	O
sequential	O
LSTM	O
-	O
RNNs	O
.	O
This	O
allows	O
our	O
model	O
to	O
jointly	B-RESEARCH_PROBLEM
represent	I-RESEARCH_PROBLEM
both	I-RESEARCH_PROBLEM
entities	I-RESEARCH_PROBLEM
and	I-RESEARCH_PROBLEM
relations	I-RESEARCH_PROBLEM
with	I-RESEARCH_PROBLEM
shared	I-RESEARCH_PROBLEM
parameters	I-RESEARCH_PROBLEM
in	I-RESEARCH_PROBLEM
a	I-RESEARCH_PROBLEM
single	I-RESEARCH_PROBLEM
model	E-RESEARCH_PROBLEM
.	O
We	O
further	O
encourage	O
detection	O
of	O
entities	O
during	O
training	O
and	O
use	O
of	O
entity	O
information	O
in	O
relation	O
extraction	O
via	O
entity	O
pretraining	O
and	O
scheduled	O
sampling	O
.	O
Our	O
model	O
improves	O
over	O
the	O
stateof	O
-	O
the	O
-	O
art	O
feature	O
-	O
based	O
model	O
on	O
end	O
-toend	O
relation	O
extraction	O
,	O
achieving	O
12.1	O
%	O
and	O
5.7	O
%	O
relative	O
error	O
reductions	O
in	O
F1score	O
on	O
ACE2005	O
and	O
ACE2004	O
,	O
respectively	O
.	O
We	O
also	O
show	O
that	O
our	O
LSTM	O
-	O
RNN	O
based	O
model	O
compares	O
favorably	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
CNN	O
based	O
model	O
(	O
in	O
F1-score	O
)	O
on	O
nominal	O
relation	O
classification	O
(	O
Sem	O
Eval	O
-	O
2010	O
Task	O
8	O
)	O
.	O
Finally	O
,	O
we	O
present	O
an	O
extensive	O
ablation	O
analysis	O
of	O
several	O
model	O
components	O
.	O

State	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
joint	O
entity	O
recognition	O
and	O
relation	O
extraction	O
strongly	O
rely	O
on	O
external	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
tools	O
such	O
as	O
POS	O
(	O
part	O
-	O
of	O
-	O
speech	O
)	O
taggers	O
and	O
dependency	O
parsers	O
.	O
Thus	O
,	O
the	O
performance	O
of	O
such	O
joint	O
models	O
depends	O
on	O
the	O
quality	O
of	O
the	O
features	O
obtained	O
from	O
these	O
NLP	O
tools	O
.	O
However	O
,	O
these	O
features	O
are	O
not	O
always	O
accurate	O
for	O
various	O
languages	O
and	O
contexts	O
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
joint	O
neural	O
model	O
which	O
performs	O
entity	B-RESEARCH_PROBLEM
recognition	I-RESEARCH_PROBLEM
and	I-RESEARCH_PROBLEM
relation	I-RESEARCH_PROBLEM
extraction	I-RESEARCH_PROBLEM
simultaneously	E-RESEARCH_PROBLEM
,	O
without	O
the	O
need	O
of	O
any	O
manually	O
extracted	O
features	O
or	O
the	O
use	O
of	O
any	O
external	O
tool	O
.	O
Specifically	O
,	O
we	O
model	O
the	O
entity	O
recognition	O
task	O
using	O
a	O
CRF	O
(	O
Conditional	O
Random	O
Fields	O
)	O
layer	O
and	O
the	O
relation	O
extraction	O
task	O
as	O
a	O
multi-head	O
selection	O
problem	O
(	O
i.e.	O
,	O
potentially	O
identify	O
multiple	O
relations	O
for	O
each	O
entity	O
)	O
.	O
We	O
present	O
an	O
extensive	O
experimental	O
setup	O
,	O
to	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
method	O
using	O
datasets	O
from	O
various	O
contexts	O
(	O
i.e.	O
,	O
news	O
,	O
biomedical	O
,	O
real	O
estate	O
)	O
and	O
languages	O
(	O
i.e.	O
,	O
English	O
,	O
Dutch	O
)	O
.	O
Our	O
model	O
outperforms	O
the	O
previous	O
neural	O
models	O
that	O
use	O
automatically	O
extracted	O
features	O
,	O
while	O
it	O
performs	O
within	O
a	O
reasonable	O
margin	O
of	O
feature	O
-	O
based	O
neural	O
models	O
,	O
or	O
even	O
beats	O
them	O
.	O

Adversarial	O
training	O
(	O
AT	O
)	O
is	O
a	O
regularization	O
method	O
that	O
can	O
be	O
used	O
to	O
improve	O
the	O
robustness	O
of	O
neural	O
network	O
methods	O
by	O
adding	O
small	O
perturbations	O
in	O
the	O
training	O
data	O
.	O
We	O
show	O
how	O
to	O
use	O
AT	O
for	O
the	O
tasks	O
of	O
entity	B-RESEARCH_PROBLEM
recognition	I-RESEARCH_PROBLEM
and	I-RESEARCH_PROBLEM
relation	I-RESEARCH_PROBLEM
extraction	E-RESEARCH_PROBLEM
.	O
In	O
particular	O
,	O
we	O
demonstrate	O
that	O
applying	O
AT	O
to	O
a	O
general	O
purpose	O
baseline	O
model	O
for	O
jointly	B-RESEARCH_PROBLEM
extracting	I-RESEARCH_PROBLEM
entities	I-RESEARCH_PROBLEM
and	I-RESEARCH_PROBLEM
relations	E-RESEARCH_PROBLEM
,	O
allows	O
improving	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
effectiveness	O
on	O
several	O
datasets	O
in	O
different	O
contexts	O
(	O
i.e.	O
,	O
news	O
,	O
biomedical	O
,	O
and	O
real	O
estate	O
data	O
)	O
and	O
for	O
different	O
languages	O
(	O
English	O
and	O
Dutch	O
)	O
.	O

Dependency	O
trees	O
help	O
relation	O
extraction	O
models	O
capture	B-RESEARCH_PROBLEM
long	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
range	I-RESEARCH_PROBLEM
relations	I-RESEARCH_PROBLEM
between	I-RESEARCH_PROBLEM
words	E-RESEARCH_PROBLEM
.	O
However	O
,	O
existing	O
dependency	O
-	O
based	O
models	O
either	O
neglect	O
crucial	O
information	O
(	O
e.g.	O
,	O
negation	O
)	O
by	O
pruning	O
the	O
dependency	O
trees	O
too	O
aggressively	O
,	O
or	O
are	O
computationally	O
inefficient	O
because	O
it	O
is	O
difficult	O
to	O
parallelize	O
over	O
different	O
tree	O
structures	O
.	O
We	O
propose	O
an	O
extension	O
of	O
graph	O
convolutional	O
networks	O
that	O
is	O
tailored	O
for	O
relation	O
extraction	O
,	O
which	O
pools	O
information	O
over	O
arbitrary	O
dependency	O
structures	O
efficiently	O
in	O
parallel	O
.	O
To	O
incorporate	O
relevant	O
information	O
while	O
maximally	O
removing	O
irrelevant	O
content	O
,	O
we	O
further	O
apply	O
a	O
novel	O
pruning	O
strategy	O
to	O
the	O
input	O
trees	O
by	O
keeping	O
words	O
immediately	O
around	O
the	O
shortest	O
path	O
between	O
the	O
two	O
entities	O
among	O
which	O
a	O
relation	O
might	O
hold	O
.	O
The	O
resulting	O
model	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
large	O
-	O
scale	O
TACRED	O
dataset	O
,	O
outperforming	O
existing	O
sequence	O
and	O
dependency	O
-	O
based	O
neural	O
models	O
.	O
We	O
also	O
show	O
through	O
detailed	O
analysis	O
that	O
this	O
model	O
has	O
complementary	O
strengths	O
to	O
sequence	O
models	O
,	O
and	O
combining	O
them	O
further	O
improves	O
the	O
state	O
of	O
the	O
art	O
.	O
*	O
Equal	O
contribution	O
.	O

We	O
propose	O
a	O
neural	O
network	O
model	O
for	O
joint	B-RESEARCH_PROBLEM
extraction	I-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
named	I-RESEARCH_PROBLEM
entities	I-RESEARCH_PROBLEM
and	I-RESEARCH_PROBLEM
relations	I-RESEARCH_PROBLEM
between	I-RESEARCH_PROBLEM
them	E-RESEARCH_PROBLEM
,	O
without	O
any	O
hand	O
-	O
crafted	O
features	O
.	O
The	O
key	O
contribution	O
of	O
our	O
model	O
is	O
to	O
extend	O
a	O
BiLSTM	O
-	O
CRF	O
-	O
based	O
entity	O
recognition	O
model	O
with	O
a	O
deep	O
biaffine	O
attention	O
layer	O
to	O
model	O
second	O
-	O
order	O
interactions	O
between	O
latent	O
features	O
for	O
relation	O
classification	O
,	O
specifically	O
attending	O
to	O
the	O
role	O
of	O
an	O
entity	O
in	O
a	O
directional	O
relationship	O
.	O
On	O
the	O
benchmark	O
"	O
relation	O
and	O
entity	O
recognition	O
"	O
dataset	O
CoNLL04	O
,	O
experimental	O
results	O
show	O
that	O
our	O
model	O
outperforms	O
previous	O
models	O
,	O
producing	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
.	O

Classifying	B-RESEARCH_PROBLEM
semantic	I-RESEARCH_PROBLEM
relations	I-RESEARCH_PROBLEM
between	I-RESEARCH_PROBLEM
entity	I-RESEARCH_PROBLEM
pairs	I-RESEARCH_PROBLEM
in	I-RESEARCH_PROBLEM
sentences	E-RESEARCH_PROBLEM
is	O
an	O
important	O
task	O
in	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
.	O
Most	O
previous	O
models	O
for	O
relation	O
classification	O
rely	O
on	O
the	O
high	O
-	O
level	O
lexical	O
and	O
syntatic	O
features	O
obtained	O
by	O
NLP	O
tools	O
such	O
as	O
WordNet	O
,	O
dependency	O
parser	O
,	O
part	O
-	O
ofspeech	O
(	O
POS	O
)	O
tagger	O
,	O
and	O
named	O
entity	O
recognizers	O
(	O
NER	O
)	O
.	O
In	O
addition	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
models	O
based	O
on	O
attention	O
mechanisms	O
do	O
not	O
fully	O
utilize	O
information	O
of	O
entity	O
that	O
maybe	O
the	O
most	O
crucial	O
features	O
for	O
relation	O
classification	O
.	O
To	O
address	O
these	O
issues	O
,	O
we	O
propose	O
a	O
novel	O
end	O
-	O
to	O
-	O
end	O
recurrent	O
neural	O
model	O
which	O
incorporates	O
an	O
entity	O
-	O
aware	O
attention	O
mechanism	O
with	O
a	O
latent	O
entity	O
typing	O
(	O
LET	O
)	O
method	O
.	O
Our	O
model	O
not	O
only	O
utilizes	O
entities	O
and	O
their	O
latent	O
types	O
as	O
features	O
effectively	O
but	O
also	O
is	O
more	O
interpretable	O
by	O
visualizing	O
attention	O
mechanisms	O
applied	O
to	O
our	O
model	O
and	O
results	O
of	O
LET	O
.	O
Experimental	O
results	O
on	O
the	O
SemEval	O
-	O
2010	O
Task	O
8	O
,	O
one	O
of	O
the	O
most	O
popular	O
relation	O
classification	O
task	O
,	O
demonstrate	O
that	O
our	O
model	O
outperforms	O
existing	O
state	O
-	O
of	O
the	O
-	O
art	O
models	O
without	O
any	O
high	O
-	O
level	O
features	O
.	O

Motivation	O
:	O
Biomedical	O
text	O
mining	O
is	O
becoming	O
increasingly	O
important	O
as	O
the	O
number	O
of	O
biomedical	O
documents	O
rapidly	O
grows	O
.	O
With	O
the	O
progress	O
in	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
,	O
extracting	B-RESEARCH_PROBLEM
valuable	I-RESEARCH_PROBLEM
information	I-RESEARCH_PROBLEM
from	I-RESEARCH_PROBLEM
biomedical	I-RESEARCH_PROBLEM
literature	E-RESEARCH_PROBLEM
has	O
gained	O
popularity	O
among	O
researchers	O
,	O
and	O
deep	O
learning	O
has	O
boosted	O
the	O
development	O
of	O
effective	O
biomedical	O
text	O
mining	O
models	O
.	O
However	O
,	O
directly	O
applying	O
the	O
advancements	O
in	O
NLP	O
to	O
biomedical	B-RESEARCH_PROBLEM
text	I-RESEARCH_PROBLEM
mining	I-RESEARCH_PROBLEM
often	I-RESEARCH_PROBLEM
yields	I-RESEARCH_PROBLEM
unsatisfactory	I-RESEARCH_PROBLEM
results	I-RESEARCH_PROBLEM
due	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
a	I-RESEARCH_PROBLEM
word	I-RESEARCH_PROBLEM
distribution	I-RESEARCH_PROBLEM
shift	I-RESEARCH_PROBLEM
from	I-RESEARCH_PROBLEM
general	I-RESEARCH_PROBLEM
domain	I-RESEARCH_PROBLEM
corpora	I-RESEARCH_PROBLEM
to	I-RESEARCH_PROBLEM
biomedical	I-RESEARCH_PROBLEM
corpora	E-RESEARCH_PROBLEM
.	O
In	O
this	O
article	O
,	O
we	O
investigate	O
how	O
the	O
recently	O
introduced	O
pre-trained	B-RESEARCH_PROBLEM
language	I-RESEARCH_PROBLEM
model	I-RESEARCH_PROBLEM
BERT	I-RESEARCH_PROBLEM
can	I-RESEARCH_PROBLEM
be	I-RESEARCH_PROBLEM
adapted	I-RESEARCH_PROBLEM
for	I-RESEARCH_PROBLEM
biomedical	I-RESEARCH_PROBLEM
corpora	E-RESEARCH_PROBLEM
.	O
Results	O
:	O
We	O
introduce	O
BioBERT	O
(	O
Bidirectional	O
Encoder	O
Representations	O
from	O
Transformers	O
for	O
Biomedical	O
Text	O
Mining	O
)	O
,	O
which	O
is	O
a	O
domain	O
-	O
specific	O
language	O
representation	O
model	O
pre-trained	O
on	O
large	O
-	O
scale	O
biomedical	O
corpora	O
.	O

The	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
solutions	O
for	O
extracting	B-RESEARCH_PROBLEM
multiple	I-RESEARCH_PROBLEM
entity	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
relations	I-RESEARCH_PROBLEM
from	I-RESEARCH_PROBLEM
an	I-RESEARCH_PROBLEM
input	I-RESEARCH_PROBLEM
paragraph	E-RESEARCH_PROBLEM
always	O
require	O
a	O
multiple	O
-	O
pass	O
encoding	O
on	O
the	O
input	O
.	O
This	O
paper	O
proposes	O
a	O
new	O
solution	O
that	O
can	O
complete	O
the	O
multiple	B-RESEARCH_PROBLEM
entityrelations	I-RESEARCH_PROBLEM
extraction	I-RESEARCH_PROBLEM
task	I-RESEARCH_PROBLEM
with	I-RESEARCH_PROBLEM
only	I-RESEARCH_PROBLEM
one	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
pass	E-RESEARCH_PROBLEM
encoding	O
on	O
the	O
input	O
corpus	O
,	O
and	O
achieve	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	O
performance	O
,	O
as	O
demonstrated	O
in	O
the	O
ACE	O
2005	O
benchmark	O
.	O
Our	O
solution	O
is	O
built	O
on	O
top	O
of	O
the	O
pre-trained	O
self	O
-	O
attentive	O
models	O
(	O
Transformer	O
)	O
.	O
Since	O
our	O
method	O
uses	O
a	O
single	O
-	O
pass	O
to	O
compute	O
all	O
relations	O
at	O
once	O
,	O
it	O
scales	O
to	O
larger	O
datasets	O
easily	O
;	O
which	O
makes	O
it	O
more	O
usable	O
in	O
real	O
-	O
world	O
applications	O
.	O
1	O

Obtaining	B-RESEARCH_PROBLEM
large	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
scale	I-RESEARCH_PROBLEM
annotated	I-RESEARCH_PROBLEM
data	I-RESEARCH_PROBLEM
for	I-RESEARCH_PROBLEM
NLP	I-RESEARCH_PROBLEM
tasks	I-RESEARCH_PROBLEM
in	I-RESEARCH_PROBLEM
the	I-RESEARCH_PROBLEM
scientific	I-RESEARCH_PROBLEM
domain	E-RESEARCH_PROBLEM
is	O
challenging	O
and	O
expensive	O
.	O
We	O
release	O
SCIBERT	O
,	O
a	O
pretrained	O
language	O
model	O
based	O
on	O
BERT	O
(	O
Devlin	O
et	O
al.	O
,	O
2019	O
)	O
to	O
address	B-RESEARCH_PROBLEM
the	I-RESEARCH_PROBLEM
lack	I-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
high	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
quality	I-RESEARCH_PROBLEM
,	I-RESEARCH_PROBLEM
large	I-RESEARCH_PROBLEM
-	I-RESEARCH_PROBLEM
scale	I-RESEARCH_PROBLEM
labeled	I-RESEARCH_PROBLEM
scientific	I-RESEARCH_PROBLEM
data	E-RESEARCH_PROBLEM
.	O
SCIBERT	O
leverages	O
unsupervised	O
pretraining	O
on	O
a	O
large	O
multi-domain	O
corpus	O
of	O
scientific	O
publications	O
to	O
improve	O
performance	O
on	O
downstream	O
scientific	O
NLP	O
tasks	O
.	O
We	O
evaluate	O
on	O
a	O
suite	O
of	O
tasks	O
including	O
sequence	O
tagging	O
,	O
sentence	O
classification	O
and	O
dependency	O
parsing	O
,	O
with	O
datasets	O
from	O
a	O
variety	O
of	O
scientific	O
domains	O
.	O
We	O
demonstrate	O
statistically	O
significant	O
improvements	O
over	O
BERT	O
and	O
achieve	O
new	O
state	O
-	O
of	O
-	O
theart	O
results	O
on	O
several	O
of	O
these	O
tasks	O
.	O
The	O
code	O
and	O
pretrained	O
models	O
are	O
available	O
at	O
https://github.com/allenai/scibert/.	O

One	O
-	O
hot	O
CNN	O
(	O
convolutional	O
neural	O
network	O
)	O
has	O
been	O
shown	O
to	O
be	O
effective	O
for	O
text	B-RESEARCH_PROBLEM
categorization	E-RESEARCH_PROBLEM
(	O
Johnson	O
&	O
Zhang	O
,	O
2015a	O
;	O
b	O
)	O
.	O
We	O
view	O
it	O
as	O
a	O
special	O
case	O
of	O
a	O
general	O
framework	O
which	O
jointly	O
trains	O
a	O
linear	O
model	O
with	O
a	O
non-linear	O
feature	O
generator	O
consisting	O
of	O
'	O
text	O
region	O
embedding	O
+	O
pooling	O
'	O
.	O
Under	O
this	O
framework	O
,	O
we	O
explore	O
a	O
more	O
sophisticated	O
region	O
embedding	O
method	O
using	O
Long	O
Short	O
-	O
Term	O
Memory	O
(	O
LSTM	O
)	O
.	O
LSTM	O
can	O
embed	O
text	O
regions	O
of	O
variable	O
(	O
and	O
possibly	O
large	O
)	O
sizes	O
,	O
whereas	O
the	O
region	O
size	O
needs	O
to	O
be	O
fixed	O
in	O
a	O
CNN	O
.	O
We	O
seek	O
effective	O
and	O
efficient	O
use	O
of	O
LSTM	O
for	O
this	O
purpose	O
in	O
the	O
supervised	O
and	O
semi-supervised	O
settings	O
.	O
The	O
best	O
results	O
were	O
obtained	O
by	O
combining	O
region	O
embeddings	O
in	O
the	O
form	O
of	O
LSTM	O
and	O
convolution	O
layers	O
trained	O
on	O
unlabeled	O
data	O
.	O
The	O
results	O
indicate	O
that	O
on	O
this	O
task	O
,	O
embeddings	O
of	O
text	O
regions	O
,	O
which	O
can	O
convey	O
complex	O
concepts	O
,	O
are	O
more	O
useful	O
than	O
embeddings	O
of	O
single	O
words	O
in	O
isolation	O
.	O

This	O
paper	O
explores	O
a	O
simple	O
and	O
efficient	O
baseline	O
for	O
text	B-RESEARCH_PROBLEM
classification	E-RESEARCH_PROBLEM
.	O
Our	O
experiments	O
show	O
that	O
our	O
fast	O
text	O
classifier	O
fastText	O
is	O
often	O
on	O
par	O
with	O
deep	O
learning	O
classifiers	O
in	O
terms	O
of	O
accuracy	O
,	O
and	O
many	O
orders	O
of	O
magnitude	O
faster	O
for	O
training	O
and	O
evaluation	O
.	O
We	O
can	O
train	O
fastText	O
on	O
more	O
than	O
one	O
billion	O
words	O
in	O
less	O
than	O
ten	O
minutes	O
using	O
a	O
standard	O
multicore	O
CPU	O
,	O
and	O
classify	O
half	O
a	O
million	O
sentences	O
among	O
312K	O
classes	O
in	O
less	O
than	O
a	O
minute	O
.	O

Text	B-RESEARCH_PROBLEM
preprocessing	E-RESEARCH_PROBLEM
is	O
often	O
the	O
first	O
step	O
in	O
the	O
pipeline	O
of	O
a	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
system	O
,	O
with	O
potential	O
impact	O
in	O
its	O
final	O
performance	O
.	O
Despite	O
its	O
importance	O
,	O
text	O
preprocessing	O
has	O
not	O
received	O
much	O
attention	O
in	O
the	O
deep	O
learning	O
literature	O
.	O
In	O
this	O
paper	O
we	O
investigate	O
the	O
impact	O
of	O
simple	O
text	O
preprocessing	O
decisions	O
(	O
particularly	O
tokenizing	O
,	O
lemmatizing	O
,	O
lowercasing	O
and	O
multiword	O
grouping	O
)	O
on	O
the	O
performance	O
of	O
a	O
standard	O
neural	O
text	O
classifier	O
.	O
We	O
perform	O
an	O
extensive	O
evaluation	O
on	O
standard	O
benchmarks	O
from	O
text	O
categorization	O
and	O
sentiment	O
analysis	O
.	O
While	O
our	O
experiments	O
show	O
that	O
a	O
simple	O
tokenization	O
of	O
input	O
text	O
is	O
generally	O
adequate	O
,	O
they	O
also	O
highlight	O
significant	O
degrees	O
of	O
variability	O
across	O
preprocessing	O
techniques	O
.	O
This	O
reveals	O
the	O
importance	O
of	O
paying	O
attention	O
to	O
this	O
usually	O
-	O
overlooked	O
step	O
in	O
the	O
pipeline	O
,	O
particularly	O
when	O
comparing	O
different	O
models	O
.	O
Finally	O
,	O
our	O
evaluation	O
provides	O
insights	O
into	O
the	O
best	O
preprocessing	O
practices	O
for	O
training	O
word	O
embeddings	O
.	O

Convolutional	O
neural	O
networks	O
(	O
CNNs	O
)	O
have	O
recently	O
emerged	O
as	O
a	O
popular	O
building	O
block	O
for	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
.	O
Despite	O
their	O
success	O
,	O
most	O
existing	O
CNN	O
models	O
employed	O
in	O
NLP	O
share	O
the	O
same	O
learned	O
(	O
and	O
static	O
)	O
set	O
of	O
filters	O
for	O
all	O
input	O
sentences	O
.	O
In	O
this	O
paper	O
,	O
we	O
consider	O
an	O
approach	O
of	O
using	O
a	O
small	O
meta	O
network	O
to	O
learn	B-RESEARCH_PROBLEM
contextsensitive	I-RESEARCH_PROBLEM
convolutional	I-RESEARCH_PROBLEM
filters	I-RESEARCH_PROBLEM
for	I-RESEARCH_PROBLEM
text	I-RESEARCH_PROBLEM
processing	E-RESEARCH_PROBLEM
.	O
The	O
role	O
of	O
meta	O
network	O
is	O
to	O
abstract	O
the	O
contextual	O
information	O
of	O
a	O
sentence	O
or	O
document	O
into	O
a	O
set	O
of	O
input	O
-aware	O
filters	O
.	O
We	O
further	O
generalize	O
this	O
framework	O
to	O
model	O
sentence	O
pairs	O
,	O
where	O
a	O
bidirectional	O
filter	O
generation	O
mechanism	O
is	O
introduced	O
to	O
encapsulate	O
co-dependent	O
sentence	O
representations	O
.	O
In	O
our	O
benchmarks	O
on	O
four	O
different	O
tasks	O
,	O
including	O
ontology	O
classification	O
,	O
sentiment	O
analysis	O
,	O
answer	O
sentence	O
selection	O
,	O
and	O
paraphrase	O
identification	O
,	O
our	O
proposed	O
model	O
,	O
a	O
modified	O
CNN	O
with	O
context	O
-	O
sensitive	O
filters	O
,	O
consistently	O
outperforms	O
the	O
standard	O
CNN	O
and	O
attention	O
-	O
based	O
CNN	O
baselines	O
.	O
By	O
visualizing	O
the	O
learned	O
context	O
-	O
sensitive	O
filters	O
,	O
we	O
further	O
validate	O
and	O
rationalize	O
the	O
effectiveness	O
of	O
proposed	O
framework	O
.	O

We	O
present	O
models	O
for	O
encoding	B-RESEARCH_PROBLEM
sentences	I-RESEARCH_PROBLEM
into	I-RESEARCH_PROBLEM
embedding	I-RESEARCH_PROBLEM
vectors	I-RESEARCH_PROBLEM
that	I-RESEARCH_PROBLEM
specifically	I-RESEARCH_PROBLEM
target	I-RESEARCH_PROBLEM
transfer	I-RESEARCH_PROBLEM
learning	E-RESEARCH_PROBLEM
to	O
other	O
NLP	O
tasks	O
.	O
The	O
models	O
are	O
efficient	O
and	O
result	O
in	O
accurate	O
performance	O
on	O
diverse	O
transfer	O
tasks	O
.	O
Two	O
variants	O
of	O
the	O
encoding	O
models	O
allow	O
for	O
trade	O
-	O
offs	O
between	O
accuracy	O
and	O
compute	O
resources	O
.	O
For	O
both	O
variants	O
,	O
we	O
investigate	O
and	O
report	O
the	O
relationship	O
between	O
model	O
complexity	O
,	O
resource	O
consumption	O
,	O
the	O
availability	O
of	O
transfer	O
task	O
training	O
data	O
,	O
and	O
task	O
performance	O
.	O
Comparisons	O
are	O
made	O
with	O
baselines	O
that	O
use	O
word	O
level	O
transfer	O
learning	O
via	O
pretrained	O
word	O
embeddings	O
as	O
well	O
as	O
baselines	O
do	O
not	O
use	O
any	O
transfer	O
learning	O
.	O
We	O
find	O
that	O
transfer	B-RESEARCH_PROBLEM
learning	I-RESEARCH_PROBLEM
using	I-RESEARCH_PROBLEM
sentence	I-RESEARCH_PROBLEM
embeddings	E-RESEARCH_PROBLEM
tends	O
to	O
outperform	O
word	O
level	O
transfer	O
.	O
With	O
transfer	B-RESEARCH_PROBLEM
learning	I-RESEARCH_PROBLEM
via	I-RESEARCH_PROBLEM
sentence	I-RESEARCH_PROBLEM
embeddings	E-RESEARCH_PROBLEM
,	O
we	O
observe	O
surprisingly	O
good	O
performance	O
with	O
minimal	O
amounts	O
of	O
supervised	O
training	O
data	O
for	O
a	O
transfer	O
task	O
.	O

Many	O
deep	O
learning	O
architectures	O
have	O
been	O
proposed	O
to	O
model	B-RESEARCH_PROBLEM
the	I-RESEARCH_PROBLEM
compositionality	I-RESEARCH_PROBLEM
in	I-RESEARCH_PROBLEM
text	I-RESEARCH_PROBLEM
sequences	E-RESEARCH_PROBLEM
,	O
requiring	O
a	O
substantial	O
number	O
of	O
parameters	O
and	O
expensive	O
computations	O
.	O
However	O
,	O
there	O
has	O
not	O
been	O
a	O
rigorous	O
evaluation	O
regarding	O
the	O
added	O
value	O
of	O
sophisticated	O
compositional	O
functions	O
.	O
In	O
this	O
paper	O
,	O
we	O
conduct	O
a	O
point	O
-	O
by	O
-	O
point	O
comparative	O
study	O
between	O
Simple	O
Word	O
-	O
Embeddingbased	O
Models	O
(	O
SWEMs	O
)	O
,	O
consisting	O
of	O
parameter	O
-	O
free	O
pooling	O
operations	O
,	O
relative	O
to	O
word	O
-	O
embedding	O
-	O
based	O
RNN	O
/	O
CNN	O
models	O
.	O
Surprisingly	O
,	O
SWEMs	O
exhibit	O
comparable	O
or	O
even	O
superior	O
performance	O
in	O
the	O
majority	O
of	O
cases	O
considered	O
.	O
Based	O
upon	O
this	O
understanding	O
,	O
we	O
propose	O
two	O
additional	O
pooling	O
strategies	O
over	O
learned	O
word	O
embeddings	O
:	O
(	O
i	O
)	O
a	O
max	O
-	O
pooling	O
operation	O
for	O
improved	O
interpretability	O
;	O
and	O
(	O
ii	O
)	O
a	O
hierarchical	O
pooling	O
operation	O
,	O
which	O
preserves	O
spatial	O
(	O
n	O
-	O
gram	O
)	O
information	O
within	O
text	O
sequences	O
.	O
We	O
present	O
experiments	O
on	O
17	O
datasets	O
encompassing	O
three	O
tasks	O
:	O
(	O
i	O
)	O
(	O
long	O
)	O
document	O
classification	O
;	O
(	O
ii	O
)	O
text	O
sequence	O
matching	O
;	O
and	O
(	O
iii	O
)	O
short	O
text	O
tasks	O
,	O
including	O
classification	O
and	O
tagging	O
.	O
The	O
source	O
code	O
and	O
datasets	O
can	O
be	O
obtained	O
from	O
https://github.com/dinghanshen/SWEM	O
.	O

Spoken	B-RESEARCH_PROBLEM
Language	I-RESEARCH_PROBLEM
Understanding	E-RESEARCH_PROBLEM
(SLU)	O
systems	O
parse	O
speech	O
into	O
semantic	O
structures	O
like	O
dialog	O
acts	O
and	O
slots.	O
This	O
involves	O
the	O
use	O
of	O
an	O
Automatic	O
Speech	O
Recognizer	O
(ASR)	O
to	O
transcribe	O
speech	O
into	O
multiple	O
text	O
alternatives	O
(hypotheses).	O
Transcription	O
errors,	O
common	O
in	O
ASRs,	O
impact	O
downstream	O
SLU	O
performance	O
negatively.	O
Approaches	O
to	O
mitigate	O
such	O
errors	O
involve	O
using	O
richer	O
information	O
from	O
the	O
ASR,	O
either	O
in	O
form	O
of	O
N-best	O
hypotheses	O
or	O
word-lattices.	O
We	O
hypothesize	O
that	O
transformer	O
models	O
learn	O
better	O
with	O
a	O
simpler	O
utterance	O
representation	O
using	O
the	O
concatenation	O
of	O
the	O
N-best	O
ASR	O
alternatives,	O
where	O
each	O
alternative	O
is	O
separated	O
by	O
a	O
special	O
delimiter	O
[SEP].	O
In	O
our	O
work,	O
we	O
test	O
our	O
hypothesis	O
by	O
using	O
concatenated	O
N-best	O
ASR	O
alternatives	O
as	O
the	O
input	O
to	O
transformer	O
encoder	O
models,	O
namely	O
BERT	O
and	O
XLM-RoBERT	O
a,	O
and	O
achieve	O
performance	O
equivalent	O
to	O
the	O
prior	O
state-of-the-art	O
model	O
on	O
DSTC2	O
dataset.	O
We	O
also	O
show	O
that	O
our	O
approach	O
significantly	O
outperforms	O
the	O
prior	O
state-of-the-art	O
when	O
subjected	O
to	O
the	O
low	O
data	O
regime.	O
Additionally,	O
this	O
methodology	O
is	O
accessible	O
to	O
users	O
of	O
third-party	O
ASR	O
APIs	O
which	O
do	O
not	O
provide	O
word-lattice	O
information.	O

Question	B-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
(QA)	O
is	O
a	O
task	O
in	O
natural	O
language	O
processing	O
that	O
has	O
seen	O
considerable	O
growth	O
after	O
the	O
advent	O
of	O
transformers.	O
There	O
has	O
been	O
a	O
surge	O
in	O
QA	O
datasets	O
that	O
have	O
been	O
proposed	O
to	O
challenge	O
natural	O
language	O
processing	O
models	O
to	O
improve	O
human	O
and	O
existing	O
model	O
performance.	O
Many	O
pre-trained	O
language	O
models	O
have	O
proven	O
to	O
be	O
incredibly	O
effective	O
at	O
the	O
task	O
of	O
extractive	O
question	O
answering.	O
However,	O
generalizability	O
remains	O
as	O
a	O
challenge	O
for	O
the	O
majority	O
of	O
these	O
models.	O
That	O
is,	O
some	O
datasets	O
require	O
models	O
to	O
reason	O
more	O
than	O
others.	O
In	O
this	O
paper,	O
we	O
train	O
various	O
pre-trained	O
language	O
models	O
and	O
fine-tune	O
them	O
on	O
multiple	O
question	O
answering	O
datasets	O
of	O
varying	O
levels	O
of	O
difficulty	O
to	O
determine	O
which	O
of	O
the	O
models	O
are	O
capable	O
of	O
generalizing	O
the	O
most	O
comprehensively	O
across	O
different	O
datasets.	O
Further,	O
we	O
propose	O
a	O
new	O
architecture,	O
BERT-BiLSTM,	O
and	O
compare	O
it	O
with	O
other	O
language	O
models	O
to	O
determine	O
if	O
adding	O
more	O
bidirectionality	O
can	O
improve	O
model	O
performance.	O
Using	O
the	O
F1-score	O
as	O
our	O
metric,	O
we	O
find	O
that	O
the	O
RoBERTa	O
and	O
BART	O
pre-trained	O
models	O
perform	O
the	O
best	O
across	O
all	O
datasets	O
and	O
that	O
our	O
BERT-BiLSTM	O
model	O
outperforms	O
the	O
baseline	O
BERT	O
model.	O

Optimal	O
trade	O
execution	O
is	O
an	O
important	O
problem	O
faced	O
by	O
essentially	O
all	O
traders.	O
Much	O
research	O
into	O
optimal	O
execution	O
uses	O
stringent	O
model	O
assumptions	O
and	O
applies	O
continuous	O
time	O
stochastic	O
control	O
to	O
solve	O
them.	O
Here,	O
we	O
instead	O
take	O
a	O
model	O
free	O
approach	O
and	O
develop	O
a	O
variation	O
of	O
Deep	O
Q-Learning	S-RESEARCH_PROBLEM
to	O
estimate	O
the	O
optimal	O
actions	O
of	O
a	O
trader.	O
The	O
model	O
is	O
a	O
fully	O
connected	O
Neural	O
Network	O
trained	O
using	O
Experience	O
Replay	O
and	O
Double	O
DQN	O
with	O
input	O
features	O
given	O
by	O
the	O
current	O
state	O
of	O
the	O
limit	O
order	O
book,	O
other	O
trading	O
signals,	O
and	O
available	O
execution	O
actions,	O
while	O
the	O
output	O
is	O
the	O
Q-value	O
function	O
estimating	O
the	O
future	O
rewards	O
under	O
an	O
arbitrary	O
action.	O
We	O
apply	O
our	O
model	O
to	O
nine	O
different	O
stocks	O
and	O
find	O
that	O
it	O
outperforms	O
the	O
standard	O
benchmark	O
approach	O
on	O
most	O
stocks	O
using	O
the	O
measures	O
of	O
(i)	O
mean	O
and	O
median	O
out-performance,	O
(ii)	O
probability	O
of	O
out-performance,	O
and	O
(iii)	O
gain-loss	O
ratios.	O

Automatic	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(ASR)	O
robustness	O
toward	O
slot	O
entities	O
are	O
critical	O
in	O
e-commerce	O
voice	O
assistants	O
that	O
involve	O
monetary	O
transactions	O
and	O
purchases.	O
Along	O
with	O
effective	O
domain	O
adaptation,	O
it	O
is	O
intuitive	O
that	O
cross	O
utterance	O
contextual	O
cues	O
play	O
an	O
important	O
role	O
in	O
disambiguating	O
domain	O
specific	O
content	O
words	O
from	O
speech.	O
In	O
this	O
paper,	O
we	O
investigate	O
various	O
techniques	O
to	O
improve	O
contextualization,	O
content	O
word	O
robustness	O
and	O
domain	O
adaptation	O
of	O
a	O
Transformer-XL	O
neural	O
language	O
model	O
(NLM)	O
to	O
rescore	O
ASR	O
N-best	O
hypotheses.	O
To	O
improve	O
contextualization,	O
we	O
utilize	O
turn	O
level	O
dialogue	O
acts	O
along	O
with	O
cross	O
utterance	O
context	O
carry	O
over.	O
Additionally,	O
to	O
adapt	O
our	O
domain-general	O
NLM	O
towards	O
e-commerce	O
on-the-fly,	O
we	O
use	O
embeddings	O
derived	O
from	O
a	O
finetuned	O
masked	O
LM	O
on	O
in-domain	O
data.	O
Finally,	O
to	O
improve	O
robustness	O
towards	O
in-domain	O
content	O
words,	O
we	O
propose	O
a	O
multi-task	O
model	O
that	O
can	O
jointly	O
perform	O
content	O
word	O
detection	O
and	O
language	O
modeling	O
tasks.	O
Compared	O
to	O
a	O
non-contextual	O
LSTM	O
LM	O
baseline,	O
our	O
best	O
performing	O
NLM	O
rescorer	O
results	O
in	O
a	O
content	O
WER	O
reduction	O
of	O
19.2%	O
on	O
e-commerce	O
audio	O
test	O
set	O
and	O
a	O
slot	O
labeling	O
F1	O
improvement	O
of	O
6.4%.	O

Key	O
properties	O
of	O
brain-inspired	O
hyperdimensional	O
(HD)	O
computing	O
make	O
it	O
aprime	O
candidate	O
for	O
energy-efficient	O
and	O
fast	O
learning	O
in	O
biosignal	O
processing.The	O
main	O
challenge	O
is	O
however	O
to	O
formulate	O
embedding	O
methods	O
that	O
map	O
biosignalmeasures	O
to	O
a	O
binary	O
HD	O
space.	O
In	O
this	O
paper,	O
we	O
explore	O
variety	O
of	O
suchembedding	O
methods	O
and	O
examine	O
them	O
with	O
a	O
challenging	O
application	O
of	O
motorimagery	O
brain-computer	O
interface	O
(MI-BCI)	O
from	O
electroencephalography	O
(EEG	S-RESEARCH_PROBLEM
)recordings.	O
We	O
explore	O
embedding	O
methods	O
including	O
random	O
projections,quantization	O
based	O
thermometer	O
and	O
Gray	O
coding,	O
and	O
learning	O
HD	O
representationsusing	O
end-to-end	O
training.	O
All	O
these	O
methods,	O
differing	O
in	O
complexity,	O
aim	O
torepresent	O
EEG	S-RESEARCH_PROBLEM
signals	O
in	O
binary	O
HD	O
space,	O
e.g.	O
with	O
10,000	O
bits.	O
This	O
leads	O
todevelopment	O
of	O
a	O
set	O
of	O
HD	O
learning	O
and	O
classification	O
methods	O
that	O
can	O
beselectively	O
chosen	O
(or	O
configured)	O
based	O
on	O
accuracy	O
and/or	O
computationalcomplexity	O
requirements	O
of	O
a	O
given	O
task.	O
We	O
compare	O
them	O
with	O
state-of-the-artlinear	O
support	O
vector	O
machine	O
(SVM	O
)	O
on	O
an	O
NVIDIA	O
TX2	O
board	O
using	O
the	O
4-classBCI	O
competition	O
IV-2a	O
dataset	O
as	O
well	O
as	O
a	O
new	O
3-class	O
dataset.	O
Compared	O
toSVM	O
,	O
results	O
on	O
3-class	O
dataset	O
show	O
that	O
simple	O
thermometer	O
embedding	O
achievesmoderate	O
average	O
accuracy	O
(79.56%	O
vs.	O
82.67%)	O
with	O
26.8$\times$	O
faster	O
trainingtime	O
and	O
22.3$\times$	O
lower	O
energy;	O
on	O
the	O
other	O
hand,	O
switching	O
to	O
end-to-endtraining	O
with	O
learned	O
HD	O
representations	O
wipes	O
out	O
these	O
training	O
benefitswhile	O
boosting	O
the	O
accuracy	O
to	O
84.22%	O
(1.55%	O
higher	O
than	O
SVM	O
).	O
Similar	O
trend	O
isobserved	O
on	O
the	O
4-class	O
dataset	O
where	O
SVM	O
achieves	O
on	O
average	O
74.29%:	O
thethermometer	O
embedding	O
achieves	O
89.9$\times$	O
faster	O
training	O
time	O
and58.7$\times$	O
lower	O
energy,	O
but	O
a	O
lower	O
accuracy	O
(67.09%)	O
than	O
the	O
learnedrepresentation	O
of	O
72.54%.	O

The	O
Dynamical	O
Gaussian	O
Process	O
Latent	B-RESEARCH_PROBLEM
Variable	I-RESEARCH_PROBLEM
Models	E-RESEARCH_PROBLEM
provide	O
an	O
elegant	O
non-parametric	O
framework	O
for	O
learning	O
the	O
low	O
dimensional	O
representations	O
of	O
the	O
high-dimensional	O
time-series.	O
Real	O
world	O
observational	O
studies,	O
however,	O
are	O
often	O
ill-conditioned:	O
the	O
observations	O
can	O
be	O
noisy,	O
not	O
assuming	O
the	O
luxury	O
of	O
relatively	O
complete	O
and	O
equally	O
spaced	O
like	O
those	O
in	O
time	O
series.	O
Such	O
conditions	O
make	O
it	O
difficult	O
to	O
learn	O
reasonable	O
representations	O
in	O
the	O
high	O
dimensional	O
longitudinal	O
data	O
set	O
by	O
way	O
of	O
Gaussian	O
Process	O
Latent	O
Variable	O
Model	O
as	O
well	O
as	O
other	O
dimensionality	O
reduction	O
procedures.	O
In	O
this	O
study,	O
we	O
approach	O
the	O
inference	O
of	O
Gaussian	O
Process	O
Dynamical	O
Systems	O
in	O
Longitudinal	O
scenario	O
by	O
augmenting	O
the	O
bound	O
in	O
the	O
variational	O
approximation	O
to	O
include	O
systematic	O
samples	O
of	O
the	O
unseen	O
observations.	O
We	O
demonstrate	O
the	O
usefulness	O
of	O
this	O
approach	O
on	O
synthetic	O
as	O
well	O
as	O
the	O
human	O
motion	O
capture	O
data	O
set.	O

With	O
the	O
recent	O
success	O
of	O
Recurrent	O
Neural	O
Networks	O
(RNNs)	O
in	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(MT),	O
attention	O
mechanisms	O
have	O
become	O
increasingly	O
popular.	O
The	O
purpose	O
of	O
this	O
paper	O
is	O
two-fold;	O
firstly,	O
we	O
propose	O
a	O
novel	O
attention	O
model	O
on	O
Tree	O
Long	O
Short-Term	O
Memory	O
Networks	O
(Tree-LSTM	O
s),	O
a	O
tree-structured	O
generalization	O
of	O
standard	O
LSTM	O
.	O
Secondly,	O
we	O
study	O
the	O
interaction	O
between	O
attention	O
and	O
syntactic	O
structures,	O
by	O
experimenting	O
with	O
three	O
LSTM	O
variants:	O
bidirectional-LSTM	O
s,	O
Constituency	O
Tree-LSTM	O
s,	O
and	O
Dependency	O
Tree-LSTM	O
s.	O
Our	O
models	O
are	O
evaluated	O
on	O
two	O
semantic	O
relatedness	O
tasks:	O
semantic	O
relatedness	O
scoring	O
for	O
sentence	O
pairs	O
(SemEval	O
2012,	O
Task	O
6	O
and	O
SemEval	O
2014,	O
Task	O
1)	O
and	O
paraphrase	O
detection	O
for	O
question	O
pairs	O
(Quora,	O
2017).	O

This	O
paper	O
studies	O
video	O
inpainting	O
detection,	O
which	O
localizes	O
an	O
inpainted	O
region	O
in	O
a	O
video	O
both	O
spatially	O
and	O
temporally.	O
In	O
particular,	O
we	O
introduce	O
VIDNet,	O
Video	B-RESEARCH_PROBLEM
Inpainting	E-RESEARCH_PROBLEM
Detection	O
Network,	O
which	O
contains	O
a	O
two-stream	O
encoder-decoder	O
architecture	O
with	O
attention	O
module.	O
To	O
reveal	O
artifacts	O
encoded	O
in	O
compression,	O
VIDNet	O
additionally	O
takes	O
in	O
Error	O
Level	O
Analysis	O
frames	O
to	O
augment	O
RGB	O
frames,	O
producing	O
multimodal	O
features	O
at	O
different	O
levels	O
with	O
an	O
encoder.	O
Exploring	O
spatial	O
and	O
temporal	O
relationships,	O
these	O
features	O
are	O
further	O
decoded	O
by	O
a	O
Convolutional	O
LSTM	O
to	O
predict	O
masks	O
of	O
inpainted	O
regions.	O
In	O
addition,	O
when	O
detecting	O
whether	O
a	O
pixel	O
is	O
inpainted	O
or	O
not,	O
we	O
present	O
a	O
quad-directional	O
local	O
attention	O
module	O
that	O
borrows	O
information	O
from	O
its	O
surrounding	O
pixels	O
from	O
four	O
directions.	O
Extensive	O
experiments	O
are	O
conducted	O
to	O
validate	O
our	O
approach.	O
We	O
demonstrate,	O
among	O
other	O
things,	O
that	O
VIDNet	O
not	O
only	O
outperforms	O
by	O
clear	O
margins	O
alternative	O
inpainting	O
detection	O
methods	O
but	O
also	O
generalizes	O
well	O
on	O
novel	O
videos	O
that	O
are	O
unseen	O
during	O
training.	O

Human	B-RESEARCH_PROBLEM
motion	I-RESEARCH_PROBLEM
prediction	E-RESEARCH_PROBLEM
aims	O
to	O
generate	O
future	O
motions	O
based	O
on	O
the	O
observed	O
human	O
motions.	O
Witnessing	O
the	O
success	O
of	O
Recurrent	O
Neural	O
Networks	O
(RNN)	O
in	O
modeling	O
the	O
sequential	O
data,	O
recent	O
works	O
utilize	O
RNN	O
to	O
model	O
human-skeleton	O
motion	O
on	O
the	O
observed	O
motion	O
sequence	O
and	O
predict	O
future	O
human	O
motions.	O
However,	O
these	O
methods	O
did	O
not	O
consider	O
the	O
existence	O
of	O
the	O
spatial	O
coherence	O
among	O
joints	O
and	O
the	O
temporal	O
evolution	O
among	O
skeletons,	O
which	O
reflects	O
the	O
crucial	O
characteristics	O
of	O
human	O
motion	O
in	O
spatiotemporal	O
space.	O
To	O
this	O
end,	O
we	O
propose	O
a	O
novel	O
Skeleton-joint	O
Co-attention	O
Recurrent	O
Neural	O
Networks	O
(SC-RNN)	O
to	O
capture	O
the	O
spatial	O
coherence	O
among	O
joints,	O
and	O
the	O
temporal	O
evolution	O
among	O
skeletons	O
simultaneously	O
on	O
a	O
skeleton-joint	O
co-attention	O
feature	O
map	O
in	O
spatiotemporal	O
space.	O
First,	O
a	O
skeleton-joint	O
feature	O
map	O
is	O
constructed	O
as	O
the	O
representation	O
of	O
the	O
observed	O
motion	O
sequence.	O
Second,	O
we	O
design	O
a	O
new	O
Skeleton-joint	O
Co-Attention	O
(SCA)	O
mechanism	O
to	O
dynamically	O
learn	O
a	O
skeleton-joint	O
co-attention	O
feature	O
map	O
of	O
this	O
skeleton-joint	O
feature	O
map,	O
which	O
can	O
refine	O
the	O
useful	O
observed	O
motion	O
information	O
to	O
predict	O
one	O
future	O
motion.	O
Third,	O
a	O
variant	O
of	O
GRU	O
embedded	O
with	O
SCA	O
collaboratively	O
models	O
the	O
human-skeleton	O
motion	O
and	O
human-joint	O
motion	O
in	O
spatiotemporal	O
space	O
by	O
regarding	O
the	O
skeleton-joint	O
co-attention	O
feature	O
map	O
as	O
the	O
motion	O
context.	O
Experimental	O
results	O
on	O
human	O
motion	O
prediction	O
demonstrate	O
the	O
proposed	O
method	O
outperforms	O
the	O
related	O
methods.	O

Bilevel	O
optimization	O
problems	O
can	O
be	O
used	O
to	O
represent	O
the	O
collaborative	O
interaction	O
between	O
a	O
power	O
system	O
and	O
grid-connected	O
entities,	O
called	O
the	O
followers,	O
such	O
as	O
data	O
centers.	O
Most	O
existing	O
approaches	O
assume	O
that	O
such	O
followers'	O
response	O
behaviors	O
are	O
made	O
available	O
to	O
the	O
power	O
system	O
in	O
the	O
operation	O
decision-making,	O
which	O
may	O
be	O
untenable	O
in	O
reality.	O
This	O
work	O
presents	O
a	O
novel	O
idea	O
of	O
solving	O
bilevel	B-RESEARCH_PROBLEM
optimization	E-RESEARCH_PROBLEM
problems	O
without	O
assuming	O
power	O
systems'	O
omniscience.	O
The	O
followers'	O
responses	O
will	O
be	O
represented	O
by	O
a	O
function	O
of	O
the	O
power	O
system's	O
decisions	O
using	O
Gaussian	O
Process	O
Regression.	O
Then	O
the	O
two	O
layers	O
in	O
the	O
bilevel	O
problem	O
can	O
be	O
solved	O
separately	O
by	O
the	O
power	O
system	O
and	O
its	O
followers.	O
This	O
not	O
only	O
avoids	O
the	O
omniscience	O
assumption,	O
but	O
also	O
significantly	O
increases	O
the	O
computational	O
efficiency	O
without	O
compromising	O
accuracy,	O
especially	O
for	O
the	O
problems	O
with	O
a	O
complex	O
lower	O
layer.	O
Moreover,	O
a	O
bilevel	O
critical	O
load	O
restoration	O
model	O
is	O
developed	O
to	O
test	O
the	O
proposed	O
technique.	O
Compared	O
to	O
the	O
conventional	O
methods,	O
the	O
proposed	O
restoration	O
model	O
considers	O
the	O
load-side	O
operation	O
and	O
the	O
varying	O
load	O
marginal	O
value,	O
and	O
can	O
accurately	O
estimate	O
load-side	O
loss	O
and	O
achieve	O
better	O
restoration	O
solutions.	O
Two	O
case	O
studies	O
validate	O
the	O
advantages	O
of	O
the	O
proposed	O
approaches	O
from	O
different	O
perspectives.	O

In	O
this	O
work,	O
we	O
propose	O
a	O
two-stage	O
method	O
for	O
named	O
entity	O
recognition	O
(NER	S-RESEARCH_PROBLEM
),	O
especially	O
for	O
nested	O
NER	S-RESEARCH_PROBLEM
.	O
We	O
borrowed	O
the	O
idea	O
from	O
the	O
two-stage	O
Object	B-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
in	O
computer	O
vision	O
and	O
the	O
way	O
how	O
they	O
construct	O
the	O
loss	O
function.	O
First,	O
a	O
region	O
proposal	O
network	O
generates	O
region	O
candidates	O
and	O
then	O
a	O
second-stage	O
model	O
discriminates	O
and	O
classifies	O
the	O
entity	O
and	O
makes	O
the	O
final	O
prediction.	O
We	O
also	O
designed	O
a	O
special	O
loss	O
function	O
for	O
the	O
second-stage	O
training	O
that	O
predicts	O
the	O
entityness	O
and	O
entity	O
type	O
at	O
the	O
same	O
time.	O
The	O
model	O
is	O
built	O
on	O
top	O
of	O
pretrained	O
BERT	O
encoders,	O
and	O
we	O
tried	O
both	O
BERT	O
base	O
and	O
BERT	O
large	O
models.	O
For	O
experiments,	O
we	O
first	O
applied	O
it	O
to	O
flat	O
NER	S-RESEARCH_PROBLEM
tasks	O
such	O
as	O
CoNLL2003	O
and	O
OntoNotes	O
5.0	O
and	O
got	O
comparable	O
results	O
with	O
traditional	O
NER	S-RESEARCH_PROBLEM
models	O
using	O
sequence	O
labeling	O
methodology.	O
We	O
then	O
tested	O
the	O
model	O
on	O
the	O
nested	O
named	O
entity	O
recognition	O
task	O
ACE2005	O
and	O
Genia,	O
and	O
got	O
F1	O
score	O
of	O
85.6$\%$	O
and	O
76.8$\%$	O
respectively.	O
In	O
terms	O
of	O
the	O
second-stage	O
training,	O
we	O
found	O
that	O
adding	O
extra	O
randomly	O
selected	O
regions	O
plays	O
an	O
important	O
role	O
in	O
improving	O
the	O
precision.	O
We	O
also	O
did	O
error	O
profiling	O
to	O
better	O
evaluate	O
the	O
performance	O
of	O
the	O
model	O
in	O
different	O
circumstances	O
for	O
potential	O
improvements	O
in	O
the	O
future.	O

End-to-end	O
Automatic	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(ASR)	O
models	O
are	O
commonly	O
trained	O
over	O
spoken	O
utterances	O
using	O
optimization	O
methods	O
like	O
Stochastic	O
Gradient	O
Descent	O
(SGD	O
).	O
In	O
distributed	O
settings	O
like	O
Federated	O
Learning,	O
model	O
training	O
requires	O
transmission	O
of	O
gradients	O
over	O
a	O
network.	O
In	O
this	O
work,	O
we	O
design	O
the	O
first	O
method	O
for	O
revealing	O
the	O
identity	O
of	O
the	O
speaker	O
of	O
a	O
training	O
utterance	O
with	O
access	O
only	O
to	O
a	O
gradient.	O
We	O
propose	O
Hessian-Free	O
Gradients	O
Matching,	O
an	O
input	O
reconstruction	O
technique	O
that	O
operates	O
without	O
second	O
derivatives	O
of	O
the	O
loss	O
function	O
(required	O
in	O
prior	O
works),	O
which	O
can	O
be	O
expensive	O
to	O
compute.	O
We	O
show	O
the	O
effectiveness	O
of	O
our	O
method	O
using	O
the	O
DeepSpeech	O
model	O
architecture,	O
demonstrating	O
that	O
it	O
is	O
possible	O
to	O
reveal	O
the	O
speaker's	O
identity	O
with	O
34%	O
top-1	O
accuracy	O
(51%	O
top-5	O
accuracy)	O
on	O
the	O
LibriSpeech	O
dataset.	O
Further,	O
we	O
study	O
the	O
effect	O
of	O
two	O
well-known	O
techniques,	O
Differentially	O
Private	O
SGD	O
and	O
Dropout,	O
on	O
the	O
success	O
of	O
our	O
method.	O
We	O
show	O
that	O
a	O
dropout	O
rate	O
of	O
0.2	O
can	O
reduce	O
the	O
speaker	O
identity	O
accuracy	O
to	O
0%	O
top-1	O
(0.5%	O
top-5).	O

Biomedical	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER	S-RESEARCH_PROBLEM
)	O
is	O
a	O
challenging	O
problem	O
in	O
biomedical	O
information	O
processing	O
due	O
to	O
the	O
widespread	O
ambiguity	O
of	O
out	O
of	O
context	O
terms	O
and	O
extensive	O
lexical	O
variations.	O
Performance	O
on	O
bioNER	S-RESEARCH_PROBLEM
benchmarks	O
continues	O
to	O
improve	O
due	O
to	O
advances	O
like	O
BERT	O
,	O
GPT,	O
and	O
XLNet.	O
FLAIR	O
(1)	O
is	O
an	O
alternative	O
embedding	O
model	O
which	O
is	O
less	O
computationally	O
intensive	O
than	O
the	O
others	O
mentioned.	O
We	O
test	O
FLAIR	O
and	O
its	O
pretrained	O
PubMed	O
embeddings	O
(which	O
we	O
term	O
BioFLAIR)	O
on	O
a	O
variety	O
of	O
bio	O
NER	S-RESEARCH_PROBLEM
tasks	O
and	O
compare	O
those	O
with	O
results	O
from	O
BERT	O
-type	O
networks.	O
We	O
also	O
investigate	O
the	O
effects	O
of	O
a	O
small	O
amount	O
of	O
additional	O
pretraining	O
on	O
PubMed	O
content,	O
and	O
of	O
combining	O
FLAIR	O
and	O
ELMO	O
models.	O
We	O
find	O
that	O
with	O
the	O
provided	O
embeddings,	O
FLAIR	O
performs	O
on-par	O
with	O
the	O
BERT	O
networks	O
-	O
even	O
establishing	O
a	O
new	O
state	O
of	O
the	O
art	O
on	O
one	O
benchmark.	O
Additional	O
pretraining	O
did	O
not	O
provide	O
a	O
clear	O
benefit,	O
although	O
this	O
might	O
change	O
with	O
even	O
more	O
pretraining	O
being	O
done.	O
Stacking	O
the	O
FLAIR	O
embeddings	O
with	O
others	O
typically	O
does	O
provide	O
a	O
boost	O
in	O
the	O
benchmark	O
results.	O

Background:	O
Independent	O
Component	O
Analysis	O
(ICA	O
)	O
is	O
a	O
widespread	O
tool	O
for	O
exploration	O
and	O
denoising	O
of	O
electroencephalography	O
(EEG	S-RESEARCH_PROBLEM
)	O
or	O
magnetoencephalography	O
(MEG)	O
signals.	O
In	O
its	O
most	O
common	O
formulation,	O
ICA	O
assumes	O
that	O
the	O
signal	O
matrix	O
is	O
a	O
noiseless	O
linear	O
mixture	O
of	O
independent	O
sources	O
that	O
are	O
assumed	O
non-Gaussian.	O
A	O
limitation	O
is	O
that	O
it	O
enforces	O
to	O
estimate	O
as	O
many	O
sources	O
as	O
sensors	O
or	O
to	O
rely	O
on	O
a	O
detrimental	O
PCA	O
step.	O
Methods:	O
We	O
present	O
the	O
Spectral	O
Matching	O
ICA	O
(SMICA	O
)	O
model.	O
Signals	O
are	O
modelled	O
as	O
a	O
linear	O
mixing	O
of	O
independent	O
sources	O
corrupted	O
by	O
additive	O
noise,	O
where	O
sources	O
and	O
the	O
noise	O
are	O
stationary	O
Gaussian	O
time	O
series.	O
Thanks	O
to	O
the	O
Gaussian	O
assumption,	O
the	O
negative	O
log-likelihood	O
has	O
a	O
simple	O
expression	O
as	O
a	O
sum	O
of	O
divergences	O
between	O
the	O
empirical	O
spectral	O
covariance	O
matrices	O
of	O
the	O
signals	O
and	O
those	O
predicted	O
by	O
the	O
model.	O
The	O
model	O
parameters	O
can	O
then	O
be	O
estimated	O
by	O
the	O
expectation-maximization	O
(EM)	O
algorithm.	O
Results:	O
Experiments	O
on	O
phantom	O
MEG	O
datasets	O
show	O
that	O
SMICA	O
can	O
recover	O
dipole	O
locations	O
more	O
precisely	O
than	O
usual	O
ICA	O
algorithms	O
or	O
Maxwell	O
filtering	O
when	O
the	O
dipole	O
amplitude	O
is	O
low.	O
Experiments	O
on	O
EEG	S-RESEARCH_PROBLEM
datasets	O
show	O
that	O
SMICA	O
identifies	O
a	O
source	O
subspace	O
which	O
contains	O
sources	O
that	O
have	O
less	O
pairwise	O
mutual	O
information,	O
and	O
are	O
better	O
explained	O
by	O
the	O
projection	O
of	O
a	O
single	O
dipole	O
on	O
the	O
scalp.	O
Comparison	O
with	O
existing	O
methods:	O
Noiseless	O
ICA	O
models	O
lead	O
to	O
degenerate	O
likelihood	O
when	O
there	O
are	O
fewer	O
sources	O
than	O
sensors,	O
while	O
SMICA	O
succeeds	O
without	O
resorting	O
to	O
prior	O
dimension	O
reduction.	O
Conclusions:	O
SMICA	O
is	O
a	O
promising	O
alternative	O
to	O
other	O
noiseless	O
ICA	O
models	O
based	O
on	O
non-Gaussian	O
assumptions.	O

Although	O
attention-based	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
has	O
achieved	O
remarkable	O
progress	O
in	O
recent	O
layers,	O
it	O
still	O
suffers	O
from	O
issue	O
of	O
making	O
insufficient	O
use	O
of	O
the	O
output	O
of	O
each	O
layer.	O
In	O
transformer,	O
it	O
only	O
uses	O
the	O
top	O
layer	O
of	O
encoder	O
and	O
decoder	O
in	O
the	O
subsequent	O
process,	O
which	O
makes	O
it	O
impossible	O
to	O
take	O
advantage	O
of	O
the	O
useful	O
information	O
in	O
other	O
layers.	O
To	O
address	O
this	O
issue,	O
we	O
propose	O
a	O
residual	O
tree	O
aggregation	O
of	O
layers	O
for	O
Transformer	O
(RTAL),	O
which	O
helps	O
to	O
fuse	O
information	O
across	O
layers.	O
Specifically,	O
we	O
try	O
to	O
fuse	O
the	O
information	O
across	O
layers	O
by	O
constructing	O
a	O
post-order	O
binary	O
tree.	O
In	O
additional	O
to	O
the	O
last	O
node,	O
we	O
add	O
the	O
residual	O
connection	O
to	O
the	O
process	O
of	O
generating	O
child	O
nodes.	O
Our	O
model	O
is	O
based	O
on	O
the	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
model	O
Transformer	O
and	O
we	O
conduct	O
our	O
experiments	O
on	O
WMT14	O
English-to-German	O
and	O
WMT17	O
English-to-France	O
translation	O
tasks.	O
Experimental	O
results	O
across	O
language	O
pairs	O
show	O
that	O
the	O
proposed	O
approach	O
outperforms	O
the	O
strong	O
baseline	O
model	O
significantly	O

Human	B-RESEARCH_PROBLEM
motion	I-RESEARCH_PROBLEM
prediction	E-RESEARCH_PROBLEM
is	O
a	O
challenging	O
task	O
due	O
to	O
the	O
stochasticity	O
and	O
aperiodicity	O
of	O
future	O
poses.	O
Recently,	O
graph	O
convolutional	O
network	O
has	O
been	O
proven	O
to	O
be	O
very	O
effective	O
to	O
learn	O
dynamic	O
relations	O
among	O
pose	O
joints,	O
which	O
is	O
helpful	O
for	O
pose	O
prediction.	O
On	O
the	O
other	O
hand,	O
one	O
can	O
abstract	O
a	O
human	O
pose	O
recursively	O
to	O
obtain	O
a	O
set	O
of	O
poses	O
at	O
multiple	O
scales.	O
With	O
the	O
increase	O
of	O
the	O
abstraction	O
level,	O
the	O
motion	O
of	O
the	O
pose	O
becomes	O
more	O
stable,	O
which	O
benefits	O
pose	O
prediction	O
too.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
novel	O
Multi-Scale	O
Residual	O
Graph	O
Convolution	O
Network	O
(MSR-GCN)	O
for	O
human	O
pose	O
prediction	O
task	O
in	O
the	O
manner	O
of	O
end-to-end.	O
The	O
GCNs	O
are	O
used	O
to	O
extract	O
features	O
from	O
fine	O
to	O
coarse	O
scale	O
and	O
then	O
from	O
coarse	O
to	O
fine	O
scale.	O
The	O
extracted	O
features	O
at	O
each	O
scale	O
are	O
then	O
combined	O
and	O
decoded	O
to	O
obtain	O
the	O
residuals	O
between	O
the	O
input	O
and	O
target	O
poses.	O
Intermediate	O
supervisions	O
are	O
imposed	O
on	O
all	O
the	O
predicted	O
poses,	O
which	O
enforces	O
the	O
network	O
to	O
learn	O
more	O
representative	O
features.	O
Our	O
proposed	O
approach	O
is	O
evaluated	O
on	O
two	O
standard	O
benchmark	O
datasets,	O
i.e.,	O
the	O
Human3.6M	O
dataset	O
and	O
the	O
CMU	O
Mocap	O
dataset.	O
Experimental	O
results	O
demonstrate	O
that	O
our	O
method	O
outperforms	O
the	O
state-of-the-art	O
approaches.	O
Code	O
and	O
pre-trained	O
models	O
are	O
available	O
at	O
https://github.com/Droliven/MSRGCN.	O

Analyzing	O
the	O
abnormality	O
of	O
morphological	O
characteristics	O
of	O
male	O
human	O
sperm	O
has	O
been	O
studied	O
for	O
a	O
long	O
time	O
mainly	O
because	O
it	O
has	O
many	O
implications	O
on	O
the	O
male	O
infertility	O
problem,	O
which	O
accounts	O
for	O
approximately	O
half	O
of	O
the	O
infertility	O
problems	O
in	O
the	O
world.	O
Yet,	O
detecting	O
such	O
abnormalities	O
by	O
embryologists	O
has	O
several	O
downsides.	O
To	O
clarify,	O
analyzing	O
sperms	O
through	O
visual	O
inspection	O
of	O
an	O
expert	O
embryologist	O
is	O
a	O
highly	O
subjective	O
and	O
biased	O
process.	O
Furthermore,	O
it	O
takes	O
much	O
time	O
for	O
a	O
specialist	O
to	O
make	O
a	O
diagnosis.	O
Hence,	O
in	O
this	O
paper,	O
we	O
proposed	O
two	O
deep	O
learning	O
algorithms	O
that	O
are	O
able	O
to	O
automate	O
this	O
process.	O
The	O
first	O
algorithm	O
uses	O
a	O
network-based	O
deep	O
transfer	O
learning	O
approach,	O
while	O
the	O
second	O
technique,	O
named	O
Deep	O
Multi-task	O
Transfer	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(DMTL),	O
employs	O
a	O
novel	O
combination	O
of	O
network-based	O
deep	O
transfer	O
learning	O
and	O
multi-task	O
learning	O
to	O
classify	O
sperm's	O
head,	O
vacuole,	O
and	O
acrosome	O
as	O
either	O
normal	O
or	O
abnormal.	O
This	O
DMTL	O
technique	O
is	O
capable	O
of	O
classifying	O
all	O
the	O
aforementioned	O
parts	O
of	O
the	O
sperm	O
in	O
a	O
single	O
prediction.	O
Moreover,	O
this	O
is	O
the	O
first	O
time	O
that	O
the	O
concept	O
of	O
multi-task	O
learning	O
has	O
been	O
introduced	O
to	O
the	O
field	O
of	O
Sperm	O
Morphology	O
Analysis	O
(SMA	O
).	O
To	O
benchmark	O
our	O
algorithms,	O
we	O
employed	O
a	O
freely-available	O
SMA	O
dataset	O
named	O
MHSMA	O
.	O
During	O
our	O
experiments,	O
our	O
algorithms	O
reached	O
the	O
state-of-the-art	O
results	O
on	O
the	O
accuracy,	O
precision,	O
and	O
f0.5,	O
as	O
well	O
as	O
other	O
important	O
metrics,	O
such	O
as	O
the	O
Matthews	O
Correlation	O
Coefficient	O
on	O
one,	O
two,	O
or	O
all	O
three	O
labels.	O
Notably,	O
our	O
algorithms	O
increased	O
the	O
accuracy	O
of	O
the	O
head,	O
acrosome,	O
and	O
vacuole	O
by	O
6.66%,3.00%	O
,	O
and	O
1.33%,	O
and	O
reached	O
the	O
accuracy	O
of	O
84.00%	O
,80.66%,	O
and	O
94.00%	O
on	O
these	O
labels,	O
respectively.	O
Consequently,	O
our	O
algorithms	O
can	O
be	O
used	O
in	O
health	O
institutions,	O
such	O
as	O
fertility	O
clinics,	O
with	O
further	O
recommendations	O
to	O
practically	O
improve	O
the	O
performance	O
of	O
our	O
algorithms.	O

Activity	O
recognition	O
in	O
smart	O
homes	O
is	O
essential	O
when	O
we	O
wish	O
to	O
propose	O
automatic	O
services	O
for	O
the	O
inhabitants.	O
However,	O
it	O
poses	O
challenges	O
in	O
terms	O
of	O
variability	O
of	O
the	O
environment,	O
sensorimotor	O
system,	O
but	O
also	O
user	O
habits.	O
Therefore,	O
endto-end	O
systems	O
fail	O
at	O
automatically	O
extracting	O
key	O
features,	O
without	O
extensive	O
pre-processing.	O
We	O
propose	O
to	O
tackle	O
feature	O
extraction	O
for	O
activity	O
recognition	O
in	O
smart	O
homes	O
by	O
merging	O
methods	O
from	O
the	O
Natural	O
Language	O
Processing	O
(NLP)	O
and	O
the	O
Time	B-RESEARCH_PROBLEM
Series	I-RESEARCH_PROBLEM
Classification	E-RESEARCH_PROBLEM
(TSC)	O
domains.	O
We	O
evaluate	O
the	O
performance	O
of	O
our	O
method	O
on	O
two	O
datasets	O
issued	O
from	O
the	O
Center	O
for	O
Advanced	O
Studies	O
in	O
Adaptive	O
Systems	O
(CASAS).	O
Moreover,	O
we	O
analyze	O
the	O
contributions	O
of	O
the	O
use	O
of	O
NLP	O
encoding	O
Bag-Of-Word	O
with	O
Embedding	O
as	O
well	O
as	O
the	O
ability	O
of	O
the	O
FCN	O
algorithm	O
to	O
automatically	O
extract	O
features	O
and	O
classify.	O
The	O
method	O
we	O
propose	O
shows	O
good	O
performance	O
in	O
offline	O
activity	O
classification.	O
Our	O
analysis	O
also	O
shows	O
that	O
FCN	O
is	O
a	O
suitable	O
algorithm	O
for	O
smart	O
home	O
activity	O
recognition	O
and	O
hightlights	O
the	O
advantages	O
of	O
automatic	O
feature	O
extraction.	O

Since	O
the	O
superiority	O
of	O
Transformer	O
in	O
learning	O
long-term	O
dependency,	O
the	O
sign	O
language	O
Transformer	O
model	O
achieves	O
remarkable	O
progress	O
in	O
Sign	B-RESEARCH_PROBLEM
Language	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(SLR)	O
and	O
Translation	S-RESEARCH_PROBLEM
(SLT).	O
However,	O
there	O
are	O
several	O
issues	O
with	O
the	O
Transformer	O
that	O
prevent	O
it	O
from	O
better	O
sign	O
language	O
understanding.	O
The	O
first	O
issue	O
is	O
that	O
the	O
self-attention	O
mechanism	O
learns	O
sign	O
video	O
representation	O
in	O
a	O
frame-wise	O
manner,	O
neglecting	O
the	O
temporal	O
semantic	O
structure	O
of	O
sign	O
gestures.	O
Secondly,	O
the	O
attention	O
mechanism	O
with	O
absolute	O
position	O
encoding	O
is	O
direction	O
and	O
distance	O
unaware,	O
thus	O
limiting	O
its	O
ability.	O
To	O
address	O
these	O
issues,	O
we	O
propose	O
a	O
new	O
model	O
architecture,	O
namely	O
PiSLTRc,	O
with	O
two	O
distinctive	O
characteristics:	O
(i)	O
content-aware	O
and	O
position-aware	O
convolution	O
layers.	O
Specifically,	O
we	O
explicitly	O
select	O
relevant	O
features	O
using	O
a	O
novel	O
content-aware	O
neighborhood	O
gathering	O
method.	O
Then	O
we	O
aggregate	O
these	O
features	O
with	O
position-informed	O
temporal	O
convolution	O
layers,	O
thus	O
generating	O
robust	O
neighborhood-enhanced	O
sign	O
representation.	O
(ii)	O
injecting	O
the	O
relative	O
position	O
information	O
to	O
the	O
attention	O
mechanism	O
in	O
the	O
encoder,	O
decoder,	O
and	O
even	O
encoder-decoder	O
cross	O
attention.	O
Compared	O
with	O
the	O
vanilla	O
Transformer	O
model,	O
our	O
model	O
performs	O
consistently	O
better	O
on	O
three	O
large-scale	O
sign	O
language	O
benchmarks:	O
PHOENIX-2014,	O
PHOENIX-2014-T	O
and	O
CSL.	O
Furthermore,	O
extensive	O
experiments	O
demonstrate	O
that	O
the	O
proposed	O
method	O
achieves	O
state-of-the-art	O
performance	O
on	O
translation	O
quality	O
with	O
$+1.6$	O
BLEU	O
improvements.	O

Modern	O
machine	O
learning	O
techniques	O
are	O
successfully	O
being	O
adapted	O
to	O
data	O
modeled	O
as	O
graphs.	O
However,	O
many	O
real-world	O
graphs	O
are	O
typically	O
very	O
large	O
and	O
do	O
not	O
fit	O
in	O
memory,	O
often	O
making	O
the	O
problem	O
of	O
training	O
machine	O
learning	O
models	O
on	O
them	O
intractable.	O
Distributed	O
training	O
has	O
been	O
successfully	O
employed	O
to	O
alleviate	O
memory	O
problems	O
and	O
speed	O
up	O
training	O
in	O
machine	O
learning	O
domains	O
in	O
which	O
the	O
input	O
data	O
is	O
assumed	O
to	O
be	O
independently	O
identical	O
distributed	O
(i.i.d).	O
However,	O
distributing	O
the	O
training	O
of	O
non	O
i.i.d	O
data	O
such	O
as	O
graphs	O
that	O
are	O
used	O
as	O
training	O
inputs	O
in	O
Graph	O
Convolutional	O
Networks	O
(GCNs)	O
causes	O
accuracy	O
problems	O
since	O
information	O
is	O
lost	O
at	O
the	O
graph	B-RESEARCH_PROBLEM
partitioning	E-RESEARCH_PROBLEM
boundaries.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
training	O
strategy	O
that	O
mitigates	O
the	O
lost	O
information	O
across	O
multiple	O
partitions	O
of	O
a	O
graph	O
through	O
a	O
subgraph	O
approximation	O
scheme.	O
Our	O
proposed	O
approach	O
augments	O
each	O
sub-graph	O
with	O
a	O
small	O
amount	O
of	O
edge	O
and	O
vertex	O
information	O
that	O
is	O
approximated	O
from	O
all	O
other	O
sub-graphs.	O
The	O
subgraph	O
approximation	O
approach	O
helps	O
the	O
distributed	O
training	O
system	O
converge	O
at	O
single-machine	O
accuracy,	O
while	O
keeping	O
the	O
memory	O
footprint	O
low	O
and	O
minimizing	O
synchronization	O
overhead	O
between	O
the	O
machines.	O

Aspect-based	O
Sentiment	B-RESEARCH_PROBLEM
Analysis	E-RESEARCH_PROBLEM
(ABSA),	O
aiming	O
at	O
predicting	O
the	O
polarities	O
for	O
aspects,	O
is	O
a	O
fine-grained	O
task	O
in	O
the	O
field	O
of	O
sentiment	O
analysis.	O
Previous	O
work	O
showed	O
syntactic	O
information,	O
e.g.	O
dependency	O
trees,	O
can	O
effectively	O
improve	O
the	O
ABSA	O
performance.	O
Recently,	O
pre-trained	O
models	O
(PTMs)	O
also	O
have	O
shown	O
their	O
effectiveness	O
on	O
ABSA.	O
Therefore,	O
the	O
question	O
naturally	O
arises	O
whether	O
PTMs	O
contain	O
sufficient	O
syntactic	O
information	O
for	O
ABSA	O
so	O
that	O
we	O
can	O
obtain	O
a	O
good	O
ABSA	O
model	O
only	O
based	O
on	O
PTMs.	O
In	O
this	O
paper,	O
we	O
firstly	O
compare	O
the	O
induced	O
trees	O
from	O
PTMs	O
and	O
the	O
dependency	O
parsing	O
trees	O
on	O
several	O
popular	O
models	O
for	O
the	O
ABSA	O
task,	O
showing	O
that	O
the	O
induced	O
tree	O
from	O
fine-tuned	O
RoBERTa	O
(FT-RoBERTa	O
)	O
outperforms	O
the	O
parser-provided	O
tree.	O
The	O
further	O
analysis	O
experiments	O
reveal	O
that	O
the	O
FT-RoBERTa	O
Induced	O
Tree	O
is	O
more	O
sentiment-word-oriented	O
and	O
could	O
benefit	O
the	O
ABSA	O
task.	O
The	O
experiments	O
also	O
show	O
that	O
the	O
pure	O
RoBERTa	O
-based	O
model	O
can	O
outperform	O
or	O
approximate	O
to	O
the	O
previous	O
SOTA	O
performances	O
on	O
six	O
datasets	O
across	O
four	O
languages	O
since	O
it	O
implicitly	O
incorporates	O
the	O
task-oriented	O
syntactic	O
information.	O

In	O
this	O
paper,	O
we	O
propose	O
a	O
new	O
adversarial	O
augmentation	O
method	O
for	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(NMT).	O
The	O
main	O
idea	O
is	O
to	O
minimize	O
the	O
vicinal	O
risk	O
over	O
virtual	O
sentences	O
sampled	O
from	O
two	O
vicinity	O
distributions,	O
of	O
which	O
the	O
crucial	O
one	O
is	O
a	O
novel	O
vicinity	O
distribution	O
for	O
adversarial	O
sentences	O
that	O
describes	O
a	O
smooth	O
interpolated	O
embedding	O
space	O
centered	O
around	O
observed	O
training	O
sentence	O
pairs.	O
We	O
then	O
discuss	O
our	O
approach,	O
AdvAug,	O
to	O
train	O
NMT	O
models	O
using	O
the	O
embeddings	O
of	O
virtual	O
sentences	O
in	O
sequence-to-sequence	O
learning.	O
Experiments	O
on	O
Chinese-English,	O
English-French,	O
and	O
English-German	O
translation	O
benchmarks	O
show	O
that	O
AdvAug	O
achieves	O
significant	O
improvements	O
over	O
the	O
Transformer	O
(up	O
to	O
4.9	O
BLEU	O
points),	O
and	O
substantially	O
outperforms	O
other	O
data	O
augmentation	O
techniques	O
(e.g.	O
back-translation)	O
without	O
using	O
extra	O
corpora.	O

Dynamic	B-RESEARCH_PROBLEM
Time	I-RESEARCH_PROBLEM
Warping	E-RESEARCH_PROBLEM
(DTW	O
)	O
is	O
a	O
popular	O
similarity	O
measure	O
for	O
aligning	O
and	O
comparing	O
time	O
series.	O
Due	O
to	O
DTW	O
's	O
high	O
computation	O
time,	O
lower	O
bounds	O
are	O
often	O
employed	O
to	O
screen	O
poor	O
matches.	O
Many	O
alternative	O
lower	O
bounds	O
have	O
been	O
proposed,	O
providing	O
a	O
range	O
of	O
different	O
trade-offs	O
between	O
tightness	O
and	O
computational	O
efficiency.	O
LB	O
Keogh	O
provides	O
a	O
useful	O
trade-off	O
in	O
many	O
applications.	O
Two	O
recent	O
lower	O
bounds,	O
LB	O
Improved	O
and	O
LB	O
Enhanced,	O
are	O
substantially	O
tighter	O
than	O
LB	O
Keogh.	O
All	O
three	O
have	O
the	O
same	O
worst	O
case	O
computational	O
complexity	O
-	O
linear	O
with	O
respect	O
to	O
series	O
length	O
and	O
constant	O
with	O
respect	O
to	O
window	O
size.	O
We	O
present	O
four	O
new	O
DTW	O
lower	O
bounds	O
in	O
the	O
same	O
complexity	O
class.	O
LB	O
Petitjean	O
is	O
substantially	O
tighter	O
than	O
LB	O
Improved,	O
with	O
only	O
modest	O
additional	O
computational	O
overhead.	O
LB	O
Webb	O
is	O
more	O
efficient	O
than	O
LB	O
Improved,	O
while	O
often	O
providing	O
a	O
tighter	O
bound.	O
LB	O
Webb	O
is	O
always	O
tighter	O
than	O
LB	O
Keogh.	O
The	O
parameter	O
free	O
LB	O
Webb	O
is	O
usually	O
tighter	O
than	O
LB	O
Enhanced.	O
A	O
parameterized	O
variant,	O
LB	O
Webb	O
Enhanced,	O
is	O
always	O
tighter	O
than	O
LB	O
Enhanced.	O
A	O
further	O
variant,	O
LB	O
Webb*,	O
is	O
useful	O
for	O
some	O
constrained	O
distance	O
functions.	O
In	O
extensive	O
experiments,	O
LB	O
Webb	O
proves	O
to	O
be	O
very	O
effective	O
for	O
nearest	O
neighbor	O
search.	O

This	O
paper	O
describes	O
our	O
method	O
for	O
the	O
task	O
of	O
Semantic	O
Question	B-RESEARCH_PROBLEM
Similarity	E-RESEARCH_PROBLEM
in	O
Arabic	O
in	O
the	O
workshop	O
on	O
NLP	O
Solutions	O
for	O
Under-Resourced	O
Languages	O
(NSURL).	O
The	O
aim	O
is	O
to	O
build	O
a	O
model	O
that	O
is	O
able	O
to	O
detect	O
similar	O
semantic	O
questions	O
in	O
the	O
Arabic	O
language	O
for	O
the	O
provided	O
dataset.	O
Different	O
methods	O
of	O
determining	O
questions	O
similarity	O
are	O
explored	O
in	O
this	O
work.	O
The	O
proposed	O
models	O
achieved	O
high	O
F1-scores,	O
which	O
range	O
from	O
(88%	O
to	O
96%).	O
Our	O
official	O
best	O
result	O
is	O
produced	O
from	O
the	O
ensemble	O
model	O
of	O
using	O
a	O
pre-trained	O
multilingual	O
BERT	O
model	O
with	O
different	O
random	O
seeds	O
with	O
95.924%	O
F1-Score,	O
which	O
ranks	O
the	O
first	O
among	O
nine	O
participants	O
teams.	O

The	O
use	O
of	O
supervised	O
Machine	O
Learning	O
(ML)	O
to	O
enhance	O
Intrusion	B-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
Systems	O
has	O
been	O
the	O
subject	O
of	O
significant	O
research.	O
Supervised	O
ML	O
is	O
based	O
upon	O
learning	O
by	O
example,	O
demanding	O
significant	O
volumes	O
of	O
representative	O
instances	O
for	O
effective	O
training	O
and	O
the	O
need	O
to	O
re-train	O
the	O
model	O
for	O
every	O
unseen	O
cyber-attack	O
class.	O
However,	O
retraining	O
the	O
models	O
in-situ	O
renders	O
the	O
network	O
susceptible	O
to	O
attacks	O
owing	O
to	O
the	O
time-window	O
required	O
to	O
acquire	O
a	O
sufficient	O
volume	O
of	O
data.	O
Although	O
anomaly	O
detection	O
systems	O
provide	O
a	O
coarse-grained	O
defence	O
against	O
unseen	O
attacks,	O
these	O
approaches	O
are	O
significantly	O
less	O
accurate	O
and	O
suffer	O
from	O
high	O
false-positive	O
rates.	O
Here,	O
a	O
complementary	O
approach	O
referred	O
to	O
as	O
'One-Shot	O
Learning',	O
whereby	O
a	O
limited	O
number	O
of	O
examples	O
of	O
a	O
new	O
attack-class	O
is	O
used	O
to	O
identify	O
a	O
new	O
attack-class	O
(out	O
of	O
many)	O
is	O
detailed.	O
The	O
model	O
grants	O
a	O
new	O
cyber-attack	O
classification	O
without	O
retraining.	O
A	O
Siamese	O
Network	O
is	O
trained	O
to	O
differentiate	O
between	O
classes	O
based	O
on	O
pairs	O
similarities,	O
rather	O
than	O
features,	O
allowing	O
to	O
identify	O
new	O
and	O
previously	O
unseen	O
attacks.	O
The	O
performance	O
of	O
a	O
pre-trained	O
model	O
to	O
classify	O
attack-classes	O
based	O
only	O
on	O
one	O
example	O
is	O
evaluated	O
using	O
three	O
datasets.	O
Results	O
confirm	O
the	O
adaptability	O
of	O
the	O
model	O
in	O
classifying	O
unseen	O
attacks	O
and	O
the	O
trade-off	O
between	O
performance	O
and	O
the	O
need	O
for	O
distinctive	O
class	O
representation.	O

Contrastive	O
learning	O
(CL)	O
has	O
been	O
successful	O
as	O
a	O
powerful	O
representation	O
learning	O
method.	O
In	O
this	O
work	O
we	O
propose	O
CLIM:	O
Contrastive	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
with	O
mutual	O
Information	O
Maximization,	O
to	O
explore	O
the	O
potential	O
of	O
CL	O
on	O
cross-domain	O
sentiment	O
classification.	O
To	O
the	O
best	O
of	O
our	O
knowledge,	O
CLIM	O
is	O
the	O
first	O
to	O
adopt	O
contrastive	O
learning	O
for	O
natural	O
language	O
processing	O
(NLP)	O
tasks	O
across	O
domains.	O
Due	O
to	O
scarcity	O
of	O
labels	O
on	O
the	O
target	O
domain,	O
we	O
introduce	O
mutual	O
information	O
maximization	O
(MIM	O
)	O
apart	O
from	O
CL	O
to	O
exploit	O
the	O
features	O
that	O
best	O
support	O
the	O
final	O
prediction.	O
Furthermore,	O
MIM	O
is	O
able	O
to	O
maintain	O
a	O
relatively	O
balanced	O
distribution	O
of	O
the	O
model's	O
prediction,	O
and	O
enlarges	O
the	O
margin	O
between	O
classes	O
on	O
the	O
target	O
domain.	O
The	O
larger	O
margin	O
increases	O
our	O
model's	O
robustness	O
and	O
enables	O
the	O
same	O
classifier	O
to	O
be	O
optimal	O
across	O
domains.	O
Consequently,	O
we	O
achieve	O
new	O
state-of-the-art	O
results	O
on	O
the	O
Amazon-review	O
dataset	O
as	O
well	O
as	O
the	O
airlines	O
dataset,	O
showing	O
the	O
efficacy	O
of	O
our	O
proposed	O
method	O
CLIM.	O

The	O
analysis	O
of	O
electroencephalogram	O
(EEG	S-RESEARCH_PROBLEM
)	O
waves	O
is	O
of	O
critical	O
importance	O
for	O
the	O
diagnosis	O
of	O
sleep	O
disorders,	O
such	O
as	O
sleep	O
apnea	O
and	O
insomnia,	O
besides	O
that,	O
seizures,	O
epilepsy,	O
head	O
injuries,	O
dizziness,	O
headaches	O
and	O
brain	O
tumors.	O
In	O
this	O
context,	O
one	O
important	O
task	O
is	O
the	O
identification	O
of	O
visible	O
structures	O
in	O
the	O
EEG	S-RESEARCH_PROBLEM
signal,	O
such	O
as	O
sleep	O
spindles	O
and	O
K-complexes.	O
The	O
identification	O
of	O
these	O
structures	O
is	O
usually	O
performed	O
by	O
visual	O
inspection	O
from	O
human	O
experts,	O
a	O
process	O
that	O
can	O
be	O
error	O
prone	O
and	O
susceptible	O
to	O
biases.	O
Therefore	O
there	O
is	O
interest	O
in	O
developing	O
technologies	O
for	O
the	O
automated	O
analysis	O
of	O
EEG	S-RESEARCH_PROBLEM
.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
new	O
Genetic	O
Programming	O
(GP)	O
framework	O
for	O
feature	O
construction	O
and	O
dimensionality	O
reduction	O
from	O
EEG	S-RESEARCH_PROBLEM
signals.	O
We	O
use	O
these	O
features	O
to	O
automatically	O
identify	O
spindles	O
and	O
K-complexes	O
on	O
data	O
from	O
the	O
DREAMS	O
project.	O
Using	O
5	O
different	O
classifiers,	O
the	O
set	O
of	O
attributes	O
produced	O
by	O
GP	O
obtained	O
better	O
AUC	O
scores	O
than	O
those	O
obtained	O
from	O
PCA	O
or	O
the	O
full	O
set	O
of	O
attributes.	O
Also,	O
the	O
results	O
obtained	O
from	O
the	O
proposed	O
framework	O
obtained	O
a	O
better	O
balance	O
of	O
Specificity	O
and	O
Recall	O
than	O
other	O
models	O
recently	O
proposed	O
in	O
the	O
literature.	O
Analysis	O
of	O
the	O
features	O
most	O
used	O
by	O
GP	O
also	O
suggested	O
improvements	O
for	O
data	O
acquisition	O
protocols	O
in	O
future	O
EEG	S-RESEARCH_PROBLEM
examinations.	O

In	O
this	O
paper,	O
we	O
formulate	O
a	O
more	O
realistic	O
and	O
difficult	O
problem	O
setup	O
for	O
the	O
intent	O
detection	O
task	O
in	O
natural	O
language	O
understanding,	O
namely	O
Generalized	O
Few-Shot	O
Intent	B-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
(GFSID).	O
GFSID	O
aims	O
to	O
discriminate	O
a	O
joint	O
label	O
space	O
consisting	O
of	O
both	O
existing	O
intents	O
which	O
have	O
enough	O
labeled	O
data	O
and	O
novel	O
intents	O
which	O
only	O
have	O
a	O
few	O
examples	O
for	O
each	O
class.	O
To	O
approach	O
this	O
problem,	O
we	O
propose	O
a	O
novel	O
model,	O
Conditional	B-RESEARCH_PROBLEM
Text	I-RESEARCH_PROBLEM
Generation	E-RESEARCH_PROBLEM
with	O
BERT	O
(CG-BERT	O
).	O
CG-BERT	O
effectively	O
leverages	O
a	O
large	O
pre-trained	O
language	O
model	O
to	O
generate	O
text	O
conditioned	O
on	O
the	O
intent	O
label.	O
By	O
modeling	O
the	O
utterance	O
distribution	O
with	O
variational	O
inference,	O
CG-BERT	O
can	O
generate	O
diverse	O
utterances	O
for	O
the	O
novel	O
intents	O
even	O
with	O
only	O
a	O
few	O
utterances	O
available.	O
Experimental	O
results	O
show	O
that	O
CG-BERT	O
achieves	O
state-of-the-art	O
performance	O
on	O
the	O
GFSID	O
task	O
with	O
1-shot	O
and	O
5-shot	O
settings	O
on	O
two	O
real-world	O
datasets.	O

A	O
novel	O
coronavirus	O
disease	O
2019	O
(COVID-19)	O
was	O
detected	O
and	O
has	O
spread	O
rapidly	O
across	O
various	O
countries	O
around	O
the	O
world	O
since	O
the	O
end	O
of	O
the	O
year	O
2019,	O
Computed	B-RESEARCH_PROBLEM
Tomography	I-RESEARCH_PROBLEM
(CT)	E-RESEARCH_PROBLEM
images	O
have	O
been	O
used	O
as	O
a	O
crucial	O
alternative	O
to	O
the	O
time-consuming	O
RT-PCR	O
test.	O
However,	O
pure	O
manual	O
segmentation	O
of	O
CT	O
images	O
faces	O
a	O
serious	O
challenge	O
with	O
the	O
increase	O
of	O
suspected	O
cases,	O
resulting	O
in	O
urgent	O
requirements	O
for	O
accurate	O
and	O
automatic	O
segmentation	O
of	O
COVID-19	O
infections.	O
Unfortunately,	O
since	O
the	O
imaging	O
characteristics	O
of	O
the	O
COVID-19	O
infection	O
are	O
diverse	O
and	O
similar	O
to	O
the	O
backgrounds,	O
existing	O
medical	O
image	O
segmentation	O
methods	O
cannot	O
achieve	O
satisfactory	O
performance.	O
In	O
this	O
work,	O
we	O
try	O
to	O
establish	O
a	O
new	O
deep	O
convolutional	O
neural	O
network	O
tailored	O
for	O
segmenting	O
the	O
chest	O
CT	O
images	O
with	O
COVID-19	O
infections.	O
We	O
firstly	O
maintain	O
a	O
large	O
and	O
new	O
chest	O
CT	O
image	O
dataset	O
consisting	O
of	O
165,667	O
annotated	O
chest	O
CT	O
images	O
from	O
861	O
patients	O
with	O
confirmed	O
COVID-19.	O
Inspired	O
by	O
the	O
observation	O
that	O
the	O
boundary	O
of	O
the	O
infected	O
lung	O
can	O
be	O
enhanced	O
by	O
adjusting	O
the	O
global	O
intensity,	O
in	O
the	O
proposed	O
deep	O
CNN,	O
we	O
introduce	O
a	O
feature	O
variation	O
block	O
which	O
adaptively	O
adjusts	O
the	O
global	O
properties	O
of	O
the	O
features	O
for	O
segmenting	O
COVID-19	O
infection.	O
The	O
proposed	O
FV	O
block	O
can	O
enhance	O
the	O
capability	O
of	O
feature	O
representation	O
effectively	O
and	O
adaptively	O
for	O
diverse	O
cases.	O
We	O
fuse	O
features	O
at	O
different	O
scales	O
by	O
proposing	O
Progressive	O
Atrous	O
Spatial	O
Pyramid	O
Pooling	O
to	O
handle	O
the	O
sophisticated	O
infection	O
areas	O
with	O
diverse	O
appearance	O
and	O
shapes.	O
We	O
conducted	O
experiments	O
on	O
the	O
data	O
collected	O
in	O
China	O
and	O
Germany	O
and	O
show	O
that	O
the	O
proposed	O
deep	O
CNN	O
can	O
produce	O
impressive	O
performance	O
effectively.	O

In	O
this	O
paper,	O
we	O
tackle	O
the	O
task	O
of	O
Word	B-RESEARCH_PROBLEM
Sense	I-RESEARCH_PROBLEM
Disambiguation	E-RESEARCH_PROBLEM
(WSD).	O
We	O
present	O
our	O
system	O
submitted	O
to	O
the	O
Word-in-Context	O
Target	O
Sense	O
Verification	O
challenge,	O
part	O
of	O
the	O
SemDeep	O
workshop	O
at	O
IJCAI	O
2020	O
(Breit	O
et	O
al.,	O
2020).	O
That	O
challenge	O
asks	O
participants	O
to	O
predict	O
if	O
a	O
specific	O
mention	O
of	O
a	O
word	O
in	O
a	O
text	O
matches	O
a	O
pre-defined	O
sense.	O
Our	O
approach	O
uses	O
pre-trained	O
transformer	O
models	O
such	O
as	O
BERT	O
that	O
are	O
fine-tuned	O
on	O
the	O
task	O
using	O
different	O
architecture	O
strategies.	O
Our	O
model	O
achieves	O
the	O
best	O
accuracy	O
and	O
precision	O
on	O
Subtask	O
1	O
?	O
make	O
use	O
of	O
definitions	O
for	O
deciding	O
whether	O
the	O
target	O
word	O
in	O
context	O
corresponds	O
to	O
the	O
given	O
sense	O
or	O
not.	O
We	O
believe	O
the	O
strategies	O
we	O
explored	O
in	O
the	O
context	O
of	O
this	O
challenge	O
can	O
be	O
useful	O
to	O
other	O
Natural	O
Language	O
Processing	O
tasks.	O

Brief	O
fragments	O
of	O
sleep	O
shorter	O
than	O
15	O
s	O
are	O
defined	O
as	O
microsleep	O
episodes	O
(MSEs),	O
often	O
subjectively	O
perceived	O
as	O
sleepiness.	O
Their	O
main	O
characteristic	O
is	O
a	O
slowing	O
in	O
frequency	O
in	O
the	O
electroencephalogram	O
(EEG	S-RESEARCH_PROBLEM
),	O
similar	O
to	O
stage	O
N1	O
sleep	O
according	O
to	O
standard	O
criteria.	O
The	O
maintenance	O
of	O
wakefulness	O
test	O
(MWT)	O
is	O
often	O
used	O
in	O
a	O
clinical	O
setting	O
to	O
assess	O
vigilance.	O
Scoring	O
of	O
the	O
MWT	O
in	O
most	O
sleep-wake	O
centers	O
is	O
limited	O
to	O
classical	O
definition	O
of	O
sleep	O
(30-s	O
epochs),	O
and	O
MSEs	O
are	O
mostly	O
not	O
considered	O
in	O
the	O
absence	O
of	O
established	O
scoring	O
criteria	O
defining	O
MSEs	O
but	O
also	O
because	O
of	O
the	O
laborious	O
work.	O
We	O
aimed	O
for	O
automatic	O
detection	O
of	O
MSEs	O
with	O
machine	O
learning,	O
i.e.	O
with	O
deep	O
learning	O
based	O
on	O
raw	O
EEG	S-RESEARCH_PROBLEM
and	O
EOG	O
data	O
as	O
input.	O
We	O
analyzed	O
MWT	O
data	O
of	O
76	O
patients.	O
Experts	O
visually	O
scored	O
wakefulness,	O
and	O
according	O
to	O
recently	O
developed	O
scoring	O
criteria	O
MSEs,	O
microsleep	O
episode	O
candidates	O
(MSEc),	O
and	O
episodes	O
of	O
drowsiness	O
(ED).	O
We	O
implemented	O
segmentation	O
algorithms	O
based	O
on	O
convolutional	O
neural	O
networks	O
(CNNs)	O
and	O
a	O
combination	O
of	O
a	O
CNN	O
with	O
a	O
long-short	O
term	O
memory	O
(LSTM	O
)	O
network.	O
A	O
LSTM	O
network	O
is	O
a	O
type	O
of	O
a	O
recurrent	O
neural	O
network	O
which	O
has	O
a	O
memory	O
for	O
past	O
events	O
and	O
takes	O
them	O
into	O
account.	O
Data	O
of	O
53	O
patients	O
were	O
used	O
for	O
training	O
of	O
the	O
classifiers,	O
12	O
for	O
validation	O
and	O
11	O
for	O
testing.	O
Our	O
algorithms	O
showed	O
a	O
good	O
performance	O
close	O
to	O
human	O
experts.	O
The	O
detection	O
was	O
very	O
good	O
for	O
wakefulness	O
and	O
MSEs	O
and	O
poor	O
for	O
MSEc	O
and	O
ED,	O
similar	O
to	O
the	O
low	O
inter-expert	O
reliability	O
for	O
these	O
borderline	O
segments.	O
We	O
provide	O
a	O
proof	O
of	O
principle	O
that	O
it	O
is	O
feasible	O
to	O
reliably	O
detect	O
MSEs	O
with	O
deep	O
neuronal	O
networks	O
based	O
on	O
raw	O
EEG	S-RESEARCH_PROBLEM
and	O
EOG	O
data	O
with	O
a	O
performance	O
close	O
to	O
that	O
of	O
human	O
experts.	O
Code	O
of	O
algorithms	O
(	O
https://github.com/alexander-malafeev/microsleep-detection	O
)	O
and	O
data	O
(	O
https://zenodo.org/record/3251716	O
)	O
are	O
available.	O

Recently	O
several	O
datasets	O
have	O
been	O
proposed	O
to	O
encourage	O
research	O
in	O
Question	B-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
domains	O
where	O
commonsense	O
knowledge	O
is	O
expected	O
to	O
play	O
an	O
important	O
role.	O
Recent	O
language	O
models	O
such	O
as	O
ROBERT	O
A,	O
BERT	O
and	O
GPT	O
that	O
have	O
been	O
pre-trained	O
on	O
Wikipedia	O
articles	O
and	O
books	O
have	O
shown	O
reasonable	O
performance	O
with	O
little	O
fine-tuning	O
on	O
several	O
such	O
Multiple	O
Choice	O
Question-Answering	O
(MCQ)	O
datasets.	O
Our	O
goal	O
in	O
this	O
work	O
is	O
to	O
develop	O
methods	O
to	O
incorporate	O
additional	O
(commonsense)	O
knowledge	O
into	O
language	O
model-based	O
approaches	O
for	O
better	O
question-answering	O
in	O
such	O
domains.	O
In	O
this	O
work,	O
we	O
first	O
categorize	O
external	O
knowledge	O
sources,	O
and	O
show	O
performance	O
does	O
improve	O
on	O
using	O
such	O
sources.	O
We	O
then	O
explore	O
three	O
different	O
strategies	O
for	O
knowledge	O
incorporation	O
and	O
four	O
different	O
models	O
for	O
question-answering	O
using	O
external	O
commonsense	O
knowledge.	O
We	O
analyze	O
our	O
predictions	O
to	O
explore	O
the	O
scope	O
of	O
further	O
improvements.	O

Heavily	O
pre-trained	O
transformer	O
models	O
such	O
as	O
BERT	O
have	O
recently	O
shown	O
to	O
be	O
remarkably	O
powerful	O
at	O
language	O
modelling	O
by	O
achieving	O
impressive	O
results	O
on	O
numerous	O
downstream	O
tasks.	O
It	O
has	O
also	O
been	O
shown	O
that	O
they	O
are	O
able	O
to	O
implicitly	O
store	O
factual	O
knowledge	O
in	O
their	O
parameters	O
after	O
pre-training.	O
Understanding	O
what	O
the	O
pre-training	O
procedure	O
of	O
LMs	O
actually	O
learns	O
is	O
a	O
crucial	O
step	O
for	O
using	O
and	O
improving	O
them	O
for	O
Conversational	O
Recommender	O
Systems	O
(CRS).	O
We	O
first	O
study	O
how	O
much	O
off-the-shelf	O
pre-trained	O
BERT	O
"knows"	O
about	O
recommendation	O
items	O
such	O
as	O
books,	O
movies	O
and	O
music.	O
In	O
order	O
to	O
analyze	O
the	O
knowledge	O
stored	O
in	O
BERT	O
's	O
parameters,	O
we	O
use	O
different	O
probes	O
that	O
require	O
different	O
types	O
of	O
knowledge	O
to	O
solve,	O
namely	O
content-based	O
and	O
collaborative-based.	O
Content-based	O
knowledge	O
is	O
knowledge	O
that	O
requires	O
the	O
model	O
to	O
match	O
the	O
titles	O
of	O
items	O
with	O
their	O
content	O
information,	O
such	O
as	O
textual	O
descriptions	O
and	O
genres.	O
In	O
contrast,	O
collaborative-based	O
knowledge	O
requires	O
the	O
model	O
to	O
match	O
items	O
with	O
similar	O
ones,	O
according	O
to	O
community	O
interactions	O
such	O
as	O
ratings.	O
We	O
resort	O
to	O
BERT	O
's	O
Masked	O
Language	B-RESEARCH_PROBLEM
Modelling	E-RESEARCH_PROBLEM
head	O
to	O
probe	O
its	O
knowledge	O
about	O
the	O
genre	O
of	O
items,	O
with	O
cloze	O
style	O
prompts.	O
In	O
addition,	O
we	O
employ	O
BERT	O
's	O
Next	O
Sentence	O
Prediction	O
head	O
and	O
representations'	O
similarity	O
to	O
compare	O
relevant	O
and	O
non-relevant	O
search	O
and	O
recommendation	O
query-document	O
inputs	O
to	O
explore	O
whether	O
BERT	O
can,	O
without	O
any	O
fine-tuning,	O
rank	O
relevant	O
items	O
first.	O
Finally,	O
we	O
study	O
how	O
BERT	O
performs	O
in	O
a	O
conversational	O
recommendation	O
downstream	O
task.	O
Overall,	O
our	O
analyses	O
and	O
experiments	O
show	O
that:	O
(i)	O
BERT	O
has	O
knowledge	O
stored	O
in	O
its	O
parameters	O
about	O
the	O
content	O
of	O
books,	O
movies	O
and	O
music;	O
(ii)	O
it	O
has	O
more	O
content-based	O
knowledge	O
than	O
collaborative-based	O
knowledge;	O
and	O
(iii)	O
fails	O
on	O
conversational	O
recommendation	O
when	O
faced	O
with	O
adversarial	O
data.	O

Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
is	O
one	O
of	O
the	O
most	O
important	O
text	O
processing	O
requirement	O
in	O
many	O
NLP	O
tasks.	O
In	O
this	O
paper	O
we	O
use	O
a	O
deep	O
architecture	O
to	O
accomplish	O
the	O
task	O
of	O
recognizing	O
named	O
entities	O
in	O
a	O
given	O
Hindi	O
text	O
sentence.	O
Bidirectional	O
Long	O
Short	O
Term	O
Memory	O
(BiLSTM	O
)	O
based	O
techniques	O
have	O
been	O
used	O
for	O
NER	S-RESEARCH_PROBLEM
task	O
in	O
literature.	O
In	O
this	O
paper,	O
we	O
first	O
tune	O
BiLSTM	O
low-resource	O
scenario	O
to	O
work	O
for	O
Hindi	O
NER	S-RESEARCH_PROBLEM
and	O
propose	O
two	O
enhancements	O
namely	O
(a)	O
de-noising	O
auto-encoder	O
(DAE)	O
LSTM	O
and	O
(b)	O
conditioning	O
LSTM	O
which	O
show	O
improvement	O
in	O
NER	S-RESEARCH_PROBLEM
task	O
compared	O
to	O
the	O
BiLSTM	O
approach.	O
We	O
use	O
pre-trained	O
word	O
embedding	O
to	O
represent	O
the	O
words	O
in	O
the	O
corpus,	O
and	O
the	O
NER	S-RESEARCH_PROBLEM
tags	O
of	O
the	O
words	O
are	O
as	O
defined	O
by	O
the	O
used	O
annotated	O
corpora.	O
Experiments	O
have	O
been	O
performed	O
to	O
analyze	O
the	O
performance	O
of	O
different	O
word	O
embeddings	O
and	O
batch	O
sizes	O
which	O
is	O
essential	O
for	O
training	O
deep	O
models.	O

It	O
is	O
well	O
understood	O
that	O
Dynamic	B-RESEARCH_PROBLEM
Time	I-RESEARCH_PROBLEM
Warping	E-RESEARCH_PROBLEM
(DTW	O
)	O
is	O
effective	O
in	O
revealing	O
similarities	O
between	O
time	O
series	O
that	O
do	O
not	O
align	O
perfectly.	O
In	O
this	O
paper,	O
we	O
illustrate	O
this	O
on	O
spectroscopy	O
time-series	O
data.	O
We	O
show	O
that	O
DTW	O
is	O
effective	O
in	O
improving	O
accuracy	O
on	O
a	O
regression	O
task	O
when	O
only	O
a	O
single	O
wavelength	O
is	O
considered.	O
When	O
combined	O
with	O
k-Nearest	O
Neighbour,	O
DTW	O
has	O
the	O
added	O
advantage	O
that	O
it	O
can	O
reveal	O
similarities	O
and	O
differences	O
between	O
samples	O
at	O
the	O
level	O
of	O
the	O
time-series.	O
However,	O
in	O
the	O
problem,	O
we	O
consider	O
here	O
data	O
is	O
available	O
across	O
a	O
spectrum	O
of	O
wavelengths.	O
If	O
aggregate	O
statistics	O
(means,	O
variances)	O
are	O
used	O
across	O
many	O
wavelengths	O
the	O
benefits	O
of	O
DTW	O
are	O
no	O
longer	O
apparent.	O
We	O
present	O
this	O
as	O
another	O
example	O
of	O
a	O
situation	O
where	O
big	O
data	O
trumps	O
sophisticated	O
models	O
in	O
Machine	O
Learning.	O

In	O
this	O
work,	O
we	O
propose	O
an	O
ensemble	O
of	O
classifiers	O
to	O
distinguish	O
betweenvarious	O
degrees	O
of	O
abnormalities	O
of	O
the	O
heart	O
using	O
Phonocardiogram	O
(PCG)signals	O
acquired	O
using	O
digital	O
stethoscopes	O
in	O
a	O
clinical	O
setting,	O
for	O
theINTERSPEECH	O
2018	O
Computational	O
Paralinguistics	O
(ComParE)	O
Heart	O
BeatsSubChallenge.	O
Our	O
primary	O
classification	O
framework	O
constitutes	O
a	O
convolutionalneural	O
network	O
with	O
1D-CNN	O
time-convolution	O
(tConv)	O
layers,	O
which	O
uses	O
featurestransferred	O
from	O
a	O
model	O
trained	O
on	O
the	O
2016	O
Physionet	O
Heart	O
Sound	O
Database.	O
Wealso	O
employ	O
a	O
Representation	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(RL)	O
approach	O
to	O
generate	O
features	O
in	O
anunsupervised	O
manner	O
using	O
Deep	O
Recurrent	O
Autoencoders	O
and	O
use	O
Support	O
VectorMachine	O
(SVM	O
)	O
and	O
Linear	O
Discriminant	O
Analysis	O
(LDA)	O
classifiers.	O
Finally,	O
weutilize	O
an	O
SVM	O
classifier	O
on	O
a	O
high-dimensional	O
segment-level	O
feature	O
extractedusing	O
various	O
functionals	O
on	O
short-term	O
acoustic	O
features,	O
i.e.,	O
Low-LevelDescriptors	O
(LLD).	O
An	O
ensemble	O
of	O
the	O
three	O
different	O
approaches	O
provides	O
arelative	O
improvement	O
of	O
11.13%	O
compared	O
to	O
our	O
best	O
single	O
sub-system	O
in	O
termsof	O
the	O
Unweighted	O
Average	O
Recall	O
(UAR)	O
performance	O
metric	O
on	O
the	O
evaluationdataset.	O

Real-world	O
Relation	B-RESEARCH_PROBLEM
Extraction	E-RESEARCH_PROBLEM
(RE)	O
tasks	O
are	O
challenging	O
to	O
deal	O
with,	O
either	O
due	O
to	O
limited	O
training	O
data	O
or	O
class	O
imbalance	O
issues.	O
In	O
this	O
work,	O
we	O
present	O
Data	O
Augmented	O
Relation	B-RESEARCH_PROBLEM
Extraction	E-RESEARCH_PROBLEM
(DARE),	O
a	O
simple	O
method	O
to	O
augment	O
training	O
data	O
by	O
properly	O
fine-tuning	O
GPT-2	O
to	O
generate	O
examples	O
for	O
specific	O
relation	O
types.	O
The	O
generated	O
training	O
data	O
is	O
then	O
used	O
in	O
combination	O
with	O
the	O
gold	O
dataset	O
to	O
train	O
a	O
BERT-based	O
RE	O
classifier.	O
In	O
a	O
series	O
of	O
experiments	O
we	O
show	O
the	O
advantages	O
of	O
our	O
method,	O
which	O
leads	O
in	O
improvements	O
of	O
up	O
to	O
11	O
F1	O
score	O
points	O
against	O
a	O
strong	O
base-line.	O
Also,	O
DARE	O
achieves	O
new	O
state	O
of	O
the	O
art	O
in	O
three	O
widely	O
used	O
biomedical	O
RE	O
datasets	O
surpassing	O
the	O
previous	O
best	O
results	O
by	O
4.7	O
F1	O
points	O
on	O
average.	O

BERT	O
and	O
its	O
variants	O
have	O
achieved	O
state-of-the-art	O
performance	O
in	O
various	O
NLP	O
tasks.	O
Since	O
then,	O
various	O
works	O
have	O
been	O
proposed	O
to	O
analyze	O
the	O
linguistic	O
information	O
being	O
captured	O
in	O
BERT	O
.	O
However,	O
the	O
current	O
works	O
do	O
not	O
provide	O
an	O
insight	O
into	O
how	O
BERT	O
is	O
able	O
to	O
achieve	O
near	O
human-level	O
performance	O
on	O
the	O
task	O
of	O
Reading	B-RESEARCH_PROBLEM
Comprehension	E-RESEARCH_PROBLEM
based	O
Question	O
Answering.	O
In	O
this	O
work,	O
we	O
attempt	O
to	O
interpret	O
BERT	O
for	O
RCQA.	O
Since	O
BERT	O
layers	O
do	O
not	O
have	O
predefined	O
roles,	O
we	O
define	O
a	O
layer's	O
role	O
or	O
functionality	O
using	O
Integrated	O
Gradients.	O
Based	O
on	O
the	O
defined	O
roles,	O
we	O
perform	O
a	O
preliminary	O
analysis	O
across	O
all	O
layers.	O
We	O
observed	O
that	O
the	O
initial	O
layers	O
focus	O
on	O
query-passage	O
interaction,	O
whereas	O
later	O
layers	O
focus	O
more	O
on	O
contextual	O
understanding	O
and	O
enhancing	O
the	O
answer	O
prediction.	O
Specifically	O
for	O
quantifier	O
questions	O
(how	O
much/how	O
many),	O
we	O
notice	O
that	O
BERT	O
focuses	O
on	O
confusing	O
words	O
(i.e.,	O
on	O
other	O
numerical	O
quantities	O
in	O
the	O
passage)	O
in	O
the	O
later	O
layers,	O
but	O
still	O
manages	O
to	O
predict	O
the	O
answer	O
correctly.	O
The	O
fine-tuning	O
and	O
analysis	O
scripts	O
will	O
be	O
publicly	O
available	O
at	O
https://github.com/iitmnlp/BERT	O
-Analysis-RCQA	O
.	O

This	O
paper	O
considers	O
an	O
architecture	O
referred	O
to	O
as	O
Cascade	O
Region	B-RESEARCH_PROBLEM
Proposal	E-RESEARCH_PROBLEM
Network	O
(Cascade	O
RPN	O
)	O
for	O
improving	O
the	O
region-proposal	O
quality	O
and	O
detection	O
performance	O
by	O
\textit{systematically}	O
addressing	O
the	O
limitation	O
of	O
the	O
conventional	O
RPN	O
that	O
\textit{heuristically	O
defines}	O
the	O
anchors	O
and	O
\textit{aligns}	O
the	O
features	O
to	O
the	O
anchors.	O
First,	O
instead	O
of	O
using	O
multiple	O
anchors	O
with	O
predefined	O
scales	O
and	O
aspect	O
ratios,	O
Cascade	O
RPN	O
relies	O
on	O
a	O
\textit{single	O
anchor}	O
per	O
location	O
and	O
performs	O
multi-stage	O
refinement.	O
Each	O
stage	O
is	O
progressively	O
more	O
stringent	O
in	O
defining	O
positive	O
samples	O
by	O
starting	O
out	O
with	O
an	O
anchor-free	O
metric	O
followed	O
by	O
anchor-based	O
metrics	O
in	O
the	O
ensuing	O
stages.	O
Second,	O
to	O
attain	O
alignment	O
between	O
the	O
features	O
and	O
the	O
anchors	O
throughout	O
the	O
stages,	O
\textit{adaptive	O
convolution}	O
is	O
proposed	O
that	O
takes	O
the	O
anchors	O
in	O
addition	O
to	O
the	O
image	O
features	O
as	O
its	O
input	O
and	O
learns	O
the	O
sampled	O
features	O
guided	O
by	O
the	O
anchors.	O
A	O
simple	O
implementation	O
of	O
a	O
two-stage	O
Cascade	O
RPN	O
achieves	O
AR	O
13.4	O
points	O
higher	O
than	O
that	O
of	O
the	O
conventional	O
RPN	O
,	O
surpassing	O
any	O
existing	O
region	O
proposal	O
methods.	O
When	O
adopting	O
to	O
Fast	O
R-CNN	O
and	O
Faster	O
R-CNN,	O
Cascade	O
RPN	O
can	O
improve	O
the	O
detection	O
mAP	O
by	O
3.1	O
and	O
3.5	O
points,	O
respectively.	O
The	O
code	O
is	O
made	O
publicly	O
available	O
at	O
\url{https://github.com/thangvubk/Cascade-RPN	O
.git}.	O

We	O
introduce	O
coroICA	O
,	O
confounding-robust	O
independent	O
component	O
analysis,	O
a	O
novel	O
ICA	O
algorithm	O
which	O
decomposes	O
linearly	O
mixed	O
multivariate	O
observations	O
into	O
independent	O
components	O
that	O
are	O
corrupted	O
(and	O
rendered	O
dependent)	O
by	O
hidden	O
group-wise	O
stationary	O
confounding.	O
It	O
extends	O
the	O
ordinary	O
ICA	O
model	O
in	O
a	O
theoretically	O
sound	O
and	O
explicit	O
way	O
to	O
incorporate	O
group-wise	O
(or	O
environment-wise)	O
confounding.	O
We	O
show	O
that	O
our	O
proposed	O
general	O
noise	O
model	O
allows	O
to	O
perform	O
ICA	O
in	O
settings	O
where	O
other	O
noisy	O
ICA	O
procedures	O
fail.	O
Additionally,	O
it	O
can	O
be	O
used	O
for	O
applications	O
with	O
grouped	O
data	O
by	O
adjusting	O
for	O
different	O
stationary	O
noise	O
within	O
each	O
group.	O
Our	O
proposed	O
noise	O
model	O
has	O
a	O
natural	O
relation	O
to	O
causality	O
and	O
we	O
explain	O
how	O
it	O
can	O
be	O
applied	O
in	O
the	O
context	O
of	O
causal	O
inference.	O
In	O
addition	O
to	O
our	O
theoretical	O
framework,	O
we	O
provide	O
an	O
efficient	O
estimation	O
procedure	O
and	O
prove	O
identifiability	O
of	O
the	O
unmixing	O
matrix	O
under	O
mild	O
assumptions.	O
Finally,	O
we	O
illustrate	O
the	O
performance	O
and	O
robustness	O
of	O
our	O
method	O
on	O
simulated	O
data,	O
provide	O
audible	O
and	O
visual	O
examples,	O
and	O
demonstrate	O
the	O
applicability	O
to	O
real-world	O
scenarios	O
by	O
experiments	O
on	O
publicly	O
available	O
Antarctic	O
ice	O
core	O
data	O
as	O
well	O
as	O
two	O
EEG	S-RESEARCH_PROBLEM
data	O
sets.	O
We	O
provide	O
a	O
scikit-learn	O
compatible	O
pip-installable	O
Python	O
package	O
coroICA	O
as	O
well	O
as	O
R	O
and	O
Matlab	O
implementations	O
accompanied	O
by	O
a	O
documentation	O
at	O
https://sweichwald.de/coroICA	O
/	O

We	O
address	O
the	O
problem	O
of	O
defining	O
a	O
group	O
sparse	O
formulation	O
for	O
Principal	O
Components	O
Analysis	O
(PCA	O
)	O
-	O
or	O
its	O
equivalent	O
formulations	O
as	O
Low	O
Rank	O
approximation	O
or	O
Dictionary	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
problems	O
-	O
which	O
achieves	O
a	O
compromise	O
between	O
maximizing	O
the	O
variance	O
explained	O
by	O
the	O
components	O
and	O
promoting	O
sparsity	O
of	O
the	O
loadings.	O
So	O
we	O
propose	O
first	O
a	O
new	O
definition	O
of	O
the	O
variance	O
explained	O
by	O
non	O
necessarily	O
orthogonal	O
components,	O
which	O
is	O
optimal	O
in	O
some	O
aspect	O
and	O
compatible	O
with	O
the	O
principal	O
components	O
situation.	O
Then	O
we	O
use	O
a	O
specific	O
regularization	O
of	O
this	O
variance	O
by	O
the	O
group-$\ell_{1}$	O
norm	O
to	O
define	O
a	O
Group	O
Sparse	O
Maximum	O
Variance	O
(GSMV)	O
formulation	O
of	O
PCA	O
.	O
The	O
GSMV	O
formulation	O
achieves	O
our	O
objective	O
by	O
construction,	O
and	O
has	O
the	O
nice	O
property	O
that	O
the	O
inner	O
non	O
smooth	O
optimization	O
problem	O
can	O
be	O
solved	O
analytically,	O
thus	O
reducing	O
GSMV	O
to	O
the	O
maximization	O
of	O
a	O
smooth	O
and	O
convex	O
function	O
under	O
unit	O
norm	O
and	O
orthogonality	O
constraints,	O
which	O
generalizes	O
Journee	O
et	O
al.	O
(2010)	O
to	O
group	O
sparsity.	O
Numerical	O
comparison	O
with	O
deflation	O
on	O
synthetic	O
data	O
shows	O
that	O
GSMV	O
produces	O
steadily	O
slightly	O
better	O
and	O
more	O
robust	O
results	O
for	O
the	O
retrieval	O
of	O
hidden	O
sparse	O
structures,	O
and	O
is	O
about	O
three	O
times	O
faster	O
on	O
these	O
examples.	O
Application	O
to	O
real	O
data	O
shows	O
the	O
interest	O
of	O
group	O
sparsity	O
for	O
variables	O
selection	O
in	O
PCA	O
of	O
mixed	O
data	O
(categorical/numerical)	O
.	O

Model	B-RESEARCH_PROBLEM
extraction	E-RESEARCH_PROBLEM
attacks	O
attempt	O
to	O
replicate	O
a	O
target	O
machine	O
learning	O
model	O
from	O
predictions	O
obtained	O
by	O
querying	O
its	O
inference	O
API.	O
Most	O
existing	O
attacks	O
on	O
Deep	O
Neural	O
Networks	O
achieve	O
this	O
by	O
supervised	O
training	O
of	O
the	O
copy	O
using	O
the	O
victim's	O
predictions.	O
An	O
emerging	O
class	O
of	O
attacks	O
exploit	O
algebraic	O
properties	O
of	O
DNNs	O
to	O
obtain	O
high-fidelity	O
copies	O
using	O
orders	O
of	O
magnitude	O
fewer	O
queries	O
than	O
the	O
prior	O
state-of-the-art.	O
So	O
far,	O
such	O
powerful	O
attacks	O
have	O
been	O
limited	O
to	O
networks	O
with	O
few	O
hidden	O
layers	O
and	O
ReLU	O
activations.In	O
this	O
paper	O
we	O
present	O
algebraic	O
attacks	O
on	O
large-scale	O
natural	O
language	O
models	O
in	O
a	O
grey-box	O
setting,	O
targeting	O
models	O
with	O
a	O
pre-trained	O
(public)	O
encoder	O
followed	O
by	O
a	O
single	O
(private)	O
classification	O
layer.	O
Our	O
key	O
observation	O
is	O
that	O
a	O
small	O
set	O
of	O
arbitrary	O
embedding	O
vectors	O
is	O
likely	O
to	O
form	O
a	O
basis	O
of	O
the	O
classification	O
layer's	O
input	O
space,	O
which	O
a	O
grey-box	O
adversary	O
can	O
compute.	O
We	O
show	O
how	O
to	O
use	O
this	O
information	O
to	O
solve	O
an	O
equation	O
system	O
that	O
determines	O
the	O
classification	O
layer	O
from	O
the	O
corresponding	O
probability	O
outputs.We	O
evaluate	O
the	O
effectiveness	O
of	O
our	O
attacks	O
on	O
different	O
sizes	O
of	O
transformer	O
models	O
and	O
downstream	O
tasks.	O
Our	O
key	O
findings	O
are	O
that	O
(i)	O
with	O
frozen	O
base	O
layers,	O
high-fidelity	O
extraction	O
is	O
possible	O
with	O
a	O
number	O
of	O
queries	O
that	O
is	O
as	O
small	O
as	O
twice	O
the	O
input	O
dimension	O
of	O
the	O
last	O
layer.	O
This	O
is	O
true	O
even	O
for	O
queries	O
that	O
are	O
entirely	O
in-distribution,	O
making	O
extraction	O
attacks	O
indistinguishable	O
from	O
legitimate	O
use;	O
(ii)	O
with	O
fine-tuned	O
base	O
layers,	O
the	O
effectiveness	O
of	O
algebraic	O
attacks	O
decreases	O
with	O
the	O
learning	O
rate,	O
showing	O
that	O
fine-tuning	O
is	O
not	O
only	O
beneficial	O
for	O
accuracy	O
but	O
also	O
indispensable	O
for	O
model	O
confidentiality.	O

We	O
present	O
AIA-BDE,	O
a	O
corpus	O
of	O
380	O
domain-oriented	O
FAQs	O
in	O
Portuguese	O
and	O
their	O
variations,	O
i.e.,	O
paraphrases	O
or	O
entailed	O
questions,	O
created	O
manually,	O
by	O
humans,	O
or	O
automatically,	O
with	O
Google	O
Translate.	O
Its	O
aims	O
to	O
be	O
used	O
as	O
a	O
benchmark	O
for	O
FAQ	O
retrieval	O
and	O
automatic	O
question-answering,	O
but	O
may	O
be	O
useful	O
in	O
other	O
contexts,	O
such	O
as	O
the	O
development	O
of	O
task-oriented	O
dialogue	O
systems,	O
or	O
models	O
for	O
natural	O
language	O
inference	O
in	O
an	O
interrogative	O
context.	O
We	O
also	O
report	O
on	O
two	O
experiments.	O
Matching	O
variations	O
with	O
their	O
original	O
questions	O
was	O
not	O
trivial	O
with	O
a	O
set	O
of	O
unsupervised	O
baselines,	O
especially	O
for	O
manually	O
created	O
variations.	O
Besides	O
high	O
performances	O
obtained	O
with	O
ELMo	O
and	O
BERT	O
embeddings,	O
an	O
Information	B-RESEARCH_PROBLEM
Retrieval	E-RESEARCH_PROBLEM
system	O
was	O
surprisingly	O
competitive	O
when	O
considering	O
only	O
the	O
first	O
hit.	O
In	O
the	O
second	O
experiment,	O
text	O
classifiers	O
were	O
trained	O
with	O
the	O
original	O
questions,	O
and	O
tested	O
when	O
assigning	O
each	O
variation	O
to	O
one	O
of	O
three	O
possible	O
sources,	O
or	O
assigning	O
them	O
as	O
out-of-domain.	O
Here,	O
the	O
difference	O
between	O
manual	O
and	O
automatic	O
variations	O
was	O
not	O
so	O
significant.	O

This	O
paper	O
describes	O
the	O
work	O
done	O
by	O
team	O
tearsofjoy	O
participating	O
in	O
the	O
VarDial	O
2019	O
Evaluation	O
Campaign.	O
We	O
developed	O
two	O
systems	O
based	O
on	O
Support	O
Vector	O
Machines:	O
SVM	O
with	O
a	O
flat	O
combination	O
of	O
features	O
and	O
SVM	O
ensembles.	O
We	O
participated	O
in	O
all	O
language/dialect	O
identification	O
tasks,	O
as	O
well	O
as	O
the	O
Moldavian	O
vs.	O
Romanian	O
cross-dialect	O
topic	O
identification	O
(MRC)	O
task.	O
Our	O
team	O
achieved	O
first	O
place	O
in	O
German	O
Dialect	O
identification	O
(GDI)	O
and	O
MRC	O
subtasks	O
2	O
and	O
3,	O
second	O
place	O
in	O
the	O
simplified	O
variant	O
of	O
Discriminating	O
between	O
Mainland	O
and	O
Taiwan	O
variation	O
of	O
Mandarin	O
Chinese	O
(DMT)	O
as	O
well	O
as	O
Cuneiform	O
Language	B-RESEARCH_PROBLEM
Identification	E-RESEARCH_PROBLEM
(CLI),	O
and	O
third	O
and	O
fifth	O
place	O
in	O
DMT	O
traditional	O
and	O
MRC	O
subtask	O
1	O
respectively.	O
In	O
most	O
cases,	O
the	O
SVM	O
with	O
a	O
flat	O
combination	O
of	O
features	O
performed	O
better	O
than	O
SVM	O
ensembles.	O
Besides	O
describing	O
the	O
systems	O
and	O
the	O
results	O
obtained	O
by	O
them,	O
we	O
provide	O
a	O
tentative	O
comparison	O
between	O
the	O
feature	O
combination	O
methods,	O
and	O
present	O
additional	O
experiments	O
with	O
a	O
method	O
of	O
adaptation	O
to	O
the	O
test	O
set,	O
which	O
may	O
indicate	O
potential	O
pitfalls	O
with	O
some	O
of	O
the	O
data	O
sets.	O

The	O
design	O
of	O
small	O
molecules	O
with	O
bespoke	O
properties	O
is	O
of	O
central	O
importance	O
to	O
drug	O
discovery.	O
However	O
significant	O
challenges	O
yet	O
remain	O
for	O
computational	O
methods,	O
despite	O
recent	O
advances	O
such	O
as	O
deep	O
recurrent	O
networks	O
and	O
reinforcement	O
learning	O
strategies	O
for	O
sequence	O
generation,	O
and	O
it	O
can	O
be	O
difficult	O
to	O
compare	O
results	O
across	O
different	O
works.	O
This	O
work	O
proposes	O
19	O
benchmarks	O
selected	O
by	O
subject	O
experts,	O
expands	O
smaller	O
datasets	O
previously	O
used	O
to	O
approximately	O
1.1	O
million	O
training	O
molecules,	O
and	O
explores	O
how	O
to	O
apply	O
new	O
reinforcement	O
learning	O
techniques	O
effectively	O
for	O
molecular	O
design.	O
The	O
benchmarks	O
here,	O
built	O
as	O
OpenAI	B-RESEARCH_PROBLEM
Gym	E-RESEARCH_PROBLEM
environments,	O
will	O
be	O
open-sourced	O
to	O
encourage	O
innovation	O
in	O
molecular	O
design	O
algorithms	O
and	O
to	O
enable	O
usage	O
by	O
those	O
without	O
a	O
background	O
in	O
chemistry.	O
Finally,	O
this	O
work	O
explores	O
recent	O
development	O
in	O
reinforcement-learning	O
methods	O
with	O
excellent	O
sample	O
complexity	O
(the	O
A2C	O
and	O
PPO	O
algorithms)	O
and	O
investigates	O
their	O
behavior	O
in	O
molecular	O
generation,	O
demonstrating	O
significant	O
performance	O
gains	O
compared	O
to	O
standard	O
reinforcement	O
learning	O
techniques.	O

Automated	O
segmentation	O
of	O
human	O
cardiac	O
magnetic	O
resonance	O
datasets	O
has	O
been	O
steadily	O
improving	O
during	O
recent	O
years.	O
However,	O
these	O
methods	O
are	O
not	O
directly	O
applicable	O
in	O
preclinical	O
context	O
due	O
to	O
limited	O
datasets	O
and	O
lower	O
image	O
resolution.	O
Successful	O
application	O
of	O
deep	O
architectures	O
for	O
rat	O
cardiac	O
segmentation,	O
although	O
of	O
critical	O
importance	O
for	O
preclinical	O
evaluation	O
of	O
cardiac	O
function,	O
has	O
to	O
our	O
knowledge	O
not	O
yet	O
been	O
reported.	O
We	O
developed	O
segmentation	O
models	O
that	O
expand	O
on	O
the	O
standard	O
U-Net	O
architecture	O
and	O
evaluated	O
separate	O
models	O
for	O
systole	O
and	O
diastole	O
phases,	O
2MSA,	O
and	O
one	O
model	O
for	O
all	O
timepoints,	O
1MSA.	O
Furthermore,	O
we	O
calibrated	O
model	O
outputs	O
using	O
a	O
Gaussian	O
Process	O
(GP)-based	O
prior	O
to	O
improve	O
phase	O
selection.	O
Resulting	O
models	O
approach	O
human	O
performance	O
in	O
terms	O
of	O
left	O
ventricular	O
segmentation	O
quality	O
and	O
ejection	O
fraction	O
(EF)	O
estimation	O
in	O
both	O
1MSA	O
and	O
2MSA	O
settings	O
(S{\o}rensen-Dice	O
score	O
0.91	O
+/-	O
0.072	O
and	O
0.93	O
+/-	O
0.032,	O
respectively).	O
2MSA	O
achieved	O
a	O
mean	O
absolute	O
difference	O
between	O
estimated	O
and	O
reference	O
EF	O
of	O
3.5	O
+/-	O
2.5	O
%,	O
while	O
1MSA	O
resulted	O
in	O
4.1	O
+/-	O
3.0	O
%.	O
Applying	O
Gaussian	B-RESEARCH_PROBLEM
Processes	E-RESEARCH_PROBLEM
to	O
1MSA	O
allows	O
to	O
automate	O
the	O
selection	O
of	O
systole	O
and	O
diastole	O
phases.	O
Combined	O
with	O
a	O
novel	O
cardiac	O
phase	O
selection	O
strategy,	O
our	O
work	O
presents	O
an	O
important	O
first	O
step	O
towards	O
a	O
fully	O
automated	O
segmentation	O
pipeline	O
in	O
the	O
context	O
of	O
rat	O
cardiac	O
analysis.	O

We	O
investigate	O
the	O
problem	O
of	O
multi-domain	O
Dialogue	B-RESEARCH_PROBLEM
State	I-RESEARCH_PROBLEM
Tracking	E-RESEARCH_PROBLEM
(DST)	O
with	O
open	O
vocabulary,	O
which	O
aims	O
to	O
extract	O
the	O
state	O
from	O
the	O
dialogue.	O
Existing	O
approaches	O
usually	O
concatenate	O
previous	O
dialogue	O
state	O
with	O
dialogue	O
history	O
as	O
the	O
input	O
to	O
a	O
bi-directional	O
Transformer	O
encoder.	O
They	O
rely	O
on	O
the	O
self-attention	O
mechanism	O
of	O
Transformer	O
to	O
connect	O
tokens	O
in	O
them.	O
However,	O
attention	O
may	O
be	O
paid	O
to	O
spurious	O
connections,	O
leading	O
to	O
wrong	O
inference.	O
In	O
this	O
paper,	O
we	O
propose	O
to	O
construct	O
a	O
dialogue	O
state	O
graph	O
in	O
which	O
domains,	O
slots	O
and	O
values	O
from	O
the	O
previous	O
dialogue	O
state	O
are	O
connected	O
properly.	O
Through	O
training,	O
the	O
graph	O
node	O
and	O
edge	O
embeddings	O
can	O
encode	O
co-occurrence	O
relations	O
between	O
domain-domain,	O
slot-slot	O
and	O
domain-slot,	O
reflecting	O
the	O
strong	O
transition	O
paths	O
in	O
general	O
dialogue.	O
The	O
state	O
graph,	O
encoded	O
with	O
relational-GCN,	O
is	O
fused	O
into	O
the	O
Transformer	O
encoder.	O
Experimental	O
results	O
show	O
that	O
our	O
approach	O
achieves	O
a	O
new	O
state	O
of	O
the	O
art	O
on	O
the	O
task	O
while	O
remaining	O
efficient.	O
It	O
outperforms	O
existing	O
open-vocabulary	O
DST	O
approaches.	O

Unlike	O
melody	O
extraction	O
and	O
other	O
aspects	O
of	O
music	O
transcription,	O
research	O
on	O
playing	O
technique	O
detection	O
is	O
still	O
in	O
its	O
early	O
stages.	O
Compared	O
to	O
existing	O
work	O
mostly	O
focused	O
on	O
playing	O
technique	O
detection	O
for	O
individual	O
single	O
notes,	O
we	O
propose	O
a	O
general	O
end-to-end	O
method	O
based	O
on	O
Sound	B-RESEARCH_PROBLEM
Event	I-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
by	O
FCN	O
for	O
musical	O
instrument	O
playing	O
technique	O
detection.	O
In	O
our	O
case,	O
we	O
choose	O
Erhu,	O
a	O
well-known	O
Chinese	O
bowed-stringed	O
instrument,	O
to	O
experiment	O
with	O
our	O
method.	O
Because	O
of	O
the	O
limitation	O
of	O
FCN	O
,	O
we	O
present	O
an	O
algorithm	O
to	O
detect	O
on	O
variable	O
length	O
audio.	O
The	O
effectiveness	O
of	O
the	O
proposed	O
framework	O
is	O
tested	O
on	O
a	O
new	O
dataset,	O
its	O
categorization	O
of	O
techniques	O
is	O
similar	O
to	O
our	O
training	O
dataset.	O
The	O
highest	O
accuracy	O
of	O
our	O
3	O
experiments	O
on	O
the	O
new	O
test	O
set	O
is	O
87.31%.	O
Furthermore,	O
we	O
also	O
evaluate	O
the	O
performance	O
of	O
the	O
proposed	O
framework	O
on	O
10	O
real-world	O
studio	O
music	O
(produced	O
by	O
midi)	O
and	O
7	O
real-world	O
recording	O
samples	O
to	O
address	O
the	O
ability	O
of	O
generalization	O
on	O
our	O
model.	O

In	O
few-shot	O
learning	O
scenarios,	O
the	O
challenge	O
is	O
to	O
generalize	O
and	O
perform	O
well	O
on	O
new	O
unseen	O
examples	O
when	O
only	O
very	O
few	O
labeled	O
examples	O
are	O
available	O
for	O
each	O
task.	O
Model-agnostic	O
meta-learning	O
(MAML	O
)	O
has	O
gained	O
the	O
popularity	O
as	O
one	O
of	O
the	O
representative	O
few-shot	O
learning	O
methods	O
for	O
its	O
flexibility	O
and	O
applicability	O
to	O
diverse	O
problems.	O
However,	O
MAML	O
and	O
its	O
variants	O
often	O
resort	O
to	O
a	O
simple	O
loss	O
function	O
without	O
any	O
auxiliary	O
loss	O
function	O
or	O
regularization	O
terms	O
that	O
can	O
help	O
achieve	O
better	O
generalization.	O
The	O
problem	O
lies	O
in	O
that	O
each	O
application	O
and	O
task	O
may	O
require	O
different	O
auxiliary	O
loss	O
function,	O
especially	O
when	O
tasks	O
are	O
diverse	O
and	O
distinct.	O
Instead	O
of	O
attempting	O
to	O
hand-design	O
an	O
auxiliary	O
loss	O
function	O
for	O
each	O
application	O
and	O
task,	O
we	O
introduce	O
a	O
new	O
meta-learning	O
framework	O
with	O
a	O
loss	O
function	O
that	O
adapts	O
to	O
each	O
task.	O
Our	O
proposed	O
framework,	O
named	O
Meta-Learning	S-RESEARCH_PROBLEM
with	O
Task-Adaptive	O
Loss	O
Function	O
(MeTAL),	O
demonstrates	O
the	O
effectiveness	O
and	O
the	O
flexibility	O
across	O
various	O
domains,	O
such	O
as	O
few-shot	O
classification	O
and	O
few-shot	O
regression.	O

The	O
application	O
of	O
machine	O
learning(ML)	O
and	O
genetic	O
programming(GP)	O
to	O
the	O
image	O
compression	O
domain	O
has	O
produced	O
promising	O
results	O
in	O
many	O
cases.	O
The	O
need	O
for	O
compression	O
arises	O
due	O
to	O
the	O
exorbitant	O
size	O
of	O
data	O
shared	O
on	O
the	O
internet.	O
Compression	O
is	O
required	O
for	O
text,	O
videos,	O
or	O
images,	O
which	O
are	O
used	O
almost	O
everywhere	O
on	O
web	O
be	O
it	O
news	O
articles,	O
social	O
media	O
posts,	O
blogs,	O
educational	O
platforms,	O
medical	O
domain,	O
government	O
services,	O
and	O
many	O
other	O
websites,	O
need	O
packets	O
for	O
transmission	O
and	O
hence	O
compression	O
is	O
necessary	O
to	O
avoid	O
overwhelming	O
the	O
network.	O
This	O
paper	O
discusses	O
some	O
of	O
the	O
implementations	O
of	O
image	O
compression	O
algorithms	O
that	O
use	O
techniques	O
such	O
as	O
Artificial	O
Neural	O
Networks,	O
Residual	O
Learning,	O
Fuzzy	O
Neural	O
Networks,	O
Convolutional	O
Neural	O
Nets,	O
Deep	O
Learning,	O
Genetic	O
Algorithms.	O
The	O
paper	O
also	O
describes	O
an	O
implementation	O
of	O
Vector	O
Quantization	S-RESEARCH_PROBLEM
using	O
GA	O
to	O
generate	O
codebook	O
which	O
is	O
used	O
for	O
Lossy	O
image	O
compression.	O
All	O
these	O
approaches	O
prove	O
to	O
be	O
very	O
contrasting	O
to	O
the	O
standard	O
approaches	O
to	O
processing	O
images	O
due	O
to	O
the	O
highly	O
parallel	O
and	O
computationally	O
extensive	O
nature	O
of	O
machine	O
learning	O
algorithms.	O
Such	O
non-linear	O
abilities	O
of	O
ML	O
and	O
GP	O
make	O
it	O
widely	O
popular	O
for	O
use	O
in	O
multiple	O
domains.	O
Traditional	O
approaches	O
are	O
also	O
combined	O
with	O
artificially	O
intelligent	O
systems,	O
leading	O
to	O
hybrid	O
systems,	O
to	O
achieve	O
better	O
results.	O

Data	O
augmentation	O
has	O
been	O
an	O
indispensable	O
tool	O
to	O
improve	O
the	O
performance	O
of	O
deep	O
neural	O
networks,	O
however	O
the	O
augmentation	O
can	O
hardly	O
transfer	O
among	O
different	O
tasks	O
and	O
datasets.	O
Consequently,	O
a	O
recent	O
trend	O
is	O
to	O
adopt	O
AutoML	S-RESEARCH_PROBLEM
technique	O
to	O
learn	O
proper	O
augmentation	O
policy	O
without	O
extensive	O
hand-crafted	O
tuning.	O
In	O
this	O
paper,	O
we	O
propose	O
an	O
efficient	O
differentiable	O
search	O
algorithm	O
called	O
Direct	O
Differentiable	O
Augmentation	O
Search	O
(DDAS).	O
It	O
exploits	O
meta-learning	O
with	O
one-step	O
gradient	O
update	O
and	O
continuous	O
relaxation	O
to	O
the	O
expected	O
training	O
loss	O
for	O
efficient	O
search.	O
Our	O
DDAS	O
can	O
achieve	O
efficient	O
augmentation	O
search	O
without	O
relying	O
on	O
approximations	O
such	O
as	O
Gumbel	O
Softmax	O
or	O
second	O
order	O
gradient	O
approximation.	O
To	O
further	O
reduce	O
the	O
adverse	O
effect	O
of	O
improper	O
augmentations,	O
we	O
organize	O
the	O
search	O
space	O
into	O
a	O
two	O
level	O
hierarchy,	O
in	O
which	O
we	O
first	O
decide	O
whether	O
to	O
apply	O
augmentation,	O
and	O
then	O
determine	O
the	O
specific	O
augmentation	O
policy.	O
On	O
standard	O
image	O
classification	O
benchmarks,	O
our	O
DDAS	O
achieves	O
state-of-the-art	O
performance	O
and	O
efficiency	O
tradeoff	O
while	O
reducing	O
the	O
search	O
cost	O
dramatically,	O
e.g.	O
0.15	O
GPU	O
hours	O
for	O
CIFAR-10.	O
In	O
addition,	O
we	O
also	O
use	O
DDAS	O
to	O
search	O
augmentation	O
for	O
object	O
detection	O
task	O
and	O
achieve	O
comparable	O
performance	O
with	O
AutoAugment,	O
while	O
being	O
1000x	O
faster.	O

Compressive	B-RESEARCH_PROBLEM
Sensing	E-RESEARCH_PROBLEM
(CS)	O
is	O
an	O
effective	O
approach	O
for	O
fast	O
Magnetic	O
Resonance	O
Imaging	O
(MRI).	O
It	O
aims	O
at	O
reconstructing	O
MR	O
image	O
from	O
a	O
small	O
number	O
of	O
under-sampled	O
data	O
in	O
k-space,	O
and	O
accelerating	O
the	O
data	O
acquisition	O
in	O
MRI.	O
To	O
improve	O
the	O
current	O
MRI	O
system	O
in	O
reconstruction	O
accuracy	O
and	O
computational	O
speed,	O
in	O
this	O
paper,	O
we	O
propose	O
a	O
novel	O
deep	O
architecture,	O
dubbed	O
ADMM	O
-Net.	O
ADMM	O
-Net	O
is	O
defined	O
over	O
a	O
data	O
flow	O
graph,	O
which	O
is	O
derived	O
from	O
the	O
iterative	O
procedures	O
in	O
Alternating	O
Direction	O
Method	O
of	O
Multipliers	O
(ADMM	O
)	O
algorithm	O
for	O
optimizing	O
a	O
CS-based	O
MRI	O
model.	O
In	O
the	O
training	O
phase,	O
all	O
parameters	O
of	O
the	O
net,	O
e.g.,	O
image	O
transforms,	O
shrinkage	O
functions,	O
etc.,	O
are	O
discriminatively	O
trained	O
end-to-end	O
using	O
L-BFGS	O
algorithm.	O
In	O
the	O
testing	O
phase,	O
it	O
has	O
computational	O
overhead	O
similar	O
to	O
ADMM	O
but	O
uses	O
optimized	O
parameters	O
learned	O
from	O
the	O
training	O
data	O
for	O
CS-based	O
reconstruction	O
task.	O
Experiments	O
on	O
MRI	O
image	O
reconstruction	O
under	O
different	O
sampling	O
ratios	O
in	O
k-space	O
demonstrate	O
that	O
it	O
significantly	O
improves	O
the	O
baseline	O
ADMM	O
algorithm	O
and	O
achieves	O
high	O
reconstruction	O
accuracies	O
with	O
fast	O
computational	O
speed.	O

We	O
develop	O
a	O
Vector	O
Quantized	O
Spectral	O
Clustering	O
(VQSC)	O
algorithm	O
that	O
is	O
acombination	O
of	O
Spectral	O
Clustering	O
(SC)	O
and	O
Vector	O
Quantization	S-RESEARCH_PROBLEM
(VQ)	O
samplingfor	O
grouping	O
Soybean	O
genomes.	O
The	O
inspiration	O
here	O
is	O
to	O
use	O
SC	O
for	O
itsaccuracy	O
and	O
VQ	O
to	O
make	O
the	O
algorithm	O
computationally	O
cheap	O
(the	O
complexity	O
ofSC	O
is	O
cubic	O
in-terms	O
of	O
the	O
input	O
size).	O
Although	O
the	O
combination	O
of	O
SC	O
and	O
VQis	O
not	O
new,	O
the	O
novelty	O
of	O
our	O
work	O
is	O
in	O
developing	O
the	O
crucial	O
similaritymatrix	O
in	O
SC	O
as	O
well	O
as	O
use	O
of	O
k-medoids	O
in	O
VQ,	O
both	O
adapted	O
for	O
the	O
Soybeangenome	O
data.	O
We	O
compare	O
our	O
approach	O
with	O
commonly	O
used	O
techniques	O
like	O
UPGMA(Un-weighted	O
Pair	O
Graph	O
Method	O
with	O
Arithmetic	O
Mean)	O
and	O
NJ	O
(NeighbourJoining).	O
Experimental	O
results	O
show	O
that	O
our	O
approach	O
outperforms	O
both	O
thesetechniques	O
significantly	O
in	O
terms	O
of	O
cluster	O
quality	O
(up	O
to	O
25%	O
better	O
clusterquality)	O
and	O
time	O
complexity	O
(order	O
of	O
magnitude	O
faster).	O

In	O
this	O
work,	O
we	O
present	O
a	O
unified	O
model	O
that	O
can	O
handle	O
both	O
Keyword	B-RESEARCH_PROBLEM
Spotting	E-RESEARCH_PROBLEM
and	O
Word	O
Recognition	O
with	O
the	O
same	O
network	O
architecture.	O
The	O
proposed	O
network	O
is	O
comprised	O
of	O
a	O
non-recurrent	O
CTC	O
branch	O
and	O
a	O
Seq2Seq	O
branch	O
that	O
is	O
further	O
augmented	O
with	O
an	O
Autoencoding	O
module.	O
The	O
related	O
joint	O
loss	O
leads	O
to	O
a	O
boost	O
in	O
recognition	O
performance,	O
while	O
the	O
Seq2Seq	O
branch	O
is	O
used	O
to	O
create	O
efficient	O
word	O
representations.	O
We	O
show	O
how	O
to	O
further	O
process	O
these	O
representations	O
with	O
binarization	O
and	O
a	O
retraining	O
scheme	O
to	O
provide	O
compact	O
and	O
highly	O
efficient	O
descriptors,	O
suitable	O
for	O
keyword	O
spotting.	O
Numerical	O
results	O
validate	O
the	O
usefulness	O
of	O
the	O
proposed	O
architecture,	O
as	O
our	O
method	O
outperforms	O
the	O
previous	O
state-of-the-art	O
in	O
keyword	O
spotting,	O
and	O
provides	O
results	O
in	O
the	O
ballpark	O
of	O
the	O
leading	O
methods	O
for	O
word	O
recognition.	O

Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER)	O
is	O
a	O
fundamental	O
Natural	O
Language	O
Processing	O
(NLP)	O
task	O
and	O
has	O
remained	O
an	O
active	O
research	O
field.	O
In	O
recent	O
years,	O
transformer	O
models	O
and	O
more	O
specifically	O
the	O
BERT	O
model	O
developed	O
at	O
Google	O
revolutionised	O
the	O
field	O
of	O
NLP.	O
While	O
the	O
performance	O
of	O
transformer-based	O
approaches	O
such	O
as	O
BERT	O
has	O
been	O
studied	O
for	O
NER,	O
there	O
has	O
not	O
yet	O
been	O
a	O
study	O
for	O
the	O
fine-grained	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(FG-NER)	O
task.	O
In	O
this	O
paper,	O
we	O
compare	O
three	O
transformer-based	O
models	O
(BERT	O
,	O
RoBERT	O
a,	O
and	O
XLNet)	O
to	O
two	O
non-transformer-based	O
models	O
(CRF	O
and	O
BiLSTM-CNN-CRF).	O
Furthermore,	O
we	O
apply	O
each	O
model	O
to	O
a	O
multitude	O
of	O
distinct	O
domains.	O
We	O
find	O
that	O
transformer-based	O
models	O
incrementally	O
outperform	O
the	O
studied	O
non-transformer-based	O
models	O
in	O
most	O
domains	O
with	O
respect	O
to	O
the	O
F1	O
score.	O
Furthermore,	O
we	O
find	O
that	O
the	O
choice	O
of	O
domains	O
significantly	O
influenced	O
the	O
performance	O
regardless	O
of	O
the	O
respective	O
data	O
size	O
or	O
the	O
model	O
chosen.	O

Differentiable	O
ARchiTecture	O
Search	O
(DARTS	O
)	O
uses	O
a	O
continuous	O
relaxation	O
of	O
network	O
representation	O
and	O
dramatically	O
accelerates	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(NAS)	O
by	O
almost	O
thousands	O
of	O
times	O
in	O
GPU-day.	O
However,	O
the	O
searching	O
process	O
of	O
DARTS	O
is	O
unstable,	O
which	O
suffers	O
severe	O
degradation	O
when	O
training	O
epochs	O
become	O
large,	O
thus	O
limiting	O
its	O
application.	O
In	O
this	O
paper,	O
we	O
claim	O
that	O
this	O
degradation	O
issue	O
is	O
caused	O
by	O
the	O
imbalanced	O
norms	O
between	O
different	O
nodes	O
and	O
the	O
highly	O
correlated	O
outputs	O
from	O
various	O
operations.	O
We	O
then	O
propose	O
an	O
improved	O
version	O
of	O
DARTS	O
,	O
namely	O
iDARTS	O
,	O
to	O
deal	O
with	O
the	O
two	O
problems.	O
In	O
the	O
training	O
phase,	O
it	O
introduces	O
node	O
normalization	O
to	O
maintain	O
the	O
norm	O
balance.	O
In	O
the	O
discretization	O
phase,	O
the	O
continuous	O
architecture	O
is	O
approximated	O
based	O
on	O
the	O
similarity	O
between	O
the	O
outputs	O
of	O
the	O
node	O
and	O
the	O
decorrelated	O
operations	O
rather	O
than	O
the	O
values	O
of	O
the	O
architecture	O
parameters.	O
Extensive	O
evaluation	O
is	O
conducted	O
on	O
CIFAR-10	O
and	O
ImageNet,	O
and	O
the	O
error	O
rates	O
of	O
2.25\%	O
and	O
24.7\%	O
are	O
reported	O
within	O
0.2	O
and	O
1.9	O
GPU-day	O
for	O
architecture	O
search	O
respectively,	O
which	O
shows	O
its	O
effectiveness.	O
Additional	O
analysis	O
also	O
reveals	O
that	O
iDARTS	O
has	O
the	O
advantage	O
in	O
robustness	O
and	O
generalization	O
over	O
other	O
DARTS	O
-based	O
counterparts.	O

This	O
paper	O
presents	O
to	O
integrate	O
the	O
auxiliary	O
information	O
(e.g.,	O
additional	O
attributes	O
for	O
data	O
such	O
as	O
the	O
hashtags	O
for	O
Instagram	O
images)	O
in	O
the	O
self-supervised	O
learning	O
process.	O
We	O
first	O
observe	O
that	O
the	O
auxiliary	O
information	O
may	O
bring	O
us	O
useful	O
information	O
about	O
data	O
structures:	O
for	O
instance,	O
the	O
Instagram	O
images	O
with	O
the	O
same	O
hashtags	O
can	O
be	O
semantically	O
similar.	O
Hence,	O
to	O
leverage	O
the	O
structural	O
information	O
from	O
the	O
auxiliary	O
information,	O
we	O
present	O
to	O
construct	O
data	O
clusters	O
according	O
to	O
the	O
auxiliary	O
information.	O
Then,	O
we	O
introduce	O
the	O
Clustering	O
InfoNCE	O
(Cl-InfoNCE	O
)	O
objective	O
that	O
learns	O
similar	O
representations	O
for	O
augmented	O
variants	O
of	O
data	O
from	O
the	O
same	O
cluster	O
and	O
dissimilar	O
representations	O
for	O
data	O
from	O
different	O
clusters.	O
Our	O
approach	O
contributes	O
as	O
follows:	O
1)	O
Comparing	O
to	O
conventional	O
self-supervised	O
representations,	O
the	O
auxiliary-information-infused	O
self-supervised	O
representations	O
bring	O
the	O
performance	O
closer	O
to	O
the	O
supervised	O
representations;	O
2)	O
The	O
presented	O
Cl-InfoNCE	O
can	O
also	O
work	O
with	O
unsupervised	O
constructed	O
clusters	O
(e.g.,	O
k-means	O
clusters)	O
and	O
outperform	O
strong	O
clustering-based	O
self-supervised	O
learning	O
approaches,	O
such	O
as	O
the	O
Prototypical	O
Contrastive	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(PCL)	O
method;	O
3)	O
We	O
show	O
that	O
Cl-InfoNCE	O
may	O
be	O
a	O
better	O
approach	O
to	O
leverage	O
the	O
data	O
clustering	O
information,	O
by	O
comparing	O
it	O
to	O
the	O
baseline	O
approach	O
-	O
learning	O
to	O
predict	O
the	O
clustering	O
assignments	O
with	O
cross-entropy	O
loss.	O
For	O
analysis,	O
we	O
connect	O
the	O
goodness	O
of	O
the	O
learned	O
representations	O
with	O
the	O
statistical	O
relationships:	O
i)	O
the	O
mutual	O
information	O
between	O
the	O
labels	O
and	O
the	O
clusters	O
and	O
ii)	O
the	O
conditional	O
entropy	O
of	O
the	O
clusters	O
given	O
the	O
labels.	O

Question	B-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
(QA)	O
is	O
a	O
widely-used	O
framework	O
for	O
developing	O
and	O
evaluating	O
an	O
intelligent	O
machine.	O
In	O
this	O
light,	O
QA	O
on	O
Electronic	O
Health	O
Records	O
(EHR),	O
namely	O
EHR	O
QA,	O
can	O
work	O
as	O
a	O
crucial	O
milestone	O
towards	O
developing	O
an	O
intelligent	O
agent	O
in	O
healthcare.	O
EHR	O
data	O
are	O
typically	O
stored	O
in	O
a	O
relational	O
database,	O
which	O
can	O
also	O
be	O
converted	O
to	O
a	O
directed	O
acyclic	O
graph,	O
allowing	O
two	O
approaches	O
for	O
EHR	O
QA:	O
Table-based	O
QA	O
and	O
Knowledge	O
Graph-based	O
QA.	O
We	O
hypothesize	O
that	O
the	O
graph-based	O
approach	O
is	O
more	O
suitable	O
for	O
EHR	O
QA	O
as	O
graphs	O
can	O
represent	O
relations	O
between	O
entities	O
and	O
values	O
more	O
naturally	O
compared	O
to	O
tables,	O
which	O
essentially	O
require	O
JOIN	O
operations.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
graph-based	O
EHR	O
QA	O
where	O
natural	O
language	O
queries	O
are	O
converted	O
to	O
SPARQL	O
instead	O
of	O
SQL.	O
To	O
validate	O
our	O
hypothesis,	O
we	O
create	O
four	O
EHR	O
QA	O
datasets	O
(graph-based	O
VS	O
table-based,	O
and	O
simplified	O
database	O
schema	O
VS	O
original	O
database	O
schema),	O
based	O
on	O
a	O
table-based	O
dataset	O
MIMICSQL.	O
We	O
test	O
both	O
a	O
simple	O
Seq2Seq	O
model	O
and	O
a	O
state-of-the-art	O
EHR	O
QA	O
model	O
on	O
all	O
datasets	O
where	O
the	O
graph-based	O
datasets	O
facilitated	O
up	O
to	O
34%	O
higher	O
accuracy	O
than	O
the	O
table-based	O
dataset	O
without	O
any	O
modification	O
to	O
the	O
model	O
architectures.	O
Finally,	O
all	O
datasets	O
are	O
open-sourced	O
to	O
encourage	O
further	O
EHR	O
QA	O
research	O
in	O
both	O
directions.	O

Anomaly	O
detection	O
is	O
a	O
significant	O
and	O
hence	O
well-studied	O
problem.	O
However,developing	O
effective	O
anomaly	O
detection	O
methods	O
for	O
complex	O
and	O
high-dimensionaldata	O
remains	O
a	O
challenge.	O
As	O
Generative	O
Adversarial	O
Networks	O
(GAN	O
s)	O
are	O
able	O
tomodel	O
the	O
complex	O
high-dimensional	O
distributions	O
of	O
real-world	O
data,	O
they	O
offera	O
promising	O
approach	O
to	O
address	O
this	O
challenge.	O
In	O
this	O
work,	O
we	O
propose	O
ananomaly	O
detection	O
method,	O
Adversarially	O
Learned	O
Anomaly	B-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
(ALAD)	O
basedon	O
bi-directional	O
GAN	O
s,	O
that	O
derives	O
adversarially	O
learned	O
features	O
for	O
theanomaly	O
detection	O
task.	O
ALAD	O
then	O
uses	O
reconstruction	O
errors	O
based	O
on	O
theseadversarially	O
learned	O
features	O
to	O
determine	O
if	O
a	O
data	O
sample	O
is	O
anomalous.	O
ALADbuilds	O
on	O
recent	O
advances	O
to	O
ensure	O
data-space	O
and	O
latent-spacecycle-consistencies	O
and	O
stabilize	O
GAN	O
training,	O
which	O
results	O
in	O
significantlyimproved	O
anomaly	O
detection	O
performance.	O
ALAD	O
achieves	O
state-of-the-artperformance	O
on	O
a	O
range	O
of	O
image	O
and	O
tabular	O
datasets	O
while	O
being	O
severalhundred-fold	O
faster	O
at	O
test	O
time	O
than	O
the	O
only	O
published	O
GAN	O
-based	O
method.	O

Currently,	O
many	O
applications	O
in	O
Machine	O
Learning	O
are	O
based	O
on	O
define	O
new	O
models	O
to	O
extract	O
more	O
information	O
about	O
data,	O
In	O
this	O
case	O
Deep	O
Reinforcement	O
Learning	O
with	O
the	O
most	O
common	O
application	O
in	O
video	O
games	O
like	O
Atari,	O
Mario,	O
and	O
others	O
causes	O
an	O
impact	O
in	O
how	O
to	O
computers	O
can	O
learning	O
by	O
himself	O
with	O
only	O
information	O
called	O
rewards	O
obtained	O
from	O
any	O
action.	O
There	O
is	O
a	O
lot	O
of	O
algorithms	O
modeled	O
and	O
implemented	O
based	O
on	O
Deep	O
Recurrent	O
Q-Learning	S-RESEARCH_PROBLEM
proposed	O
by	O
DeepMind	O
used	O
in	O
AlphaZero	O
and	O
Go.	O
In	O
this	O
document,	O
We	O
proposed	O
Deep	O
Recurrent	O
Double	O
Q-Learning	S-RESEARCH_PROBLEM
that	O
is	O
an	O
implementation	O
of	O
Deep	O
Reinforcement	O
Learning	O
using	O
Double	O
Q-Learning	S-RESEARCH_PROBLEM
algorithms	O
and	O
Recurrent	O
Networks	O
like	O
LSTM	O
and	O
DRQN.	O

Plot-based	O
Graphic	O
API	O
recommendation	O
(Plot2API)	O
is	O
an	O
unstudied	O
but	O
meaningful	O
issue,	O
which	O
has	O
several	O
important	O
applications	O
in	O
the	O
context	O
of	O
software	O
engineering	O
and	O
data	O
visualization,	O
such	O
as	O
the	O
plotting	O
guidance	O
of	O
the	O
beginner,	O
graphic	O
API	O
correlation	O
analysis,	O
and	O
code	O
conversion	O
for	O
plotting.	O
Plot2API	O
is	O
a	O
very	O
challenging	O
task,	O
since	O
each	O
plot	O
is	O
often	O
associated	O
with	O
multiple	O
APIs	O
and	O
the	O
appearances	O
of	O
the	O
graphics	O
drawn	O
by	O
the	O
same	O
API	O
can	O
be	O
extremely	O
varied	O
due	O
to	O
the	O
different	O
settings	O
of	O
the	O
parameters.	O
Additionally,	O
the	O
samples	O
of	O
different	O
APIs	O
also	O
suffer	O
from	O
extremely	O
imbalanced.	O
Considering	O
the	O
lack	O
of	O
technologies	O
in	O
Plot2API,	O
we	O
present	O
a	O
novel	O
deep	O
multi-task	O
learning	O
approach	O
named	O
Semantic	B-RESEARCH_PROBLEM
Parsing	E-RESEARCH_PROBLEM
Guided	O
Neural	O
Network	O
(SPGNN)	O
which	O
translates	O
the	O
Plot2API	O
issue	O
as	O
a	O
multi-label	O
image	O
classification	O
and	O
an	O
image	O
semantic	O
parsing	O
tasks	O
for	O
the	O
solution.	O
In	O
SPGNN,	O
the	O
recently	O
advanced	O
Convolutional	O
Neural	O
Network	O
(CNN)	O
named	O
EfficientNet	O
is	O
employed	O
as	O
the	O
backbone	O
network	O
for	O
API	O
recommendation.	O
Meanwhile,	O
a	O
semantic	O
parsing	O
module	O
is	O
complemented	O
to	O
exploit	O
the	O
semantic	O
relevant	O
visual	O
information	O
in	O
feature	O
learning	O
and	O
eliminate	O
the	O
appearance-relevant	O
visual	O
information	O
which	O
may	O
confuse	O
the	O
visual-information-based	O
API	O
recommendation.	O
Moreover,	O
the	O
recent	O
data	O
augmentation	O
technique	O
named	O
random	O
erasing	O
is	O
also	O
applied	O
for	O
alleviating	O
the	O
imbalance	O
of	O
API	O
categories.	O
We	O
collect	O
plots	O
with	O
the	O
graphic	O
APIs	O
used	O
to	O
drawn	O
them	O
from	O
Stack	O
Overflow,	O
and	O
release	O
three	O
new	O
Plot2API	O
datasets	O
corresponding	O
to	O
the	O
graphic	O
APIs	O
of	O
R	O
and	O
Python	O
programming	O
languages	O
for	O
evaluating	O
the	O
effectiveness	O
of	O
Plot2API	O
techniques.	O
Extensive	O
experimental	O
results	O
not	O
only	O
demonstrate	O
the	O
superiority	O
of	O
our	O
method	O
over	O
the	O
recent	O
deep	O
learning	O
baselines	O
but	O
also	O
show	O
the	O
practicability	O
of	O
our	O
method	O
in	O
the	O
recommendation	O
of	O
graphic	O
APIs.	O

Polyphone	B-RESEARCH_PROBLEM
disambiguation	E-RESEARCH_PROBLEM
serves	O
as	O
an	O
essential	O
part	O
of	O
Mandarin	O
text-to-speech	O
(TTS)	O
system.	O
However,	O
conventional	O
system	O
modeling	O
the	O
entire	O
Pinyin	O
set	O
causes	O
the	O
case	O
that	O
prediction	O
belongs	O
to	O
the	O
unrelated	O
polyphonic	O
character	O
instead	O
of	O
the	O
current	O
input	O
one,	O
which	O
has	O
negative	O
impacts	O
on	O
TTS	O
performance.	O
To	O
address	O
this	O
issue,	O
we	O
introduce	O
a	O
mask-based	O
model	O
for	O
polyphone	O
disambiguation.	O
The	O
model	O
takes	O
a	O
mask	O
vector	O
extracted	O
from	O
the	O
context	O
as	O
an	O
extra	O
input.	O
In	O
our	O
model,	O
the	O
mask	O
vector	O
not	O
only	O
acts	O
as	O
a	O
weighting	O
factor	O
in	O
Weightedsoftmax	O
to	O
prevent	O
the	O
case	O
of	O
mis-prediction	O
but	O
also	O
eliminates	O
the	O
contribution	O
of	O
non-candidate	O
set	O
to	O
the	O
overall	O
loss.	O
Moreover,	O
to	O
mitigate	O
the	O
uneven	O
distribution	O
of	O
pronunciation,	O
we	O
introduce	O
a	O
new	O
loss	O
called	O
Modified	O
Focal	O
Loss	O
.	O
The	O
experimental	O
result	O
shows	O
the	O
effectiveness	O
of	O
the	O
proposed	O
mask	O
based	O
model.	O
We	O
also	O
empirically	O
studied	O
the	O
impact	O
of	O
Weighted-softmax	O
and	O
Modified	O
Focal	O
Loss	O
.	O
It	O
was	O
found	O
that	O
Weighted-softmax	O
can	O
effectively	O
prevent	O
the	O
model	O
from	O
predicting	O
outside	O
the	O
candidate	O
set.	O
Besides,	O
Modified	O
Focal	O
Loss	O
can	O
reduce	O
the	O
adverse	O
impacts	O
of	O
the	O
uneven	O
distribution	O
of	O
pronunciation.	O

We	O
present	O
our	O
contribution	O
to	O
the	O
EvaLatin	O
shared	O
task,	O
which	O
is	O
the	O
first	O
evaluation	O
campaign	O
devoted	O
to	O
the	O
evaluation	O
of	O
NLP	O
tools	O
for	O
Latin.	O
We	O
submitted	O
a	O
system	O
based	O
on	O
UDPipe	O
2.0,	O
one	O
of	O
the	O
winners	O
of	O
the	O
CoNLL	O
2018	O
Shared	O
Task,	O
The	O
2018	O
Shared	O
Task	O
on	O
Extrinsic	O
Parser	O
Evaluation	O
and	O
SIGMORPHON	O
2019	O
Shared	O
Task.	O
Our	O
system	O
places	O
first	O
by	O
a	O
wide	O
margin	O
both	O
in	O
lemmatization	O
and	O
POS	S-RESEARCH_PROBLEM
tagging	O
in	O
the	O
open	O
modality,	O
where	O
additional	O
supervised	O
data	O
is	O
allowed,	O
in	O
which	O
case	O
we	O
utilize	O
all	O
Universal	O
Dependency	O
Latin	O
treebanks.	O
In	O
the	O
closed	O
modality,	O
where	O
only	O
the	O
EvaLatin	O
training	O
data	O
is	O
allowed,	O
our	O
system	O
achieves	O
the	O
best	O
performance	O
in	O
lemmatization	O
and	O
in	O
classical	O
subtask	O
of	O
POS	S-RESEARCH_PROBLEM
tagging,	O
while	O
reaching	O
second	O
place	O
in	O
cross-genre	O
and	O
cross-time	O
settings.	O
In	O
the	O
ablation	O
experiments,	O
we	O
also	O
evaluate	O
the	O
influence	O
of	O
BERT	O
and	O
XLM-RoBERT	O
a	O
contextualized	O
embeddings,	O
and	O
the	O
treebank	O
encodings	O
of	O
the	O
different	O
flavors	O
of	O
Latin	O
treebanks.	O

This	O
paper	O
describes	O
the	O
BLCU	O
Group	O
submissions	O
to	O
the	O
Building	O
Educational	O
Applications	O
(BEA)	O
2019	O
Shared	O
Task	O
on	O
Grammatical	B-RESEARCH_PROBLEM
Error	I-RESEARCH_PROBLEM
Correction	E-RESEARCH_PROBLEM
(GEC).	O
The	O
task	O
is	O
to	O
detect	O
and	O
correct	O
grammatical	O
errors	O
that	O
occurred	O
in	O
essays.	O
We	O
participate	O
in	O
2	O
tracks	O
including	O
the	O
Restricted	O
Track	O
and	O
the	O
Unrestricted	O
Track.	O
Our	O
system	O
is	O
based	O
on	O
a	O
Transformer	O
model	O
architecture.	O
We	O
integrate	O
many	O
effective	O
methods	O
proposed	O
in	O
recent	O
years.	O
Such	O
as,	O
Byte	O
Pair	O
Encoding,	O
model	O
ensemble,	O
checkpoints	O
average	O
and	O
spell	O
checker.	O
We	O
also	O
corrupt	O
the	O
public	O
monolingual	O
data	O
to	O
further	O
improve	O
the	O
performance	O
of	O
the	O
model.	O
On	O
the	O
test	O
data	O
of	O
the	O
BEA	O
2019	O
Shared	O
Task,	O
our	O
system	O
yields	O
F0.5	O
=	O
58.62	O
and	O
59.50,	O
ranking	O
twelfth	O
and	O
fourth	O
respectively.	O

The	O
breakthrough	O
of	O
deep	O
Q-Learning	S-RESEARCH_PROBLEM
on	O
different	O
types	O
of	O
environments	O
revolutionized	O
the	O
algorithmic	O
design	O
of	O
Reinforcement	O
Learning	O
to	O
introduce	O
more	O
stable	O
and	O
robust	O
algorithms,	O
to	O
that	O
end	O
many	O
extensions	O
to	O
deep	O
Q-Learning	S-RESEARCH_PROBLEM
algorithm	O
have	O
been	O
proposed	O
to	O
reduce	O
the	O
variance	O
of	O
the	O
target	O
values	O
and	O
the	O
overestimation	O
phenomena.	O
In	O
this	O
paper,	O
we	O
examine	O
new	O
methodology	O
to	O
solve	O
these	O
issues,	O
we	O
propose	O
using	O
Dropout	O
techniques	O
on	O
deep	O
Q-Learning	S-RESEARCH_PROBLEM
algorithm	O
as	O
a	O
way	O
to	O
reduce	O
variance	O
and	O
overestimation.	O
We	O
further	O
present	O
experiments	O
on	O
some	O
of	O
the	O
benchmark	O
environments	O
that	O
demonstrate	O
significant	O
improvement	O
of	O
the	O
stability	O
of	O
the	O
performance	O
and	O
a	O
reduction	O
in	O
variance	O
and	O
overestimation.	O

Zero-Shot	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(ZSL)	O
aims	O
to	O
recognise	O
unseen	O
object	O
classes,	O
which	O
are	O
not	O
observed	O
during	O
the	O
training	O
phase.	O
The	O
existing	O
body	O
of	O
works	O
on	O
ZSL	O
mostly	O
relies	O
on	O
pretrained	O
visual	O
features	O
and	O
lacks	O
the	O
explicit	O
attribute	O
localisation	O
mechanism	O
on	O
images.	O
In	O
this	O
work,	O
we	O
propose	O
an	O
attention-based	O
model	O
in	O
the	O
problem	O
settings	O
of	O
ZSL	O
to	O
learn	O
attributes	O
useful	O
for	O
unseen	O
class	O
recognition.	O
Our	O
method	O
uses	O
an	O
attention	O
mechanism	O
adapted	O
from	O
Vision	O
Transformer	O
to	O
capture	O
and	O
learn	O
discriminative	O
attributes	O
by	O
splitting	O
images	O
into	O
small	O
patches.	O
We	O
conduct	O
experiments	O
on	O
three	O
popular	O
ZSL	O
benchmarks	O
(i.e.,	O
AWA2,	O
CUB	O
and	O
SUN)	O
and	O
set	O
new	O
state-of-the-art	O
harmonic	O
mean	O
results	O
{on	O
all	O
the	O
three	O
datasets},	O
which	O
illustrate	O
the	O
effectiveness	O
of	O
our	O
proposed	O
method.	O

The	O
usefulness	O
and	O
value	O
of	O
Multi-step	O
Machine	O
Learning	O
(ML),	O
where	O
a	O
task	O
is	O
organized	O
into	O
connected	O
sub-tasks	O
with	O
known	O
intermediate	O
inference	O
goals,	O
as	O
opposed	O
to	O
a	O
single	O
large	O
model	O
learned	O
end-to-end	O
without	O
intermediate	O
sub-tasks,	O
is	O
presented.	O
Pre-optimized	O
ML	O
models	O
are	O
connected	O
and	O
better	O
performance	O
is	O
obtained	O
by	O
re-optimizing	O
the	O
connected	O
one.	O
The	O
selection	O
of	O
an	O
ML	O
model	O
from	O
several	O
small	O
ML	O
model	O
candidates	O
for	O
each	O
sub-task	O
has	O
been	O
performed	O
by	O
using	O
the	O
idea	O
based	O
on	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(NAS).	O
In	O
this	O
paper,	O
Differentiable	O
Architecture	O
Search	O
(DARTS	O
)	O
and	O
Single	O
Path	O
One-Shot	O
NAS	O
(SPOS-NAS)	O
are	O
tested,	O
where	O
the	O
construction	O
of	O
loss	O
functions	O
is	O
improved	O
to	O
keep	O
all	O
ML	O
models	O
smoothly	O
learning.	O
Using	O
DARTS	O
and	O
SPOS-NAS	O
as	O
an	O
optimization	O
and	O
selection	O
as	O
well	O
as	O
the	O
connections	O
for	O
multi-step	O
machine	O
learning	O
systems,	O
we	O
find	O
that	O
(1)	O
such	O
a	O
system	O
can	O
quickly	O
and	O
successfully	O
select	O
highly	O
performant	O
model	O
combinations,	O
and	O
(2)	O
the	O
selected	O
models	O
are	O
consistent	O
with	O
baseline	O
algorithms,	O
such	O
as	O
grid	O
search,	O
and	O
their	O
outputs	O
are	O
well	O
controlled.	O

Biomedical	O
data	O
are	O
widely	O
accepted	O
in	O
developing	O
prediction	O
models	O
for	O
identifying	O
a	O
specific	O
tumor,	O
drug	O
discovery	O
and	O
classification	O
of	O
human	O
cancers.	O
However,	O
previous	O
studies	O
usually	O
focused	O
on	O
different	O
classifiers,	O
and	O
overlook	O
the	O
class	O
imbalance	O
problem	O
in	O
real-world	O
biomedical	O
datasets.	O
There	O
are	O
a	O
lack	O
of	O
studies	O
on	O
evaluation	O
of	O
data	O
pre-processing	O
techniques,	O
such	O
as	O
resampling	O
and	O
feature	O
selection,	O
on	O
imbalanced	O
biomedical	O
data	O
learning.	O
The	O
relationship	O
between	O
data	O
pre-processing	O
techniques	O
and	O
the	O
data	O
distributions	O
has	O
never	O
been	O
analysed	O
in	O
previous	O
studies.	O
This	O
article	O
mainly	O
focuses	O
on	O
reviewing	O
and	O
evaluating	O
some	O
popular	O
and	O
recently	O
developed	O
resampling	O
and	O
feature	O
selection	O
methods	O
for	O
class	O
imbalance	O
learning.	O
We	O
analyse	O
the	O
effectiveness	O
of	O
each	O
technique	O
from	O
data	O
distribution	O
perspective.	O
Extensive	O
experiments	O
have	O
been	O
done	O
based	O
on	O
five	O
classifiers,	O
four	O
performance	O
measures,	O
eight	O
learning	O
techniques	O
across	O
twenty	O
real-world	O
datasets.	O
Experimental	O
results	O
show	O
that:	O
(1)	O
resampling	O
and	O
feature	O
selection	O
techniques	O
exhibit	O
better	O
performance	O
using	O
support	O
vector	O
machine	O
(SVM	O
)	O
classifier.	O
However,	O
resampling	O
and	O
Feature	B-RESEARCH_PROBLEM
Selection	E-RESEARCH_PROBLEM
techniques	O
perform	O
poorly	O
when	O
using	O
C4.5	O
decision	O
tree	O
and	O
Linear	O
discriminant	O
analysis	O
classifiers;	O
(2)	O
for	O
datasets	O
with	O
different	O
distributions,	O
techniques	O
such	O
as	O
Random	O
undersampling	O
and	O
Feature	B-RESEARCH_PROBLEM
Selection	E-RESEARCH_PROBLEM
perform	O
better	O
than	O
other	O
data	O
pre-processing	O
methods	O
with	O
T	O
Location-Scale	O
distribution	O
when	O
using	O
SVM	O
and	O
KNN	O
(K-nearest	O
neighbours)	O
classifiers.	O
Random	O
oversampling	O
outperforms	O
other	O
methods	O
on	O
Negative	O
Binomial	O
distribution	O
using	O
Random	O
Forest	O
classifier	O
with	O
lower	O
level	O
of	O
imbalance	O
ratio;	O
(3)	O
Feature	B-RESEARCH_PROBLEM
Selection	E-RESEARCH_PROBLEM
outperforms	O
other	O
data	O
pre-processing	O
methods	O
in	O
most	O
cases,	O
thus,	O
Feature	B-RESEARCH_PROBLEM
Selection	E-RESEARCH_PROBLEM
with	O
SVM	O
classifier	O
is	O
the	O
best	O
choice	O
for	O
imbalanced	O
biomedical	O
data	O
learning.	O

The	O
Transformer	O
has	O
shown	O
tremendous	O
progress	O
in	O
Automatic	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(ASR),	O
outperforming	O
recurrent	O
neural	O
network-based	O
approaches.	O
Transformer	O
architecture	O
is	O
good	O
at	O
parallelizing	O
data	O
to	O
accelerate	O
as	O
well	O
as	O
capturing	O
content-based	O
global	O
interaction.	O
However,	O
most	O
studies	O
with	O
Transformer	O
have	O
been	O
utilized	O
only	O
shallow	O
features	O
extracted	O
from	O
the	O
backbone	O
without	O
taking	O
advantage	O
of	O
the	O
deep	O
feature	O
that	O
possesses	O
invariant	O
property.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
novel	O
framework	O
with	O
the	O
Two	O
Streams	O
and	O
Two	O
Resolution	O
spectrograms	O
Model	O
(TSTRM)	O
that	O
consists	O
of	O
different	O
resolution	O
spectrograms	O
for	O
different	O
streams	O
aiming	O
to	O
capture	O
both	O
shallow	O
and	O
deep	O
features.	O
The	O
feature	O
extraction	O
module	O
consists	O
of	O
a	O
deep	O
network	O
for	O
low-resolution	O
spectrogram	O
and	O
a	O
shallow	O
network	O
for	O
high-resolution	O
spectrogram.	O
The	O
backbone	O
obtains	O
not	O
only	O
detailed	O
acoustic	O
information	O
for	O
speech-text	O
alignment	O
but	O
also	O
utterance-level	O
representation	O
that	O
contains	O
speaker	O
information.	O
Both	O
features	O
are	O
fused	O
with	O
our	O
proposed	O
fusion	O
method	O
and	O
then	O
input	O
into	O
the	O
Transformer	O
encoder-decoder.	O
The	O
proposed	O
framework	O
shows	O
the	O
state-of-the-art	O
results	O
on	O
the	O
HKUST	O
Mandarin	O
telephone	O
and	O
Librispeech	O
corpora.	O
To	O
the	O
best	O
of	O
our	O
knowledge,	O
this	O
is	O
the	O
first	O
investigation	O
of	O
incorporating	O
deep	O
features	O
to	O
the	O
backbone	O
and	O
use	O
both	O
low	O
and	O
high	O
resolutions	O
spectrogram	O
to	O
focus	O
on	O
global	O
and	O
local	O
information.	O
Code	O
is	O
available	O
at	O
https://github.com/happyjin/TSTRM	O

Incorporating	O
lexicons	O
into	O
character-level	O
Chinese	O
NER	S-RESEARCH_PROBLEM
by	O
lattices	O
is	O
proven	O
effective	O
to	O
exploitrich	O
word	O
boundary	O
information.	O
Previous	O
work	O
has	O
extended	O
RNNs	O
to	O
consume	O
lattice	O
inputsand	O
achieved	O
great	O
success.	O
However,	O
due	O
to	O
the	O
DAG	O
structure	O
and	O
the	O
inherently	O
unidirectionalsequential	O
nature,	O
this	O
method	O
precludes	O
batched	O
computation	O
and	O
sufficient	O
semantic	O
interaction.In	O
this	O
paper,	O
we	O
propose	O
PLTE,	O
an	O
extension	O
of	O
transformer	O
encoder	O
that	O
is	O
tailored	O
for	O
ChineseNER	S-RESEARCH_PROBLEM
,	O
which	O
models	O
all	O
the	O
characters	O
and	O
matched	O
lexical	O
words	O
in	O
parallel	O
with	O
batch	O
process-ing.	O
PLTE	O
augments	O
self-attention	O
with	O
positional	O
relation	O
representations	O
to	O
incorporate	O
latticestructure.	O
It	O
also	O
introduces	O
a	O
porous	O
mechanism	O
to	O
augment	O
localness	O
modeling	O
and	O
maintainthe	O
strength	O
of	O
capturing	O
the	O
rich	O
long-term	O
dependencies.	O
Experimental	O
results	O
show	O
that	O
PLTEperforms	O
up	O
to	O
11.4	O
times	O
faster	O
than	O
state-of-the-art	O
methods	O
while	O
realizing	O
better	O
performance.We	O
also	O
demonstrate	O
that	O
using	O
BERT	O
representations	O
further	O
substantially	O
boosts	O
the	O
performanceand	O
brings	O
out	O
the	O
best	O
in	O
PLTE.	O

Children	O
acquire	O
language	O
subconsciously	O
by	O
observing	O
the	O
surrounding	O
world	O
and	O
listening	O
to	O
descriptions.	O
They	O
can	O
discover	O
the	O
meaning	O
of	O
words	O
even	O
without	O
explicit	O
language	O
knowledge,	O
and	O
generalize	O
to	O
novel	O
compositions	O
effortlessly.	O
In	O
this	O
paper,	O
we	O
bring	O
this	O
ability	O
to	O
AI,	O
by	O
studying	O
the	O
task	O
of	O
Visually	O
grounded	O
Language	B-RESEARCH_PROBLEM
Acquisition	E-RESEARCH_PROBLEM
(VLA).	O
We	O
propose	O
a	O
multimodal	O
transformer	O
model	O
augmented	O
with	O
a	O
novel	O
mechanism	O
for	O
analogical	O
reasoning,	O
which	O
approximates	O
novel	O
compositions	O
by	O
learning	O
semantic	O
mapping	O
and	O
reasoning	O
operations	O
from	O
previously	O
seen	O
compositions.	O
Our	O
proposed	O
method,	O
Analogical	O
Reasoning	O
Transformer	O
Networks	O
(ARTNet),	O
is	O
trained	O
on	O
raw	O
multimedia	O
data	O
(video	O
frames	O
and	O
transcripts),	O
and	O
after	O
observing	O
a	O
set	O
of	O
compositions	O
such	O
as	O
"washing	O
apple"	O
or	O
"cutting	O
carrot",	O
it	O
can	O
generalize	O
and	O
recognize	O
new	O
compositions	O
in	O
new	O
video	O
frames,	O
such	O
as	O
"washing	O
carrot"	O
or	O
"cutting	O
apple".	O
To	O
this	O
end,	O
ARTNet	O
refers	O
to	O
relevant	O
instances	O
in	O
the	O
training	O
data	O
and	O
uses	O
their	O
visual	O
features	O
and	O
captions	O
to	O
establish	O
analogies	O
with	O
the	O
query	O
image.	O
Then	O
it	O
chooses	O
the	O
suitable	O
verb	O
and	O
noun	O
to	O
create	O
a	O
new	O
composition	O
that	O
describes	O
the	O
new	O
image	O
best.	O
Extensive	O
experiments	O
on	O
an	O
instructional	O
video	O
dataset	O
demonstrate	O
that	O
the	O
proposed	O
method	O
achieves	O
significantly	O
better	O
generalization	O
capability	O
and	O
recognition	O
accuracy	O
compared	O
to	O
state-of-the-art	O
transformer	O
models.	O

Large-scale	O
language	O
models	O
such	O
as	O
BERT	O
have	O
achieved	O
state-of-the-art	O
performance	O
across	O
a	O
wide	O
range	O
of	O
NLP	O
tasks.	O
Recent	O
studies,	O
however,	O
show	O
that	O
such	O
BERT	O
-based	O
models	O
are	O
vulnerable	O
facing	O
the	O
threats	O
of	O
textual	O
adversarial	O
attacks.	O
We	O
aim	O
to	O
address	O
this	O
problem	O
from	O
an	O
information-theoretic	O
perspective,	O
and	O
propose	O
InfoBERT	O
,	O
a	O
novel	O
learning	O
framework	O
for	O
robust	O
fine-tuning	O
of	O
pre-trained	O
language	O
models.	O
InfoBERT	O
contains	O
two	O
mutual-information-based	O
regularizers	O
for	O
model	O
training:	O
(i)	O
an	O
Information	O
Bottleneck	O
regularizer,	O
which	O
suppresses	O
noisy	O
mutual	O
information	O
between	O
the	O
input	O
and	O
the	O
feature	O
representation;	O
and	O
(ii)	O
a	O
Robust	O
Feature	O
regularizer,	O
which	O
increases	O
the	O
mutual	O
information	O
between	O
local	O
robust	O
features	O
and	O
global	O
features.	O
We	O
provide	O
a	O
principled	O
way	O
to	O
theoretically	O
analyze	O
and	O
improve	O
the	O
robustness	O
of	O
representation	O
learning	O
for	O
language	O
models	O
in	O
both	O
standard	O
and	O
adversarial	O
training.	O
Extensive	O
experiments	O
demonstrate	O
that	O
InfoBERT	O
achieves	O
state-of-the-art	O
robust	O
accuracy	O
over	O
several	O
adversarial	O
datasets	O
on	O
Natural	B-RESEARCH_PROBLEM
Language	I-RESEARCH_PROBLEM
Inference	E-RESEARCH_PROBLEM
(NLI)	O
and	O
Question	B-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
(QA)	O
tasks.	O
Our	O
code	O
is	O
available	O
at	O
https://github.com/AI-secure/InfoBERT	O
.	O

A	O
typical	O
pipeline	O
for	O
Zero-Shot	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(ZSL)	O
is	O
to	O
integrate	O
the	O
visualfeatures	O
and	O
the	O
class	O
semantic	O
descriptors	O
into	O
a	O
multimodal	O
framework	O
with	O
alinear	O
or	O
bilinear	O
model.	O
However,	O
the	O
visual	O
features	O
and	O
the	O
class	O
semanticdescriptors	O
locate	O
in	O
different	O
structural	O
spaces,	O
a	O
linear	O
or	O
bilinear	O
modelcan	O
not	O
capture	O
the	O
semantic	O
interactions	O
between	O
different	O
modalities	O
well.	O
Inthis	O
letter,	O
we	O
propose	O
a	O
nonlinear	O
approach	O
to	O
impose	O
ZSL	O
as	O
a	O
multi-classclassification	O
problem	O
via	O
a	O
Semantic	O
Softmax	O
Loss	O
by	O
embedding	O
the	O
classsemantic	O
descriptors	O
into	O
the	O
softmax	O
layer	O
of	O
multi-class	O
classificationnetwork.	O
To	O
narrow	O
the	O
structural	O
differences	O
between	O
the	O
visual	O
features	O
andsemantic	O
descriptors,	O
we	O
further	O
use	O
an	O
L2	O
normalization	O
constraint	O
to	O
thedifferences	O
between	O
the	O
visual	O
features	O
and	O
visual	O
prototypes	O
reconstructedwith	O
the	O
semantic	O
descriptors.	O
The	O
results	O
on	O
three	O
benchmark	O
datasets,	O
i.e.,AwA,	O
CUB	O
and	O
SUN	O
demonstrate	O
the	O
proposed	O
approach	O
can	O
boost	O
the	O
performancessteadily	O
and	O
achieve	O
the	O
state-of-the-art	O
performance	O
for	O
both	O
zero-shotclassification	O
and	O
zero-shot	O
retrieval.	O

Hand	O
gestures	O
form	O
an	O
intuitive	O
means	O
of	O
interaction	O
in	O
Mixed	B-RESEARCH_PROBLEM
Reality	E-RESEARCH_PROBLEM
(MR)applications.	O
However,	O
accurate	O
gesture	O
recognition	O
can	O
be	O
achieved	O
onlythrough	O
state-of-the-art	O
deep	O
learning	O
models	O
or	O
with	O
the	O
use	O
of	O
expensivesensors.	O
Despite	O
the	O
robustness	O
of	O
these	O
deep	O
learning	O
models,	O
they	O
aregenerally	O
computationally	O
expensive	O
and	O
obtaining	O
real-time	O
performanceon-device	O
is	O
still	O
a	O
challenge.	O
To	O
this	O
end,	O
we	O
propose	O
a	O
novel	O
lightweighthand	O
gesture	O
recognition	O
framework	O
that	O
works	O
in	O
First	O
Person	O
View	O
for	O
wearabledevices.	O
The	O
models	O
are	O
trained	O
on	O
a	O
GPU	O
machine	O
and	O
ported	O
on	O
an	O
Androidsmartphone	O
for	O
its	O
use	O
with	O
frugal	O
wearable	O
devices	O
such	O
as	O
the	O
GoogleCardboard	O
and	O
VR	O
Box.	O
The	O
proposed	O
hand	O
gesture	O
recognition	O
framework	O
is	O
drivenby	O
a	O
cascade	O
of	O
state-of-the-art	O
deep	O
learning	O
models:	O
MobileNetV2	O
for	O
handlocalisation,	O
our	O
custom	O
fingertip	O
regression	O
architecture	O
followed	O
by	O
aBi-LSTM	O
model	O
for	O
gesture	O
classification.	O
We	O
extensively	O
evaluate	O
the	O
frameworkon	O
our	O
EgoGestAR	O
dataset.	O
The	O
overall	O
framework	O
works	O
in	O
real-time	O
on	O
mobiledevices	O
and	O
achieves	O
a	O
classification	O
accuracy	O
of	O
80%	O
on	O
EgoGestAR	O
videodataset	O
with	O
an	O
average	O
latency	O
of	O
only	O
0.12	O
s.	O

In	O
this	O
work,	O
we	O
present	O
a	O
simple	O
and	O
general	O
search	O
space	O
shrinking	O
method,	O
called	O
Angle-Based	O
search	O
space	O
Shrinking	O
(ABS),	O
for	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(NAS).	O
Our	O
approach	O
progressively	O
simplifies	O
the	O
original	O
search	O
space	O
by	O
dropping	O
unpromising	O
candidates,	O
thus	O
can	O
reduce	O
difficulties	O
for	O
existing	O
NAS	O
methods	O
to	O
find	O
superior	O
architectures.	O
In	O
particular,	O
we	O
propose	O
an	O
angle-based	O
metric	O
to	O
guide	O
the	O
shrinking	O
process.	O
We	O
provide	O
comprehensive	O
evidences	O
showing	O
that,	O
in	O
weight-sharing	O
supernet,	O
the	O
proposed	O
metric	O
is	O
more	O
stable	O
and	O
accurate	O
than	O
accuracy-based	O
and	O
magnitude-based	O
metrics	O
to	O
predict	O
the	O
capability	O
of	O
child	O
models.	O
We	O
also	O
show	O
that	O
the	O
angle-based	O
metric	O
can	O
converge	O
fast	O
while	O
training	O
supernet,	O
enabling	O
us	O
to	O
get	O
promising	O
shrunk	O
search	O
spaces	O
efficiently.	O
ABS	O
can	O
easily	O
apply	O
to	O
most	O
of	O
NAS	O
approaches	O
(e.g.	O
SPOS,	O
FairNAS,	O
ProxylessNAS,	O
DARTS	O
and	O
PDARTS	O
).	O
Comprehensive	O
experiments	O
show	O
that	O
ABS	O
can	O
dramatically	O
enhance	O
existing	O
NAS	O
approaches	O
by	O
providing	O
a	O
promising	O
shrunk	O
search	O
space.	O

Convolutional	O
Neural	O
Networks	O
(CNNs)	O
have	O
proven	O
very	O
effective	O
in	O
imageclassification	O
and	O
show	O
promise	O
for	O
audio.	O
We	O
use	O
various	O
CNN	O
architectures	O
toclassify	O
the	O
soundtracks	O
of	O
a	O
dataset	O
of	O
70M	O
training	O
videos	O
(5.24	O
millionhours)	O
with	O
30,871	O
video-level	O
labels.	O
We	O
examine	O
fully	O
connected	O
Deep	O
NeuralNetworks	O
(DNNs),	O
AlexNet	O
[1],	O
VGG	O
[2],	O
Inception	O
[3],	O
and	O
ResNet	O
[4].	O
Weinvestigate	O
varying	O
the	O
size	O
of	O
both	O
training	O
set	O
and	O
label	O
vocabulary,	O
findingthat	O
analogs	O
of	O
the	O
CNNs	O
used	O
in	O
image	O
classification	O
do	O
well	O
on	O
our	O
audioclassification	O
task,	O
and	O
larger	O
training	O
and	O
label	O
sets	O
help	O
up	O
to	O
a	O
point.	O
Amodel	O
using	O
embeddings	O
from	O
these	O
classifiers	O
does	O
much	O
better	O
than	O
rawfeatures	O
on	O
the	O
Audio	O
Set	O
[5]	O
Acoustic	O
Event	B-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
(AED)	O
classificationtask.	O

Generating	O
longer	O
textual	O
sequences	O
when	O
conditioned	O
on	O
the	O
visual	O
information	O
is	O
an	O
interesting	O
problem	O
to	O
explore.	O
The	O
challenge	O
here	O
proliferate	O
over	O
the	O
standard	O
vision	O
conditioned	O
sentence-level	O
generation	O
(e.g.,	O
image	O
or	O
video	O
captioning)	O
as	O
it	O
requires	O
to	O
produce	O
a	O
brief	O
and	O
coherent	O
story	O
describing	O
the	O
visual	O
content.	O
In	O
this	O
paper,	O
we	O
mask	O
this	O
Vision-to-Sequence	O
as	O
Graph-to-Sequence	S-RESEARCH_PROBLEM
learning	O
problem	O
and	O
approach	O
it	O
with	O
the	O
Transformer	O
architecture.	O
To	O
be	O
specific,	O
we	O
introduce	O
Sparse	O
Graph-to-Sequence	S-RESEARCH_PROBLEM
Transformer	O
(SGST)	O
for	O
encoding	O
the	O
graph	O
and	O
decoding	O
a	O
sequence.	O
The	O
encoder	O
aims	O
to	O
directly	O
encode	O
graph-level	O
semantics,	O
while	O
the	O
decoder	O
is	O
used	O
to	O
generate	O
longer	O
sequences.	O
Experiments	O
conducted	O
with	O
the	O
benchmark	O
image	O
paragraph	O
dataset	O
show	O
that	O
our	O
proposed	O
achieve	O
13.3%	O
improvement	O
on	O
the	O
CIDEr	O
evaluation	O
measure	O
when	O
comparing	O
to	O
the	O
previous	O
state-of-the-art	O
approach.	O

Recently,	O
remarkable	O
progress	O
has	O
been	O
made	O
in	O
learning	O
transferable	O
representation	O
across	O
domains.	O
Previous	O
works	O
in	O
domain	O
adaptation	O
are	O
majorly	O
based	O
on	O
two	O
techniques:	O
domain-adversarial	O
learning	O
and	O
self-training.	O
However,	O
domain-adversarial	O
learning	O
only	O
aligns	O
feature	O
distributions	O
between	O
domains	O
but	O
does	O
not	O
consider	O
whether	O
the	O
target	O
features	O
are	O
discriminative.	O
On	O
the	O
other	O
hand,	O
self-training	O
utilizes	O
the	O
model	O
predictions	O
to	O
enhance	O
the	O
discrimination	O
of	O
target	O
features,	O
but	O
it	O
is	O
unable	O
to	O
explicitly	O
align	O
domain	O
distributions.	O
In	O
order	O
to	O
combine	O
the	O
strengths	O
of	O
these	O
two	O
methods,	O
we	O
propose	O
a	O
novel	O
method	O
called	O
Adversarial-Learned	O
Loss	O
for	O
Domain	B-RESEARCH_PROBLEM
Adaptation	E-RESEARCH_PROBLEM
(ALDA	O
).	O
We	O
first	O
analyze	O
the	O
pseudo-label	O
method,	O
a	O
typical	O
self-training	O
method.	O
Nevertheless,	O
there	O
is	O
a	O
gap	O
between	O
pseudo-labels	O
and	O
the	O
ground	O
truth,	O
which	O
can	O
cause	O
incorrect	O
training.	O
Thus	O
we	O
introduce	O
the	O
confusion	O
matrix,	O
which	O
is	O
learned	O
through	O
an	O
adversarial	O
manner	O
in	O
ALDA	O
,	O
to	O
reduce	O
the	O
gap	O
and	O
align	O
the	O
feature	O
distributions.	O
Finally,	O
a	O
new	O
loss	O
function	O
is	O
auto-constructed	O
from	O
the	O
learned	O
confusion	O
matrix,	O
which	O
serves	O
as	O
the	O
loss	O
for	O
unlabeled	O
target	O
samples.	O
Our	O
ALDA	O
outperforms	O
state-of-the-art	O
approaches	O
in	O
four	O
standard	O
domain	O
adaptation	O
datasets.	O
Our	O
code	O
is	O
available	O
at	O
https://github.com/ZJULearning/ALDA	O
.	O

We	O
propose	O
two	O
neural	O
network	O
architectures	O
for	O
nested	O
named	O
entity	O
recognition	O
(NER	S-RESEARCH_PROBLEM
),	O
a	O
setting	O
in	O
which	O
named	O
entities	O
may	O
overlap	O
and	O
also	O
be	O
labeled	O
with	O
more	O
than	O
one	O
label.	O
We	O
encode	O
the	O
nested	O
labels	O
using	O
a	O
linearized	O
scheme.	O
In	O
our	O
first	O
proposed	O
approach,	O
the	O
nested	O
labels	O
are	O
modeled	O
as	O
multilabels	O
corresponding	O
to	O
the	O
Cartesian	O
product	O
of	O
the	O
nested	O
labels	O
in	O
a	O
standard	O
LSTM-CRF	O
architecture.	O
In	O
the	O
second	O
one,	O
the	O
nested	O
NER	S-RESEARCH_PROBLEM
is	O
viewed	O
as	O
a	O
sequence-to-sequence	O
problem,	O
in	O
which	O
the	O
input	O
sequence	O
consists	O
of	O
the	O
tokens	O
and	O
output	O
sequence	O
of	O
the	O
labels,	O
using	O
hard	O
attention	O
on	O
the	O
word	O
whose	O
label	O
is	O
being	O
predicted.	O
The	O
proposed	O
methods	O
outperform	O
the	O
nested	O
NER	S-RESEARCH_PROBLEM
state	O
of	O
the	O
art	O
on	O
four	O
corpora:	O
ACE-2004,	O
ACE-2005,	O
GENIA	O
and	O
Czech	O
CNEC.	O
We	O
also	O
enrich	O
our	O
architectures	O
with	O
the	O
recently	O
published	O
contextual	O
embeddings:	O
ELMo,	O
BERT	O
and	O
Flair,	O
reaching	O
further	O
improvements	O
for	O
the	O
four	O
nested	O
entity	O
corpora.	O
In	O
addition,	O
we	O
report	O
flat	O
NER	S-RESEARCH_PROBLEM
state-of-the-art	O
results	O
for	O
CoNLL-2002	O
Dutch	O
and	O
Spanish	O
and	O
for	O
CoNLL-2003	O
English.	O

Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(NAS)	O
is	O
one	O
of	O
the	O
most	O
rapidly	O
growing	O
research	O
fields	O
in	O
machine	O
learning	O
due	O
to	O
its	O
ability	O
to	O
discover	O
high-performance	O
architectures	O
automatically.	O
Although	O
conventional	O
NAS	O
algorithms	O
focus	O
on	O
improving	O
search	O
efficiency	O
(e.g.,	O
high	O
performance	O
with	O
less	O
search	O
time),	O
they	O
often	O
require	O
a	O
lot	O
of	O
memory	O
footprint	O
and	O
power	O
consumption.	O
To	O
remedy	O
this	O
problem,	O
we	O
propose	O
a	O
new	O
paradigm	O
for	O
NAS	O
that	O
effectively	O
reduces	O
the	O
use	O
of	O
memory	O
while	O
maintaining	O
high	O
performance.	O
The	O
proposed	O
algorithm	O
is	O
motivated	O
by	O
our	O
observation	O
that	O
manually	O
designed	O
and	O
NAS-based	O
architectures	O
share	O
similar	O
low-level	O
representations,	O
regardless	O
of	O
the	O
difference	O
in	O
the	O
network's	O
topology.	O
Reflecting	O
this,	O
we	O
propose	O
a	O
new	O
architectural	O
paradigm	O
for	O
NAS,	O
called	O
$\textbf{Transfer-NAS}$,	O
that	O
replaces	O
several	O
first	O
cells	O
in	O
the	O
generated	O
architecture	O
with	O
conventional	O
(hand-crafted)	O
pre-trained	O
blocks.	O
As	O
the	O
replaced	O
pre-trained	O
blocks	O
are	O
kept	O
frozen	O
during	O
training,	O
the	O
memory	O
footprint	O
can	O
significantly	O
be	O
reduced.	O
We	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	O
by	O
incorporating	O
it	O
into	O
Regularized	O
Evolution	O
and	O
Differentiable	O
ARchiTecture	O
Search	O
with	O
Perturbation-based	O
architecture	O
selection	O
(DARTS	O
+PT)	O
on	O
NAS-Bench-201	O
and	O
DARTS	O
search	O
spaces.	O
Extensive	O
experiments	O
show	O
that	O
Transfer-NAS	O
significantly	O
decreases	O
the	O
memory	O
usage	O
up-to	O
$\textbf{50\%}$	O
while	O
achieving	O
higher/comparable	O
performance	O
compared	O
to	O
the	O
baselines.	O
Furthermore,	O
the	O
proposed	O
method	O
is	O
$\textbf{1.98$\times$}$	O
faster	O
in	O
terms	O
of	O
search	O
time	O
when	O
incorporated	O
to	O
DARTS	O
+PT	O
on	O
NAS-Bench-201	O
compared	O
to	O
the	O
conventional	O
method.	O

Mention	O
detection	O
is	O
an	O
important	O
preprocessing	O
step	O
for	O
annotation	O
and	O
interpretation	O
in	O
applications	O
such	O
as	O
NER	S-RESEARCH_PROBLEM
and	O
coreference	O
resolution,	O
but	O
few	O
stand-alone	O
neural	O
models	O
have	O
been	O
proposed	O
able	O
to	O
handle	O
the	O
full	O
range	O
of	O
mentions.	O
In	O
this	O
work,	O
we	O
propose	O
and	O
compare	O
three	O
neural	O
network-based	O
approaches	O
to	O
mention	O
detection.	O
The	O
first	O
approach	O
is	O
based	O
on	O
the	O
mention	O
detection	O
part	O
of	O
a	O
state	O
of	O
the	O
art	O
coreference	O
resolution	O
system;	O
the	O
second	O
uses	O
ELMO	O
embeddings	O
together	O
with	O
a	O
bidirectional	O
LSTM	O
and	O
a	O
biaffine	O
classifier;	O
the	O
third	O
approach	O
uses	O
the	O
recently	O
introduced	O
BERT	O
model.	O
Our	O
best	O
model	O
(using	O
a	O
biaffine	O
classifier)	O
achieves	O
gains	O
of	O
up	O
to	O
1.8	O
percentage	O
points	O
on	O
mention	O
recall	O
when	O
compared	O
with	O
a	O
strong	O
baseline	O
in	O
a	O
HIGH	O
RECALL	O
coreference	O
annotation	O
setting.	O
The	O
same	O
model	O
achieves	O
improvements	O
of	O
up	O
to	O
5.3	O
and	O
6.2	O
p.p.	O
when	O
compared	O
with	O
the	O
best-reported	O
mention	O
detection	O
F1	O
on	O
the	O
CONLL	O
and	O
CRAC	O
coreference	O
data	O
sets	O
respectively	O
in	O
a	O
HIGH	O
F1	O
annotation	O
setting.	O
We	O
then	O
evaluate	O
our	O
models	O
for	O
coreference	O
resolution	O
by	O
using	O
mentions	O
predicted	O
by	O
our	O
best	O
model	O
in	O
start-of-the-art	O
coreference	O
systems.	O
The	O
enhanced	O
model	O
achieved	O
absolute	O
improvements	O
of	O
up	O
to	O
1.7	O
and	O
0.7	O
p.p.	O
when	O
compared	O
with	O
our	O
strong	O
baseline	O
systems	O
(pipeline	O
system	O
and	O
end-to-end	O
system)	O
respectively.	O
For	O
nested	O
NER	S-RESEARCH_PROBLEM
,	O
the	O
evaluation	O
of	O
our	O
model	O
on	O
the	O
GENIA	O
corpora	O
shows	O
that	O
our	O
model	O
matches	O
or	O
outperforms	O
state-of-the-art	O
models	O
despite	O
not	O
being	O
specifically	O
designed	O
for	O
this	O
task.	O

Temporal-difference	O
(TD)	O
learning	O
is	O
an	O
important	O
field	O
in	O
reinforcementlearning.	O
Sarsa	O
and	O
Q-Learning	S-RESEARCH_PROBLEM
are	O
among	O
the	O
most	O
used	O
TD	O
algorithms.	O
TheQ($\sigma$)	O
algorithm	O
(Sutton	O
and	O
Barto	O
(2017))	O
unifies	O
both.	O
This	O
paperextends	O
the	O
Q($\sigma$)	O
algorithm	O
to	O
an	O
online	O
multi-step	O
algorithm	O
Q($\sigma,\lambda$)	O
using	O
eligibility	O
traces	O
and	O
introduces	O
Double	O
Q($\sigma$)	O
as	O
theextension	O
of	O
Q($\sigma$)	O
to	O
double	O
learning.	O
Experiments	O
suggest	O
that	O
the	O
newQ($\sigma,	O
\lambda$)	O
algorithm	O
can	O
outperform	O
the	O
classical	O
TD	O
control	O
methodsSarsa	O
($\lambda$),	O
Q($\lambda$)	O
and	O
Q($\sigma$).	O

Although	O
modern	O
named	O
entity	O
recognition	O
(NER	S-RESEARCH_PROBLEM
)	O
systems	O
show	O
impressive	O
performance	O
on	O
standard	O
datasets,	O
they	O
perform	O
poorly	O
when	O
presented	O
with	O
noisy	O
data.	O
In	O
particular,	O
capitalization	O
is	O
a	O
strong	O
signal	O
for	O
entities	O
in	O
many	O
languages,	O
and	O
even	O
state	O
of	O
the	O
art	O
models	O
overfit	O
to	O
this	O
feature,	O
with	O
drastically	O
lower	O
performance	O
on	O
uncapitalized	O
text.	O
In	O
this	O
work,	O
we	O
address	O
the	O
problem	O
of	O
robustness	O
of	O
NER	S-RESEARCH_PROBLEM
systems	O
in	O
data	O
with	O
noisy	O
or	O
uncertain	O
casing,	O
using	O
a	O
pretraining	O
objective	O
that	O
predicts	O
casing	O
in	O
text,	O
or	O
a	O
truecaser,	O
leveraging	O
unlabeled	O
data.	O
The	O
pretrained	O
truecaser	O
is	O
combined	O
with	O
a	O
standard	O
BiLSTM-CRF	O
model	O
for	O
NER	S-RESEARCH_PROBLEM
by	O
appending	O
output	O
distributions	O
to	O
character	O
embeddings.	O
In	O
experiments	O
over	O
several	O
datasets	O
of	O
varying	O
domain	O
and	O
casing	O
quality,	O
we	O
show	O
that	O
our	O
new	O
model	O
improves	O
performance	O
in	O
uncased	O
text,	O
even	O
adding	O
value	O
to	O
uncased	O
BERT	O
embeddings.	O
Our	O
method	O
achieves	O
a	O
new	O
state	O
of	O
the	O
art	O
on	O
the	O
WNUT17	O
shared	O
task	O
dataset.	O

Multilingual	O
BERT	O
(M-BERT	O
)	O
has	O
been	O
a	O
huge	O
success	O
in	O
both	O
supervised	O
and	O
zero-shot	O
cross-lingual	O
transfer	O
learning.	O
However,	O
this	O
success	O
has	O
focused	O
only	O
on	O
the	O
top	O
104	O
languages	O
in	O
Wikipedia	O
that	O
it	O
was	O
trained	O
on.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
simple	O
but	O
effective	O
approach	O
to	O
extend	O
M-BERT	O
(E-BERT	O
)	O
so	O
that	O
it	O
can	O
benefit	O
any	O
new	O
language,	O
and	O
show	O
that	O
our	O
approach	O
benefits	O
languages	O
that	O
are	O
already	O
in	O
M-BERT	O
as	O
well.	O
We	O
perform	O
an	O
extensive	O
set	O
of	O
experiments	O
with	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER)	O
on	O
27	O
languages,	O
only	O
16	O
of	O
which	O
are	O
in	O
M-BERT	O
,	O
and	O
show	O
an	O
average	O
increase	O
of	O
about	O
6%	O
F1	O
on	O
languages	O
that	O
are	O
already	O
in	O
M-BERT	O
and	O
23%	O
F1	O
increase	O
on	O
new	O
languages.	O

Clustering	O
genotypes	O
based	O
upon	O
their	O
phenotypic	O
characteristics	O
is	O
used	O
to	O
obtain	O
diverse	O
sets	O
of	O
parents	O
that	O
are	O
useful	O
in	O
their	O
breeding	O
programs.	O
The	O
Hierarchical	O
Clustering	O
(HC)	O
algorithm	O
is	O
the	O
current	O
standard	O
in	O
clustering	O
of	O
phenotypic	O
data.	O
This	O
algorithm	O
suffers	O
from	O
low	O
accuracy	O
and	O
high	O
computational	O
complexity	O
issues.	O
To	O
address	O
the	O
accuracy	O
challenge,	O
we	O
propose	O
the	O
use	O
of	O
Spectral	O
Clustering	O
(SC)	O
algorithm.	O
To	O
make	O
the	O
algorithm	O
computationally	O
cheap,	O
we	O
propose	O
using	O
sampling,	O
specifically,	O
Pivotal	O
Sampling	O
that	O
is	O
probability	O
based.	O
Since	O
application	O
of	O
samplings	O
to	O
phenotypic	O
data	O
has	O
not	O
been	O
explored	O
much,	O
for	O
effective	O
comparison,	O
another	O
sampling	O
technique	O
called	O
Vector	O
Quantization	S-RESEARCH_PROBLEM
(VQ)	O
is	O
adapted	O
for	O
this	O
data	O
as	O
well.	O
VQ	O
has	O
recently	O
given	O
promising	O
results	O
for	O
genome	O
data.	O
The	O
novelty	O
of	O
our	O
SC	O
with	O
Pivotal	O
Sampling	O
algorithm	O
is	O
in	O
constructing	O
the	O
crucial	O
similarity	O
matrix	O
for	O
the	O
clustering	O
algorithm	O
and	O
defining	O
probabilities	O
for	O
the	O
sampling	O
technique.	O
Although	O
our	O
algorithm	O
can	O
be	O
applied	O
to	O
any	O
plant	O
genotypes,	O
we	O
test	O
it	O
on	O
the	O
phenotypic	O
data	O
obtained	O
from	O
about	O
2400	O
Soybean	O
genotypes.	O
SC	O
with	O
Pivotal	O
Sampling	O
achieves	O
substantially	O
more	O
accuracy	O
(in	O
terms	O
of	O
Silhouette	O
Values)	O
than	O
all	O
the	O
other	O
proposed	O
competitive	O
clustering	O
with	O
sampling	O
algorithms	O
(i.e.	O
SC	O
with	O
VQ,	O
HC	O
with	O
Pivotal	O
Sampling,	O
and	O
HC	O
with	O
VQ).	O
The	O
complexities	O
of	O
our	O
SC	O
with	O
Pivotal	O
Sampling	O
algorithm	O
and	O
these	O
three	O
variants	O
are	O
almost	O
same	O
because	O
of	O
the	O
involved	O
sampling.	O
In	O
addition	O
to	O
this,	O
SC	O
with	O
Pivotal	O
Sampling	O
outperforms	O
the	O
standard	O
HC	O
algorithm	O
in	O
both	O
accuracy	O
and	O
computational	O
complexity.	O
We	O
experimentally	O
show	O
that	O
we	O
are	O
up	O
to	O
45%	O
more	O
accurate	O
than	O
HC	O
in	O
terms	O
of	O
clustering	O
accuracy.	O
The	O
computational	O
complexity	O
of	O
our	O
algorithm	O
is	O
more	O
than	O
a	O
magnitude	O
lesser	O
than	O
HC.	O

Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER	S-RESEARCH_PROBLEM
)	O
is	O
a	O
crucial	O
upstream	O
task	O
in	O
Natural	O
Language	O
Processing	O
(NLP).	O
Traditional	O
tag	O
scheme	O
approaches	O
offer	O
a	O
single	O
recognition	O
that	O
does	O
not	O
meet	O
the	O
needs	O
of	O
many	O
downstream	O
tasks	O
such	O
as	O
coreference	O
resolution.	O
Meanwhile,	O
Tag	O
scheme	O
approaches	O
ignore	O
the	O
continuity	O
of	O
entities.	O
Inspired	O
by	O
one-stage	O
object	O
detection	O
models	O
in	O
computer	O
vision	O
(CV),	O
this	O
paper	O
proposes	O
a	O
new	O
no-tag	O
scheme,	O
the	O
Whole-Aware	O
Detection,	O
which	O
makes	O
NER	S-RESEARCH_PROBLEM
an	O
object	O
detection	O
task.	O
Meanwhile,	O
this	O
paper	O
presents	O
a	O
novel	O
model,	O
Entity	O
Candidate	O
Network	O
(ECNet),	O
and	O
a	O
specific	O
convolution	O
network,	O
Adaptive	O
Context	O
Convolution	O
Network	O
(ACCN),	O
to	O
fuse	O
multi-scale	O
contexts	O
and	O
encode	O
entity	O
information	O
at	O
each	O
position.	O
ECNet	O
identifies	O
the	O
full	O
span	O
of	O
a	O
named	O
entity	O
and	O
its	O
type	O
at	O
each	O
position	O
based	O
on	O
Entity	O
Loss.	O
Furthermore,	O
ECNet	O
is	O
regulable	O
between	O
the	O
highest	O
precision	O
and	O
the	O
highest	O
recall,	O
while	O
the	O
tag	O
scheme	O
approaches	O
are	O
not.	O
Experimental	O
results	O
on	O
the	O
CoNLL	O
2003	O
English	O
dataset	O
and	O
the	O
WNUT	O
2017	O
dataset	O
show	O
that	O
ECNet	O
outperforms	O
other	O
previous	O
state-of-the-art	O
methods.	O

This	O
paper	O
introduces	O
BReG-NeXt,	O
a	O
residual-based	O
network	O
architecture	O
using	O
a	O
function	O
wtih	O
bounded	O
derivative	O
instead	O
of	O
a	O
simple	O
shortcut	O
path	O
(a.k.a.	O
identity	O
mapping)	O
in	O
the	O
residual	O
units	O
for	O
automatic	O
recognition	O
of	O
facial	O
expressions	O
based	O
on	O
the	O
categorical	O
and	O
dimensional	O
models	O
of	O
affect.	O
Compared	O
to	O
ResNet	O
,	O
our	O
proposed	O
adaptive	O
complex	O
mapping	O
results	O
in	O
a	O
shallower	O
network	O
with	O
less	O
numbers	O
of	O
training	O
parameters	O
and	O
floating	O
point	O
operations	O
per	O
second	O
(FLOPs).	O
Adding	O
trainable	O
parameters	O
to	O
the	O
bypass	O
function	O
further	O
improves	O
fitting	O
and	O
training	O
the	O
network	O
and	O
hence	O
recognizing	O
subtle	O
facial	O
expressions	O
such	O
as	O
contempt	O
with	O
a	O
higher	O
accuracy.	O
We	O
conducted	O
comprehensive	O
experiments	O
on	O
the	O
categorical	O
and	O
dimensional	O
models	O
of	O
affect	O
on	O
the	O
challenging	O
in-the-wild	O
databases	O
of	O
AffectNet,	O
FER2013,	O
and	O
Affect-in-Wild.	O
Our	O
experimental	O
results	O
show	O
that	O
our	O
adaptive	O
complex	O
mapping	O
approach	O
outperforms	O
the	O
original	O
ResNet	O
consisting	O
of	O
a	O
simple	O
identity	O
mapping	O
as	O
well	O
as	O
other	O
state-of-the-art	O
methods	O
for	O
Facial	B-RESEARCH_PROBLEM
Expression	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(FER).	O
Various	O
metrics	O
are	O
reported	O
in	O
both	O
affect	O
models	O
to	O
provide	O
a	O
comprehensive	O
evaluation	O
of	O
our	O
method.	O
In	O
the	O
categorical	O
model,	O
BReG-NeXt-50	O
with	O
only	O
3.1M	O
training	O
parameters	O
and	O
15	O
MFLOPs,	O
achieves	O
68.50%	O
and	O
71.53%	O
accuracy	O
on	O
AffectNet	O
and	O
FER2013	O
databases,	O
respectively.	O
In	O
the	O
dimensional	O
model,	O
BReG-NeXt	O
achieves	O
0.2577	O
and	O
0.2882	O
RMSE	O
value	O
on	O
AffectNet	O
and	O
Affect-in-Wild	O
databases,	O
respectively.	O

Learning	O
on	O
graph	O
structured	O
data	O
has	O
drawn	O
increasing	O
interest	O
in	O
recent	O
years.	O
Frameworks	O
like	O
Graph	O
Convolutional	O
Networks	O
(GCNs)	O
have	O
demonstrated	O
their	O
ability	O
to	O
capture	O
structural	O
information	O
and	O
obtain	O
good	O
performance	O
in	O
various	O
tasks.	O
In	O
these	O
frameworks,	O
node	O
aggregation	O
schemes	O
are	O
typically	O
used	O
to	O
capture	O
structural	O
information:	O
a	O
node's	O
feature	O
vector	O
is	O
recursively	O
computed	O
by	O
aggregating	O
features	O
of	O
its	O
neighboring	O
nodes.	O
However,	O
most	O
of	O
aggregation	O
schemes	O
treat	O
all	O
connections	O
in	O
a	O
graph	O
equally,	O
ignoring	O
node	O
feature	O
similarities.	O
In	O
this	O
paper,	O
we	O
re-interpret	O
node	O
aggregation	O
from	O
the	O
perspective	O
of	O
kernel	O
weighting,	O
and	O
present	O
a	O
framework	O
to	O
consider	O
feature	O
similarity	O
in	O
an	O
aggregation	O
scheme.	O
Specifically,	O
we	O
show	O
that	O
normalized	O
adjacency	O
matrix	O
is	O
equivalent	O
to	O
a	O
neighbor-based	O
kernel	O
matrix	O
in	O
a	O
Krein	O
Space.	O
We	O
then	O
propose	O
feature	O
aggregation	O
as	O
the	O
composition	O
of	O
the	O
original	O
neighbor-based	O
kernel	O
and	O
a	O
learnable	O
kernel	O
to	O
encode	O
feature	O
similarities	O
in	O
a	O
feature	O
space.	O
We	O
further	O
show	O
how	O
the	O
proposed	O
method	O
can	O
be	O
extended	O
to	O
Graph	B-RESEARCH_PROBLEM
Attention	E-RESEARCH_PROBLEM
Network	O
(GAT).	O
Experimental	O
results	O
demonstrate	O
better	O
performance	O
of	O
our	O
proposed	O
framework	O
in	O
several	O
real-world	O
applications.	O

Deep	O
convolutional	O
neural	O
networks	O
continue	O
to	O
advance	O
the	O
state-of-the-artin	O
many	O
domains	O
as	O
they	O
grow	O
bigger	O
and	O
more	O
complex.	O
It	O
has	O
been	O
observed	O
thatmany	O
of	O
the	O
parameters	O
of	O
a	O
large	O
network	O
are	O
redundant,	O
allowing	O
for	O
thepossibility	O
of	O
learning	O
a	O
smaller	O
network	O
that	O
mimics	O
the	O
outputs	O
of	O
the	O
largenetwork	O
through	O
a	O
process	O
called	O
Knowledge	B-RESEARCH_PROBLEM
Distillation	E-RESEARCH_PROBLEM
.	O
We	O
show,	O
however,	O
thatstandard	O
Knowledge	B-RESEARCH_PROBLEM
Distillation	E-RESEARCH_PROBLEM
is	O
not	O
effective	O
for	O
learning	O
small	O
models	O
forthe	O
task	O
of	O
pedestrian	O
detection.	O
To	O
improve	O
this	O
process,	O
we	O
introduce	O
ahigher-dimensional	O
hint	O
layer	O
to	O
increase	O
information	O
flow.	O
We	O
also	O
estimatethe	O
variance	O
in	O
the	O
outputs	O
of	O
the	O
large	O
network	O
and	O
propose	O
a	O
loss	O
function	O
toincorporate	O
this	O
uncertainty.	O
Finally,	O
we	O
attempt	O
to	O
boost	O
the	O
complexity	O
ofthe	O
small	O
network	O
without	O
increasing	O
its	O
size	O
by	O
using	O
as	O
input	O
hand-designedfeatures	O
that	O
have	O
been	O
demonstrated	O
to	O
be	O
effective	O
for	O
pedestrian	O
detection.We	O
succeed	O
in	O
training	O
a	O
model	O
that	O
contains	O
$400\times$	O
fewer	O
parameters	O
thanthe	O
large	O
network	O
while	O
outperforming	O
AlexNet	O
on	O
the	O
Caltech	O
PedestrianDataset.	O

Chemical	O
patents	O
are	O
an	O
important	O
resource	O
for	O
chemical	O
information.	O
However,	O
few	O
chemical	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER	S-RESEARCH_PROBLEM
)	O
systems	O
have	O
been	O
evaluated	O
on	O
patent	O
documents,	O
due	O
in	O
part	O
to	O
their	O
structural	O
and	O
linguistic	O
complexity.	O
In	O
this	O
paper,	O
we	O
explore	O
the	O
NER	S-RESEARCH_PROBLEM
performance	O
of	O
a	O
BiLSTM-CRF	O
model	O
utilising	O
pre-trained	O
word	O
embeddings,	O
character-level	O
word	O
representations	O
and	O
contextualized	O
ELMo	O
word	O
representations	O
for	O
chemical	O
patents.	O
We	O
compare	O
word	O
embeddings	O
pre-trained	O
on	O
biomedical	O
and	O
chemical	O
patent	O
corpora.	O
The	O
effect	O
of	O
tokenizers	O
optimized	O
for	O
the	O
chemical	O
domain	O
on	O
NER	S-RESEARCH_PROBLEM
performance	O
in	O
chemical	O
patents	O
is	O
also	O
explored.	O
The	O
results	O
on	O
two	O
patent	O
corpora	O
show	O
that	O
contextualized	O
word	O
representations	O
generated	O
from	O
ELMo	O
substantially	O
improve	O
chemical	O
NER	S-RESEARCH_PROBLEM
performance	O
w.r.t.	O
the	O
current	O
state-of-the-art.	O
We	O
also	O
show	O
that	O
domain-specific	O
resources	O
such	O
as	O
word	O
embeddings	O
trained	O
on	O
chemical	O
patents	O
and	O
chemical-specific	O
tokenizers	O
have	O
a	O
positive	O
impact	O
on	O
NER	S-RESEARCH_PROBLEM
performance.	O

We	O
present	O
a	O
new	O
approach	O
for	O
pretraining	O
a	O
bi-directional	O
transformer	O
modelthat	O
provides	O
significant	O
performance	O
gains	O
across	O
a	O
variety	O
of	O
languageunderstanding	O
problems.	O
Our	O
model	O
solves	O
a	O
cloze-style	O
word	O
reconstructiontask,	O
where	O
each	O
word	O
is	O
ablated	O
and	O
must	O
be	O
predicted	O
given	O
the	O
rest	O
of	O
thetext.	O
Experiments	O
demonstrate	O
large	O
performance	O
gains	O
on	O
GLUE	O
and	O
new	O
state	O
ofthe	O
art	O
results	O
on	O
NER	S-RESEARCH_PROBLEM
as	O
well	O
as	O
constituency	O
parsing	O
benchmarks,	O
consistentwith	O
the	O
concurrently	O
introduced	O
BERT	O
model.	O
We	O
also	O
present	O
a	O
detailedanalysis	O
of	O
a	O
number	O
of	O
factors	O
that	O
contribute	O
to	O
effective	O
pretraining,including	O
data	O
domain	O
and	O
size,	O
model	O
capacity,	O
and	O
variations	O
on	O
the	O
clozeobjective.	O

The	O
representation	O
used	O
for	O
Facial	B-RESEARCH_PROBLEM
Expression	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(FER)	O
usually	O
contain	O
expression	O
information	O
along	O
with	O
other	O
variations	O
such	O
as	O
identity	O
and	O
illumination.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
novel	O
Disentangled	O
Expression	O
learning-Generative	O
Adversarial	O
Network	O
(DE-GAN)	O
to	O
explicitly	O
disentangle	O
facial	O
expression	O
representation	O
from	O
identity	O
information.	O
In	O
this	O
learning	O
by	O
reconstruction	O
method,	O
facial	O
expression	O
representation	O
is	O
learned	O
by	O
reconstructing	O
an	O
expression	O
image	O
employing	O
an	O
encoder-decoder	O
based	O
generator.	O
This	O
expression	O
representation	O
is	O
disentangled	O
from	O
identity	O
component	O
by	O
explicitly	O
providing	O
the	O
identity	O
code	O
to	O
the	O
decoder	O
part	O
of	O
DE-GAN.	O
The	O
process	O
of	O
expression	O
image	O
reconstruction	O
and	O
disentangled	O
expression	O
representation	O
learning	O
is	O
improved	O
by	O
performing	O
expression	O
and	O
identity	O
classification	O
in	O
the	O
discriminator	O
of	O
DE-GAN.	O
The	O
disentangled	O
facial	O
expression	O
representation	O
is	O
then	O
used	O
for	O
facial	O
expression	O
recognition	O
employing	O
simple	O
classifiers	O
like	O
SVM	O
or	O
MLP.	O
The	O
experiments	O
are	O
performed	O
on	O
publicly	O
available	O
and	O
widely	O
used	O
face	O
expression	O
databases	O
(CK+,	O
MMI,	O
Oulu-CASIA).	O
The	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
technique	O
produces	O
comparable	O
results	O
with	O
state-of-the-art	O
methods.	O

Contextual	O
word-representations	O
became	O
a	O
standard	O
in	O
modern	O
natural	O
language	O
processing	O
systems.	O
These	O
models	O
use	O
subword	O
tokenization	O
to	O
handle	O
large	O
vocabularies	O
and	O
unknown	O
words.	O
Word-level	O
usage	O
of	O
such	O
systems	O
requires	O
a	O
way	O
of	O
pooling	O
multiple	O
subwords	O
that	O
correspond	O
to	O
a	O
single	O
word.	O
In	O
this	O
paper	O
we	O
investigate	O
how	O
the	O
choice	O
of	O
subword	O
pooling	O
affects	O
the	O
downstream	O
performance	O
on	O
three	O
tasks:	O
morphological	O
probing,	O
POS	S-RESEARCH_PROBLEM
tagging	O
and	O
NER	S-RESEARCH_PROBLEM
,	O
in	O
9	O
typologically	O
diverse	O
languages.	O
We	O
compare	O
these	O
in	O
two	O
massively	O
multilingual	O
models,	O
mBERT	O
and	O
XLM-RoBERTa.	O
For	O
morphological	O
tasks,	O
the	O
widely	O
used	O
`choose	O
the	O
first	O
subword'	O
is	O
the	O
worst	O
strategy	O
and	O
the	O
best	O
results	O
are	O
obtained	O
by	O
using	O
attention	O
over	O
the	O
subwords.	O
For	O
POS	S-RESEARCH_PROBLEM
tagging	O
both	O
of	O
these	O
strategies	O
perform	O
poorly	O
and	O
the	O
best	O
choice	O
is	O
to	O
use	O
a	O
small	O
LSTM	O
over	O
the	O
subwords.	O
The	O
same	O
strategy	O
works	O
best	O
for	O
NER	S-RESEARCH_PROBLEM
and	O
we	O
show	O
that	O
mBERT	O
is	O
better	O
than	O
XLM-RoBERTa	O
in	O
all	O
9	O
languages.	O
We	O
publicly	O
release	O
all	O
code,	O
data	O
and	O
the	O
full	O
result	O
tables	O
at	O
\url{https://github.com/juditacs/subword-choice}.	O

The	O
road	O
is	O
vital	O
for	O
many	O
aspects	O
of	O
life,	O
and	O
road	O
maintenance	O
is	O
crucial	O
for	O
human	O
safety.	O
One	O
of	O
the	O
critical	O
tasks	O
to	O
allow	O
timely	O
repair	O
of	O
road	O
damages	O
is	O
to	O
quickly	O
and	O
efficiently	O
detect	O
and	O
classify	O
them.	O
This	O
work	O
details	O
the	O
strategies	O
and	O
experiments	O
evaluated	O
for	O
these	O
tasks.	O
Specifically,	O
we	O
evaluate	O
Detectron2's	O
implementation	O
of	O
Faster	O
R-CNN	O
using	O
different	O
base	O
models	O
and	O
configurations.	O
We	O
also	O
experiment	O
with	O
these	O
approaches	O
using	O
the	O
Global	O
Road	B-RESEARCH_PROBLEM
Damage	I-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
Challenge	O
2020,	O
A	O
Track	O
in	O
the	O
IEEE	O
Big	O
Data	O
2020	O
Big	O
Data	O
Cup	O
Challenge	O
dataset.	O
The	O
results	O
show	O
that	O
the	O
X101-FPN	O
base	O
model	O
for	O
Faster	O
R-CNN	O
with	O
Detectron2's	O
default	O
configurations	O
are	O
efficient	O
and	O
general	O
enough	O
to	O
be	O
transferable	O
to	O
different	O
countries	O
in	O
this	O
challenge.	O
This	O
approach	O
results	O
in	O
F1	O
scores	O
of	O
51.0%	O
and	O
51.4%	O
for	O
the	O
test1	O
and	O
test2	O
sets	O
of	O
the	O
challenge,	O
respectively.	O
Though	O
the	O
visualizations	O
show	O
good	O
prediction	O
results,	O
the	O
F1	O
scores	O
are	O
low.	O
Therefore,	O
we	O
also	O
evaluate	O
the	O
prediction	O
results	O
against	O
the	O
existing	O
annotations	O
and	O
discover	O
some	O
discrepancies.	O
Thus,	O
we	O
also	O
suggest	O
strategies	O
to	O
improve	O
the	O
labeling	O
process	O
for	O
this	O
dataset.	O

Visible-Infrared	O
person	O
re-identification	O
(VI-ReID)	O
aims	O
to	O
match	O
cross-modality	O
pedestrian	O
images,	O
breaking	O
through	O
the	O
limitation	O
of	O
single-modality	O
person	O
ReID	O
in	O
dark	O
environment.	O
In	O
order	O
to	O
mitigate	O
the	O
impact	O
of	O
large	O
modality	O
discrepancy,	O
existing	O
works	O
manually	O
design	O
various	O
two-stream	O
architectures	O
to	O
separately	O
learn	O
modality-specific	O
and	O
modality-sharable	O
representations.	O
Such	O
a	O
manual	O
design	O
routine,	O
however,	O
highly	O
depends	O
on	O
massive	O
experiments	O
and	O
empirical	O
practice,	O
which	O
is	O
time	O
consuming	O
and	O
labor	O
intensive.	O
In	O
this	O
paper,	O
we	O
systematically	O
study	O
the	O
manually	O
designed	O
architectures,	O
and	O
identify	O
that	O
appropriately	O
separating	O
Batch	O
Normalization	O
(BN)	O
layers	O
is	O
the	O
key	O
to	O
bring	O
a	O
great	O
boost	O
towards	O
cross-modality	O
matching.	O
Based	O
on	O
this	O
observation,	O
the	O
essential	O
objective	O
is	O
to	O
find	O
the	O
optimal	O
separation	O
scheme	O
for	O
each	O
BN	O
layer.	O
To	O
this	O
end,	O
we	O
propose	O
a	O
novel	O
method,	O
named	O
Cross-Modality	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(CM-NAS).	O
It	O
consists	O
of	O
a	O
BN-oriented	O
search	O
space	O
in	O
which	O
the	O
standard	O
optimization	O
can	O
be	O
fulfilled	O
subject	O
to	O
the	O
cross-modality	O
task.	O
Equipped	O
with	O
the	O
searched	O
architecture,	O
our	O
method	O
outperforms	O
state-of-the-art	O
counterparts	O
in	O
both	O
two	O
benchmarks,	O
improving	O
the	O
Rank-1/mAP	O
by	O
6.70%/6.13%	O
on	O
SYSU-MM01	O
and	O
by	O
12.17%/11.23%	O
on	O
RegDB.	O
Code	O
is	O
released	O
at	O
https://github.com/JDAI-CV/CM-NAS.	O

Zero-shot	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(ZS-NAS)	O
is	O
a	O
recently	O
developed	O
low-cost	O
NAS	O
framework	O
which	O
identifies	O
top-performer	O
neural	O
architectures	O
from	O
a	O
large	O
candidate	O
pool	O
without	O
training	O
their	O
parameters.	O
Despite	O
its	O
popularity	O
in	O
recent	O
NAS	O
literatures,	O
the	O
effectiveness	O
of	O
ZS-NAS	O
has	O
not	O
been	O
comprehensively	O
understood.	O
Previous	O
works	O
analyze	O
ZS-NAS	O
methods	O
on	O
NAS	O
benchmark	O
datasets	O
such	O
as	O
NAS-Bench-101/201/301	O
which	O
are	O
initially	O
designed	O
for	O
learning	O
network	O
topology	O
with	O
irregular	O
connections.	O
However,	O
most	O
modern	O
state-of-the-art	O
networks	O
as	O
well	O
as	O
popular	O
classical	O
ones	O
are	O
designed	O
in	O
more	O
conventional,	O
well-established	O
search	O
spaces	O
such	O
as	O
ResNet	O
(RS)	O
and	O
MobileNet	O
(MB)	O
search	O
space.	O
This	O
imposes	O
a	O
significant	O
gap	O
between	O
the	O
benchmark	O
dataset	O
and	O
real-world	O
practice,	O
hindering	O
a	O
deeper	O
understanding	O
of	O
ZS-NAS.	O
In	O
this	O
work,	O
we	O
aim	O
to	O
bridge	O
the	O
gap	O
systematically.	O
First,	O
we	O
collect	O
a	O
novel	O
large-scale	O
dataset	O
termed	O
NAS-Bench-Zero	O
for	O
benchmarking	O
and	O
understanding	O
popular	O
ZS-NAS	O
methods	O
in	O
the	O
conventional	O
RS/MB	O
search	O
spaces.	O
Then	O
the	O
characteristics	O
of	O
these	O
ZS-NAS	O
methods	O
are	O
extensively	O
examined	O
from	O
various	O
aspects.	O
Notably,	O
we	O
find	O
that:	O
1)	O
the	O
performance	O
of	O
ZS-NAS	O
on	O
NAS-Bench-101/201/301	O
cannot	O
transfer	O
to	O
RS/MB	O
search	O
spaces;	O
2)	O
A	O
proxy	O
with	O
higher	O
ranking	O
correlation	O
score	O
may	O
actually	O
perform	O
worse	O
in	O
constrained	O
NAS;	O
3)	O
existing	O
zero-shot	O
proxies	O
cannot	O
outperform	O
naive	O
proxies	O
such	O
as	O
FLOPs/params	O
in	O
RS/MB	O
search	O
spaces;	O
4)	O
Top	O
best	O
zero-shot	O
proxies	O
as	O
well	O
as	O
FLOPs/params	O
compensate	O
each	O
other.	O
Based	O
on	O
these	O
new	O
discoveries,	O
we	O
propose	O
i)	O
a	O
novel	O
hybrid	O
zero-shot	O
proxy	O
which	O
outperforms	O
existing	O
ones	O
by	O
a	O
large	O
margin	O
and	O
is	O
transferable	O
among	O
popular	O
search	O
spaces;	O
ii)	O
a	O
new	O
index	O
for	O
better	O
measuring	O
the	O
true	O
performance	O
of	O
ZS-NAS	O
proxies	O
in	O
constrained	O
NAS.	O
Source	O
code	O
and	O
the	O
NAS-Bench-Zero	O
dataset	O
will	O
be	O
released	O
after	O
publication.	O

Graph	O
neural	O
networks	O
(GNN)	O
have	O
shown	O
great	O
success	O
in	O
learning	O
from	O
graph-structured	O
data.	O
They	O
are	O
widely	O
used	O
in	O
various	O
applications,	O
such	O
as	O
recommendation,	O
fraud	O
detection,	O
and	O
search.	O
In	O
these	O
domains,	O
the	O
graphs	O
are	O
typically	O
large,	O
containing	O
hundreds	O
of	O
millions	O
of	O
nodes	O
and	O
several	O
billions	O
of	O
edges.	O
To	O
tackle	O
this	O
challenge,	O
we	O
develop	O
DistDGL	O
,	O
a	O
system	O
for	O
training	O
GNNs	O
in	O
a	O
mini-batch	O
fashion	O
on	O
a	O
cluster	O
of	O
machines.	O
DistDGL	O
is	O
based	O
on	O
the	O
Deep	O
Graph	O
Library	O
(DGL),	O
a	O
popular	O
GNN	O
development	O
framework.	O
DistDGL	O
distributes	O
the	O
graph	O
and	O
its	O
associated	O
data	O
(initial	O
features	O
and	O
embeddings)	O
across	O
the	O
machines	O
and	O
uses	O
this	O
distribution	O
to	O
derive	O
a	O
computational	O
decomposition	O
by	O
following	O
an	O
owner-compute	O
rule.	O
DistDGL	O
follows	O
a	O
synchronous	O
training	O
approach	O
and	O
allows	O
ego-networks	O
forming	O
the	O
mini-batches	O
to	O
include	O
non-local	O
nodes.	O
To	O
minimize	O
the	O
overheads	O
associated	O
with	O
distributed	O
computations,	O
DistDGL	O
uses	O
a	O
high-quality	O
and	O
light-weight	O
min-cut	O
graph	B-RESEARCH_PROBLEM
partitioning	E-RESEARCH_PROBLEM
algorithm	O
along	O
with	O
multiple	O
balancing	O
constraints.	O
This	O
allows	O
it	O
to	O
reduce	O
communication	O
overheads	O
and	O
statically	O
balance	O
the	O
computations.	O
It	O
further	O
reduces	O
the	O
communication	O
by	O
replicating	O
halo	O
nodes	O
and	O
by	O
using	O
sparse	O
embedding	O
updates.	O
The	O
combination	O
of	O
these	O
design	O
choices	O
allows	O
DistDGL	O
to	O
train	O
high-quality	O
models	O
while	O
achieving	O
high	O
parallel	O
efficiency	O
and	O
memory	O
scalability.	O
We	O
demonstrate	O
our	O
optimizations	O
on	O
both	O
inductive	O
and	O
transductive	O
GNN	O
models.	O
Our	O
results	O
show	O
that	O
DistDGL	O
achieves	O
linear	O
speedup	O
without	O
compromising	O
model	O
accuracy	O
and	O
requires	O
only	O
13	O
seconds	O
to	O
complete	O
a	O
training	O
epoch	O
for	O
a	O
graph	O
with	O
100	O
million	O
nodes	O
and	O
3	O
billion	O
edges	O
on	O
a	O
cluster	O
with	O
16	O
machines.	O
DistDGL	O
is	O
now	O
publicly	O
available	O
as	O
part	O
of	O
DGL:https://github.com/dmlc/dgl/tree/master/python/dgl/distributed.	O

Performance	O
of	O
fingerprint	O
recognition	O
algorithms	O
substantially	O
rely	O
on	O
fine	O
features	O
extracted	O
from	O
fingerprints.	O
Apart	O
from	O
minutiae	O
and	O
ridge	O
patterns,	O
pore	O
features	O
have	O
proven	O
to	O
be	O
usable	O
for	O
fingerprint	O
recognition.	O
Although	O
features	O
from	O
minutiae	O
and	O
ridge	O
patterns	O
are	O
quite	O
attainable	O
from	O
low-resolution	O
images,	O
using	O
pore	O
features	O
is	O
practical	O
only	O
if	O
the	O
fingerprint	O
image	O
is	O
of	O
high	O
resolution	O
which	O
necessitates	O
a	O
model	O
that	O
enhances	O
the	O
image	O
quality	O
of	O
the	O
conventional	O
500	O
ppi	O
legacy	O
fingerprints	O
preserving	O
the	O
fine	O
details.	O
To	O
find	O
a	O
solution	O
for	O
recovering	O
pore	O
information	O
from	O
low-resolution	O
fingerprints,	O
we	O
adopt	O
a	O
joint	O
learning-based	O
approach	O
that	O
combines	O
both	O
super-resolution	O
and	O
pore	O
detection	O
networks.	O
Our	O
modified	O
single	O
image	O
Super-Resolution	S-RESEARCH_PROBLEM
Generative	O
Adversarial	O
Network	O
(SRGAN	O
)	O
framework	O
helps	O
to	O
reliably	O
reconstruct	O
high-resolution	O
fingerprint	O
samples	O
from	O
low-resolution	O
ones	O
assisting	O
the	O
pore	O
detection	O
network	O
to	O
identify	O
pores	O
with	O
a	O
high	O
accuracy.	O
The	O
network	O
jointly	O
learns	O
a	O
distinctive	O
feature	O
representation	O
from	O
a	O
real	O
low-resolution	O
fingerprint	O
sample	O
and	O
successfully	O
synthesizes	O
a	O
high-resolution	O
sample	O
from	O
it.	O
To	O
add	O
discriminative	O
information	O
and	O
uniqueness	O
for	O
all	O
the	O
subjects,	O
we	O
have	O
integrated	O
features	O
extracted	O
from	O
a	O
deep	O
fingerprint	O
verifier	O
with	O
the	O
SRGAN	O
quality	O
discriminator.	O
We	O
also	O
add	O
ridge	O
reconstruction	O
loss,	O
utilizing	O
ridge	O
patterns	O
to	O
make	O
the	O
best	O
use	O
of	O
extracted	O
features.	O
Our	O
proposed	O
method	O
solves	O
the	O
recognition	O
problem	O
by	O
improving	O
the	O
quality	O
of	O
fingerprint	O
images.	O
High	O
recognition	O
accuracy	O
of	O
the	O
synthesized	O
samples	O
that	O
is	O
close	O
to	O
the	O
accuracy	O
achieved	O
using	O
the	O
original	O
high-resolution	O
images	O
validate	O
the	O
effectiveness	O
of	O
our	O
proposed	O
model.	O

The	O
growing	O
interest	O
in	O
argument	O
mining	O
and	O
computational	O
argumentation	O
brings	O
with	O
it	O
a	O
plethora	O
of	O
Natural	B-RESEARCH_PROBLEM
Language	I-RESEARCH_PROBLEM
Understanding	E-RESEARCH_PROBLEM
(NLU)	O
tasks	O
and	O
corresponding	O
datasets.	O
However,	O
as	O
with	O
many	O
other	O
NLU	O
tasks,	O
the	O
dominant	O
language	O
is	O
English,	O
with	O
resources	O
in	O
other	O
languages	O
being	O
few	O
and	O
far	O
between.	O
In	O
this	O
work,	O
we	O
explore	O
the	O
potential	O
of	O
transfer	O
learning	O
using	O
the	O
multilingual	O
BERT	O
model	O
to	O
address	O
argument	O
mining	O
tasks	O
in	O
non-English	O
languages,	O
based	O
on	O
English	O
datasets	O
and	O
the	O
use	O
of	O
machine	O
translation.	O
We	O
show	O
that	O
such	O
methods	O
are	O
well	O
suited	O
for	O
classifying	O
the	O
stance	O
of	O
arguments	O
and	O
detecting	O
evidence,	O
but	O
less	O
so	O
for	O
assessing	O
the	O
quality	O
of	O
arguments,	O
presumably	O
because	O
quality	O
is	O
harder	O
to	O
preserve	O
under	O
translation.	O
In	O
addition,	O
focusing	O
on	O
the	O
translate-train	O
approach,	O
we	O
show	O
how	O
the	O
choice	O
of	O
languages	O
for	O
translation,	O
and	O
the	O
relations	O
among	O
them,	O
affect	O
the	O
accuracy	O
of	O
the	O
resultant	O
model.	O
Finally,	O
to	O
facilitate	O
evaluation	O
of	O
transfer	O
learning	O
on	O
argument	O
mining	O
tasks,	O
we	O
provide	O
a	O
human-generated	O
dataset	O
with	O
more	O
than	O
10k	O
arguments	O
in	O
multiple	O
languages,	O
as	O
well	O
as	O
machine	O
translation	O
of	O
the	O
English	O
datasets.	O

Human	B-RESEARCH_PROBLEM
motion	I-RESEARCH_PROBLEM
prediction	E-RESEARCH_PROBLEM
is	O
a	O
necessary	O
component	O
for	O
many	O
applications	O
in	O
robotics	O
and	O
autonomous	O
driving.	O
Recent	O
methods	O
propose	O
using	O
sequence-to-sequence	O
deep	O
learning	O
models	O
to	O
tackle	O
this	O
problem.	O
However,	O
they	O
do	O
not	O
focus	O
on	O
exploiting	O
different	O
temporal	O
scales	O
for	O
different	O
length	O
inputs.	O
We	O
argue	O
that	O
the	O
diverse	O
temporal	O
scales	O
are	O
important	O
as	O
they	O
allow	O
us	O
to	O
look	O
at	O
the	O
past	O
frames	O
with	O
different	O
receptive	O
fields,	O
which	O
can	O
lead	O
to	O
better	O
predictions.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
Temporal	O
Inception	O
Module	O
(TIM)	O
to	O
encode	O
human	O
motion.	O
Making	O
use	O
of	O
TIM,	O
our	O
framework	O
produces	O
input	O
embeddings	O
using	O
convolutional	O
layers,	O
by	O
using	O
different	O
kernel	O
sizes	O
for	O
different	O
input	O
lengths.	O
The	O
experimental	O
results	O
on	O
standard	O
motion	O
prediction	O
benchmark	O
datasets	O
Human3.6M	O
and	O
CMU	O
motion	O
capture	O
dataset	O
show	O
that	O
our	O
approach	O
consistently	O
outperforms	O
the	O
state	O
of	O
the	O
art	O
methods.	O

We	O
explore	O
an	O
ensembled	O
$\Sigma$-net	O
for	O
fast	O
parallel	O
MR	O
imaging,	O
including	O
parallel	O
coil	O
networks,	O
which	O
perform	O
implicit	O
coil	O
weighting,	O
and	O
sensitivity	O
networks,	O
involving	O
explicit	O
sensitivity	O
maps.	O
The	O
networks	O
in	O
$\Sigma$-net	O
are	O
trained	O
in	O
a	O
supervised	O
way,	O
including	O
content	O
and	O
GAN	O
losses,	O
and	O
with	O
various	O
ways	O
of	O
data	O
consistency,	O
i.e.,	O
proximal	O
mappings,	O
gradient	O
descent	O
and	O
variable	O
splitting.	O
A	O
semi-supervised	O
finetuning	O
scheme	O
allows	O
us	O
to	O
adapt	O
to	O
the	O
k-space	O
data	O
at	O
test	O
time,	O
which,	O
however,	O
decreases	O
the	O
quantitative	O
metrics,	O
although	O
generating	O
the	O
visually	O
most	O
textured	O
and	O
sharp	O
images.	O
For	O
this	O
challenge,	O
we	O
focused	O
on	O
robust	O
and	O
high	O
SSIM	S-RESEARCH_PROBLEM
scores,	O
which	O
we	O
achieved	O
by	O
ensembling	O
all	O
models	O
to	O
a	O
$\Sigma$-net.	O

This	O
paper	O
describes	O
the	O
machine	O
translation	O
systems	O
developed	O
by	O
the	O
Barcelona	O
Supercomputing	O
(BSC)	O
team	O
for	O
the	O
biomedical	O
translation	O
shared	O
task	O
of	O
WMT19.	O
Our	O
system	O
is	O
based	O
on	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
unsing	O
the	O
OpenNMT-py	O
toolkit	O
and	O
Transformer	O
architecture.	O
We	O
participated	O
in	O
four	O
translation	O
directions	O
for	O
the	O
English/Spanish	O
and	O
English/Portuguese	O
language	O
pairs.	O
To	O
create	O
our	O
training	O
data,	O
we	O
concatenated	O
several	O
parallel	O
corpora,	O
both	O
from	O
in-domain	O
and	O
out-of-domain	O
sources,	O
as	O
well	O
as	O
terminological	O
resources	O
from	O
UMLS.	O

In	O
graphs	O
with	O
rich	O
texts,	O
incorporating	O
textual	O
information	O
with	O
structural	O
information	O
would	O
benefit	O
constructing	O
expressive	O
graph	O
embeddings.	O
Among	O
various	O
graph	O
embedding	O
models,	O
random	O
walk	O
(RW)-based	O
is	O
one	O
of	O
the	O
most	O
popular	O
and	O
successful	O
groups.	O
However,	O
it	O
is	O
challenged	O
by	O
two	O
issues	O
when	O
applied	O
on	O
graphs	O
with	O
rich	O
texts:	O
(i)	O
sampling	O
efficiency:	O
deriving	O
from	O
the	O
training	O
objective	O
of	O
RW-based	O
models	O
(e.g.,	O
DeepWalk	O
and	O
node2vec),	O
we	O
show	O
that	O
RW-based	O
models	O
are	O
likely	O
to	O
generate	O
large	O
amounts	O
of	O
redundant	O
training	O
samples	O
due	O
to	O
three	O
main	O
drawbacks.	O
(ii)	O
text	O
utilization:	O
these	O
models	O
have	O
difficulty	O
in	O
dealing	O
with	O
zero-shot	O
scenarios	O
where	O
graph	O
embedding	O
models	O
have	O
to	O
infer	O
graph	O
structures	O
directly	O
from	O
texts.	O
To	O
solve	O
these	O
problems,	O
we	O
propose	O
a	O
novel	O
framework,	O
namely	O
Text-driven	O
Graph	B-RESEARCH_PROBLEM
Embedding	E-RESEARCH_PROBLEM
with	O
Pairs	O
Sampling	O
(TGE-PS).	O
TGE-PS	O
uses	O
Pairs	O
Sampling	O
(PS)	O
to	O
improve	O
the	O
sampling	O
strategy	O
of	O
RW,	O
being	O
able	O
to	O
reduce	O
~99%	O
training	O
samples	O
while	O
preserving	O
competitive	O
performance.	O
TGE-PS	O
uses	O
Text-driven	O
Graph	B-RESEARCH_PROBLEM
Embedding	E-RESEARCH_PROBLEM
(TGE),	O
an	O
inductive	O
graph	O
embedding	O
approach,	O
to	O
generate	O
node	O
embeddings	O
from	O
texts.	O
Since	O
each	O
node	O
contains	O
rich	O
texts,	O
TGE	O
is	O
able	O
to	O
generate	O
high-quality	O
embeddings	O
and	O
provide	O
reasonable	O
predictions	O
on	O
existence	O
of	O
links	O
to	O
unseen	O
nodes.	O
We	O
evaluate	O
TGE-PS	O
on	O
several	O
real-world	O
datasets,	O
and	O
experiment	O
results	O
demonstrate	O
that	O
TGE-PS	O
produces	O
state-of-the-art	O
results	O
on	O
both	O
traditional	O
and	O
zero-shot	O
link	O
prediction	O
tasks.	O

Today's	O
Automatic	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
systems	O
only	O
rely	O
on	O
acoustic	O
signalsand	O
often	O
don't	O
perform	O
well	O
under	O
noisy	O
conditions.	O
Performing	O
multi-modalspeech	O
recognition	O
-	O
processing	O
acoustic	O
speech	O
signals	O
and	O
lip-reading	O
videosimultaneously	O
-	O
significantly	O
enhances	O
the	O
performance	O
of	O
such	O
systems,especially	O
in	O
noisy	O
environments.	O
This	O
work	O
presents	O
the	O
design	O
of	O
such	O
anaudio-visual	O
system	O
for	O
Automated	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
,	O
taking	O
memory	O
andcomputation	O
requirements	O
into	O
account.	O
First,	O
a	O
Long-Short-Term-Memory	O
neuralnetwork	O
for	O
acoustic	O
speech	O
recognition	O
is	O
designed.	O
Second,	O
ConvolutionalNeural	O
Networks	O
are	O
used	O
to	O
model	O
lip-reading	O
features.	O
These	O
are	O
combined	O
withan	O
LSTM	O
network	O
to	O
model	O
temporal	O
dependencies	O
and	O
perform	O
automaticlip-reading	O
on	O
video.	O
Finally,	O
acoustic-speech	O
and	O
visual	O
lip-reading	O
networksare	O
combined	O
to	O
process	O
acoustic	O
and	O
visual	O
features	O
simultaneously.	O
Anattention	O
mechanism	O
ensures	O
performance	O
of	O
the	O
model	O
in	O
noisy	O
environments.This	O
system	O
is	O
evaluated	O
on	O
the	O
TCD-TIMIT	O
'lipspeaker'	O
dataset	O
for	O
audio-visualphoneme	O
recognition	O
with	O
clean	O
audio	O
and	O
with	O
additive	O
white	O
noise	O
at	O
an	O
SNR	O
of0dB.	O
It	O
achieves	O
75.70%	O
and	O
58.55%	O
phoneme	O
accuracy	O
respectively,	O
over	O
14percentage	O
points	O
better	O
than	O
the	O
state-of-the-art	O
for	O
all	O
noise	O
levels.	O

In	O
this	O
paper,	O
we	O
present	O
various	O
systems	O
submitted	O
by	O
our	O
team	O
problemConquero	O
for	O
SemEval-2020	O
Shared	O
Task	O
12	O
Multilingual	O
Offensive	O
Language	B-RESEARCH_PROBLEM
Identification	E-RESEARCH_PROBLEM
in	O
Social	O
Media.	O
We	O
participated	O
in	O
all	O
the	O
three	O
sub-tasks	O
of	O
OffensEval-2020,	O
and	O
our	O
final	O
submissions	O
during	O
the	O
evaluation	O
phase	O
included	O
transformer-based	O
approaches	O
and	O
a	O
soft	O
label-based	O
approach.	O
BERT	O
based	O
fine-tuned	O
models	O
were	O
submitted	O
for	O
each	O
language	O
of	O
sub-task	O
A	O
(offensive	O
tweet	O
identification).	O
RoBERTa	O
based	O
fine-tuned	O
model	O
for	O
sub-task	O
B	O
(automatic	O
categorization	O
of	O
offense	O
types)	O
was	O
submitted.	O
We	O
submitted	O
two	O
models	O
for	O
sub-task	O
C	O
(offense	O
target	O
identification),	O
one	O
using	O
soft	O
labels	O
and	O
the	O
other	O
using	O
BERT	O
based	O
fine-tuned	O
model.	O
Our	O
ranks	O
for	O
sub-task	O
A	O
were	O
Greek-19	O
out	O
of	O
37,	O
Turkish-22	O
out	O
of	O
46,	O
Danish-26	O
out	O
of	O
39,	O
Arabic-39	O
out	O
of	O
53,	O
and	O
English-20	O
out	O
of	O
85.	O
We	O
achieved	O
a	O
rank	O
of	O
28	O
out	O
of	O
43	O
for	O
sub-task	O
B.	O
Our	O
best	O
rank	O
for	O
sub-task	O
C	O
was	O
20	O
out	O
of	O
39	O
using	O
BERT	O
based	O
fine-tuned	O
model.	O

Residual-based	O
neural	O
networks	O
have	O
shown	O
remarkable	O
results	O
in	O
variousvisual	O
recognition	O
tasks	O
including	O
Facial	B-RESEARCH_PROBLEM
Expression	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(FER).	O
Despitethe	O
tremendous	O
efforts	O
have	O
been	O
made	O
to	O
improve	O
the	O
performance	O
of	O
FER	O
systemsusing	O
DNNs,	O
existing	O
methods	O
are	O
not	O
generalizable	O
enough	O
for	O
practicalapplications.	O
This	O
paper	O
introduces	O
Bounded	O
Residual	O
Gradient	O
Networks(BReG-Net)	O
for	O
facial	O
expression	O
recognition,	O
in	O
which	O
the	O
shortcut	O
connectionbetween	O
the	O
input	O
and	O
the	O
output	O
of	O
the	O
ResNet	O
module	O
is	O
replaced	O
with	O
adifferentiable	O
function	O
with	O
a	O
bounded	O
gradient.	O
This	O
configuration	O
preventsthe	O
network	O
from	O
facing	O
the	O
vanishing	O
or	O
exploding	O
gradient	O
problem.	O
We	O
showthat	O
utilizing	O
such	O
non-linear	O
units	O
will	O
result	O
in	O
shallower	O
networks	O
withbetter	O
performance.	O
Further,	O
by	O
using	O
a	O
weighted	O
loss	O
function	O
which	O
gives	O
ahigher	O
priority	O
to	O
less	O
represented	O
categories,	O
we	O
can	O
achieve	O
an	O
overallbetter	O
recognition	O
rate.	O
The	O
results	O
of	O
our	O
experiments	O
show	O
that	O
BReG-Netsoutperform	O
state-of-the-art	O
methods	O
on	O
three	O
publicly	O
available	O
facialdatabases	O
in	O
the	O
wild,	O
on	O
both	O
the	O
categorical	O
and	O
dimensional	O
models	O
ofaffect.	O

Automated	O
medical	O
image	O
segmentation	O
is	O
a	O
priority	O
research	O
area	O
for	O
computational	O
methods.	O
In	O
particular,	O
detection	O
of	O
cancerous	O
tumors	O
represents	O
a	O
current	O
challenge	O
in	O
this	O
area	O
with	O
potential	O
for	O
real-world	O
impact.	O
This	O
paper	O
describes	O
a	O
method	O
developed	O
in	O
response	O
to	O
the	O
2019	O
Kidney	O
Tumor	B-RESEARCH_PROBLEM
Segmentation	E-RESEARCH_PROBLEM
Challenge	O
(KiTS19).	O
Axial	O
computed	O
tomography	O
(CT)	O
scans	O
from	O
210	O
kidney	O
cancer	O
patients	O
were	O
used	O
to	O
develop	O
and	O
evaluate	O
this	O
automatic	O
segmentation	O
method	O
based	O
on	O
a	O
logical	O
ensemble	O
of	O
fully-convolutional	O
network	O
(FCN	O
)	O
architectures,	O
followed	O
by	O
volumetric	O
validation.	O
Data	O
was	O
pre-processed	O
using	O
conventional	O
computer	O
vision	O
techniques,	O
thresholding,	O
histogram	O
equalization,	O
morphological	O
operations,	O
centering,	O
zooming	O
and	O
resizing.	O
Three	O
binary	O
FCN	O
segmentation	O
models	O
were	O
trained	O
to	O
classify	O
kidney	O
and	O
tumor	O
(2),	O
and	O
only	O
tumor	O
(1),	O
respectively.	O
Model	O
output	O
images	O
were	O
stacked	O
and	O
volumetrically	O
validated	O
to	O
produce	O
the	O
final	O
segmentation	O
for	O
each	O
patient	O
scan.	O
The	O
average	O
F1	O
score	O
from	O
kidney	O
and	O
tumor	O
pixel	O
classifications	O
was	O
calculated	O
as	O
0.6758	O
using	O
preprocessed	O
images	O
and	O
annotations;	O
although	O
restoring	O
to	O
the	O
original	O
image	O
format	O
reduced	O
this	O
score.	O
It	O
remains	O
to	O
be	O
seen	O
how	O
this	O
compares	O
to	O
other	O
solutions.	O

Multi-Task	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(MTL)	O
networks	O
have	O
emerged	O
as	O
a	O
promising	O
method	O
for	O
transferring	O
learned	O
knowledge	O
across	O
different	O
tasks.	O
However,	O
MTL	O
must	O
deal	O
with	O
challenges	O
such	O
as:	O
overfitting	O
to	O
low	O
resource	O
tasks,	O
catastrophic	O
forgetting,	O
and	O
negative	O
task	O
transfer,	O
or	O
learning	O
interference.	O
Often,	O
in	O
Natural	O
Language	O
Processing	O
(NLP),	O
a	O
separate	O
model	O
per	O
task	O
is	O
needed	O
to	O
obtain	O
the	O
best	O
performance.	O
However,	O
many	O
fine-tuning	O
approaches	O
are	O
both	O
parameter	O
inefficient,	O
i.e.,	O
potentially	O
involving	O
one	O
new	O
model	O
per	O
task,	O
and	O
highly	O
susceptible	O
to	O
losing	O
knowledge	O
acquired	O
during	O
pretraining.	O
We	O
propose	O
a	O
novel	O
Transformer	O
architecture	O
consisting	O
of	O
a	O
new	O
conditional	O
attention	O
mechanism	O
as	O
well	O
as	O
a	O
set	O
of	O
task-conditioned	O
modules	O
that	O
facilitate	O
weight	O
sharing.	O
Through	O
this	O
construction,	O
we	O
achieve	O
more	O
efficient	O
parameter	O
sharing	O
and	O
mitigate	O
forgetting	O
by	O
keeping	O
half	O
of	O
the	O
weights	O
of	O
a	O
pretrained	O
model	O
fixed.	O
We	O
also	O
use	O
a	O
new	O
multi-task	O
data	O
sampling	O
strategy	O
to	O
mitigate	O
the	O
negative	O
effects	O
of	O
data	O
imbalance	O
across	O
tasks.	O
Using	O
this	O
approach,	O
we	O
are	O
able	O
to	O
surpass	O
single	O
task	O
fine-tuning	O
methods	O
while	O
being	O
parameter	O
and	O
data	O
efficient	O
(using	O
around	O
66%	O
of	O
the	O
data	O
for	O
weight	O
updates).	O
Compared	O
to	O
other	O
BERT	O
Large	O
methods	O
on	O
GLUE,	O
our	O
8-task	O
model	O
surpasses	O
other	O
Adapter	O
methods	O
by	O
2.8%	O
and	O
our	O
24-task	O
model	O
outperforms	O
by	O
0.7-1.0%	O
models	O
that	O
use	O
MTL	O
and	O
single	O
task	O
fine-tuning.	O
We	O
show	O
that	O
a	O
larger	O
variant	O
of	O
our	O
single	O
multi-task	O
model	O
approach	O
performs	O
competitively	O
across	O
26	O
NLP	O
tasks	O
and	O
yields	O
state-of-the-art	O
results	O
on	O
a	O
number	O
of	O
test	O
and	O
development	O
sets.	O
Our	O
code	O
is	O
publicly	O
available	O
at	O
https://github.com/CAMTL/CA-MTL.	O

The	O
emergence	O
and	O
rapid	O
progress	O
of	O
the	O
Internet	O
have	O
brought	O
ever-increasing	O
impact	O
on	O
financial	O
domain.	O
How	O
to	O
rapidly	O
and	O
accurately	O
mine	O
the	O
key	O
information	O
from	O
the	O
massive	O
negative	O
financial	O
texts	O
has	O
become	O
one	O
of	O
the	O
key	O
issues	O
for	O
investors	O
and	O
decision	O
makers.	O
Aiming	O
at	O
the	O
issue,	O
we	O
propose	O
a	O
sentiment	O
analysis	O
and	O
key	O
entity	O
detection	O
approach	O
based	O
on	O
BERT	O
,	O
which	O
is	O
applied	O
in	O
online	O
financial	O
text	O
mining	O
and	O
public	O
opinion	O
analysis	O
in	O
social	O
media.	O
By	O
using	O
pre-train	O
model,	O
we	O
first	O
study	O
sentiment	O
analysis,	O
and	O
then	O
we	O
consider	O
key	O
entity	O
detection	O
as	O
a	O
sentence	O
matching	O
or	O
Machine	B-RESEARCH_PROBLEM
Reading	I-RESEARCH_PROBLEM
Comprehension	E-RESEARCH_PROBLEM
(MRC)	O
task	O
in	O
different	O
granularity.	O
Among	O
them,	O
we	O
mainly	O
focus	O
on	O
negative	O
sentimental	O
information.	O
We	O
detect	O
the	O
specific	O
entity	O
by	O
using	O
our	O
approach,	O
which	O
is	O
different	O
from	O
traditional	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER).	O
In	O
addition,	O
we	O
also	O
use	O
ensemble	O
learning	O
to	O
improve	O
the	O
performance	O
of	O
proposed	O
approach.	O
Experimental	O
results	O
show	O
that	O
the	O
performance	O
of	O
our	O
approach	O
is	O
generally	O
higher	O
than	O
SVM,	O
LR,	O
NBM,	O
and	O
BERT	O
for	O
two	O
financial	O
sentiment	O
analysis	O
and	O
key	O
entity	O
detection	O
datasets.	O

We	O
propose	O
a	O
novel	O
semantic	O
tagging	O
task,	O
sem-tagging,	O
tailored	O
for	O
thepurpose	O
of	O
multilingual	O
semantic	O
parsing,	O
and	O
present	O
the	O
first	O
tagger	O
usingdeep	O
residual	O
networks	O
(ResNet	O
s).	O
Our	O
tagger	O
uses	O
both	O
word	O
and	O
characterrepresentations	O
and	O
includes	O
a	O
novel	O
residual	O
bypass	O
architecture.	O
We	O
evaluatethe	O
tagset	O
both	O
intrinsically	O
on	O
the	O
new	O
task	O
of	O
semantic	O
tagging,	O
as	O
well	O
ason	O
Part-of-Speech	O
(POS	S-RESEARCH_PROBLEM
)	O
tagging.	O
Our	O
system,	O
consisting	O
of	O
a	O
ResNet	O
and	O
anauxiliary	O
loss	O
function	O
predicting	O
our	O
semantic	O
tags,	O
significantly	O
outperformsprior	O
results	O
on	O
English	O
Universal	O
Dependencies	O
POS	S-RESEARCH_PROBLEM
tagging	O
(95.71%	O
accuracy	O
onUD	O
v1.2	O
and	O
95.67%	O
accuracy	O
on	O
UD	O
v1.3).	O

Traditional	O
model	O
training	O
for	O
sentence	O
generation	O
employs	O
cross-entropy	O
loss	O
as	O
the	O
loss	O
function.	O
While	O
cross-entropy	O
loss	O
has	O
convenient	O
properties	O
for	O
supervised	O
learning,	O
it	O
is	O
unable	O
to	O
evaluate	O
sentences	O
as	O
a	O
whole,	O
and	O
lacks	O
flexibility.	O
We	O
present	O
the	O
approach	O
of	O
training	O
the	O
generation	O
model	O
using	O
the	O
estimated	O
semantic	O
similarity	O
between	O
the	O
output	O
and	O
reference	O
sentences	O
to	O
alleviate	O
the	O
problems	O
faced	O
by	O
the	O
training	O
with	O
cross-entropy	O
loss.	O
We	O
use	O
the	O
BERT-based	O
scorer	O
fine-tuned	O
to	O
the	O
Semantic	B-RESEARCH_PROBLEM
Textual	I-RESEARCH_PROBLEM
Similarity	E-RESEARCH_PROBLEM
(STS)	O
task	O
for	O
semantic	O
similarity	O
estimation,	O
and	O
train	O
the	O
model	O
with	O
the	O
estimated	O
scores	O
through	O
reinforcement	O
learning	O
(RL).	O
Our	O
experiments	O
show	O
that	O
reinforcement	O
learning	O
with	O
semantic	O
similarity	O
reward	O
improves	O
the	O
BLEU	O
scores	O
from	O
the	O
baseline	O
LSTM	O
NMT	O
model.	O

Deep	O
learning	O
methods,	O
in	O
particular	O
trained	O
Convolutional	O
Neural	O
Networks(CNNs)	O
have	O
recently	O
been	O
shown	O
to	O
produce	O
compelling	O
state-of-the-art	O
resultsfor	O
single	O
image	O
Super-Resolution	S-RESEARCH_PROBLEM
(SR).	O
Invariably,	O
a	O
CNN	O
is	O
learned	O
to	O
map	O
thelow	O
resolution	O
(LR)	O
image	O
to	O
its	O
corresponding	O
high	O
resolution	O
(HR)	O
version	O
inthe	O
spatial	O
domain.	O
Aiming	O
for	O
faster	O
inference	O
and	O
more	O
efficient	O
solutionsthan	O
solving	O
the	O
SR	O
problem	O
in	O
the	O
spatial	O
domain,	O
we	O
propose	O
a	O
novel	O
networkstructure	O
for	O
learning	O
the	O
SR	O
mapping	O
function	O
in	O
an	O
image	O
transform	O
domain,specifically	O
the	O
Discrete	O
Cosine	O
Transform	O
(DCT).	O
As	O
a	O
first	O
contribution,	O
weshow	O
that	O
DCT	O
can	O
be	O
integrated	O
into	O
the	O
network	O
structure	O
as	O
a	O
ConvolutionalDCT	O
(CDCT)	O
layer.	O
We	O
further	O
extend	O
the	O
network	O
to	O
allow	O
the	O
CDCT	O
layer	O
tobecome	O
trainable	O
(i.e.	O
optimizable).	O
Because	O
this	O
layer	O
represents	O
an	O
imagetransform,	O
we	O
enforce	O
pairwise	O
orthogonality	O
constraints	O
on	O
the	O
individualbasis	O
functions/filters.	O
This	O
Orthogonally	O
Regularized	O
Deep	O
SR	O
network	O
(ORDSR)simplifies	O
the	O
SR	O
task	O
by	O
taking	O
advantage	O
of	O
image	O
transform	O
domain	O
whileadapting	O
the	O
design	O
of	O
transform	O
basis	O
to	O
the	O
training	O
image	O
set.	O

An	O
Intrusion	B-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
System	O
(IDS)	O
is	O
a	O
key	O
cybersecurity	O
tool	O
for	O
network	O
administrators	O
as	O
it	O
identifies	O
malicious	O
traffic	O
and	O
cyberattacks.	O
With	O
the	O
recent	O
successes	O
of	O
machine	O
learning	O
techniques	O
such	O
as	O
deep	O
learning,	O
more	O
and	O
more	O
IDS	O
are	O
now	O
using	O
machine	O
learning	O
algorithms	O
to	O
detect	O
attacks	O
faster.	O
However,	O
these	O
systems	O
lack	O
robustness	O
when	O
facing	O
previously	O
unseen	O
types	O
of	O
attacks.	O
With	O
the	O
increasing	O
number	O
of	O
new	O
attacks,	O
especially	O
against	O
Internet	O
of	O
Things	O
devices,	O
having	O
a	O
robust	O
IDS	O
able	O
to	O
spot	O
unusual	O
and	O
new	O
attacks	O
becomes	O
necessary.	O
This	O
work	O
explores	O
the	O
possibility	O
of	O
leveraging	O
generative	O
adversarial	O
models	O
to	O
improve	O
the	O
robustness	O
of	O
machine	O
learning	O
based	O
IDS.	O
More	O
specifically,	O
we	O
propose	O
a	O
new	O
method	O
named	O
SIGMA,	O
that	O
leverages	O
adversarial	O
examples	O
to	O
strengthen	O
IDS	O
against	O
new	O
types	O
of	O
attacks.	O
Using	O
Generative	O
Adversarial	O
Networks	O
(GAN	O
)	O
and	O
metaheuristics,	O
SIGMA	O
%Our	O
method	O
consists	O
in	O
generates	O
adversarial	O
examples,	O
iteratively,	O
and	O
uses	O
it	O
to	O
retrain	O
a	O
machine	O
learning-based	O
IDS,	O
until	O
a	O
convergence	O
of	O
the	O
detection	O
rate	O
(i.e.	O
until	O
the	O
detection	O
system	O
is	O
not	O
improving	O
anymore).	O
A	O
round	O
of	O
improvement	O
consists	O
of	O
a	O
generative	O
phase,	O
in	O
which	O
we	O
use	O
GAN	O
s	O
and	O
metaheuristics	O
to	O
generate	O
instances	O
;	O
an	O
evaluation	O
phase	O
in	O
which	O
we	O
calculate	O
the	O
detection	O
rate	O
of	O
those	O
newly	O
generated	O
attacks	O
;	O
and	O
a	O
training	O
phase,	O
in	O
which	O
we	O
train	O
the	O
IDS	O
with	O
those	O
attacks.	O
We	O
have	O
evaluated	O
the	O
SIGMA	O
method	O
for	O
four	O
standard	O
machine	O
learning	O
classification	O
algorithms	O
acting	O
as	O
IDS,	O
with	O
a	O
combination	O
of	O
GAN	O
and	O
a	O
hybrid	O
local-search	O
and	O
genetic	O
algorithm,	O
to	O
generate	O
new	O
datasets	O
of	O
attacks.	O
Our	O
results	O
show	O
that	O
SIGMA	O
can	O
successfully	O
generate	O
adversarial	O
attacks	O
against	O
different	O
machine	O
learning	O
based	O
IDS.	O
Also,	O
using	O
SIGMA,	O
we	O
can	O
improve	O
the	O
performance	O
of	O
an	O
IDS	O
to	O
up	O
to	O
100\%	O
after	O
as	O
little	O
as	O
two	O
rounds	O
of	O
improvement.	O

The	O
field	O
of	O
conversational	O
agents	O
is	O
growing	O
fast	O
and	O
there	O
is	O
an	O
increasing	O
need	O
for	O
algorithms	O
that	O
enhance	O
natural	O
interaction.	O
In	O
this	O
work	O
we	O
show	O
how	O
we	O
achieved	O
state	O
of	O
the	O
art	O
results	O
in	O
the	O
Keyword	B-RESEARCH_PROBLEM
Spotting	E-RESEARCH_PROBLEM
field	O
by	O
adapting	O
and	O
tweaking	O
the	O
Xception	O
algorithm,	O
which	O
achieved	O
outstanding	O
results	O
in	O
several	O
computer	O
vision	O
tasks.	O
We	O
obtained	O
about	O
96\%	O
accuracy	O
when	O
classifying	O
audio	O
clips	O
belonging	O
to	O
35	O
different	O
categories,	O
beating	O
human	O
annotation	O
at	O
the	O
most	O
complex	O
tasks	O
proposed.	O

Text	B-RESEARCH_PROBLEM
Simplification	E-RESEARCH_PROBLEM
(TS	O
)	O
aims	O
to	O
reduce	O
the	O
linguistic	O
complexity	O
of	O
content	O
to	O
make	O
it	O
easier	O
to	O
understand.	O
Research	O
in	O
TS	O
has	O
been	O
of	O
keen	O
interest,	O
especially	O
as	O
approaches	O
to	O
TS	O
have	O
shifted	O
from	O
manual,	O
hand-crafted	O
rules	O
to	O
automated	O
simplification.	O
This	O
survey	O
seeks	O
to	O
provide	O
a	O
comprehensive	O
overview	O
of	O
TS	O
,	O
including	O
a	O
brief	O
description	O
of	O
earlier	O
approaches	O
used,	O
discussion	O
of	O
various	O
aspects	O
of	O
simplification	O
(lexical,	O
semantic	O
and	O
syntactic),	O
and	O
latest	O
techniques	O
being	O
utilized	O
in	O
the	O
field.	O
We	O
note	O
that	O
the	O
research	O
in	O
the	O
field	O
has	O
clearly	O
shifted	O
towards	O
utilizing	O
deep	O
learning	O
techniques	O
to	O
perform	O
TS	O
,	O
with	O
a	O
specific	O
focus	O
on	O
developing	O
solutions	O
to	O
combat	O
the	O
lack	O
of	O
data	O
available	O
for	O
simplification.	O
We	O
also	O
include	O
a	O
discussion	O
of	O
datasets	O
and	O
evaluations	O
metrics	O
commonly	O
used,	O
along	O
with	O
discussion	O
of	O
related	O
fields	O
within	O
Natural	O
Language	O
Processing	O
(NLP),	O
like	O
semantic	O
similarity.	O

The	O
goal	O
of	O
Word	B-RESEARCH_PROBLEM
Sense	I-RESEARCH_PROBLEM
Disambiguation	E-RESEARCH_PROBLEM
(WSD)	O
is	O
to	O
identify	O
the	O
sense	O
of	O
a	O
polysemous	O
word	O
in	O
a	O
specific	O
context.	O
Deep-learning	O
techniques	O
using	O
BERT	O
have	O
achieved	O
very	O
promising	O
results	O
in	O
the	O
field	O
and	O
different	O
methods	O
have	O
been	O
proposed	O
to	O
integrate	O
structured	O
knowledge	O
to	O
enhance	O
performance.	O
At	O
the	O
same	O
time,	O
an	O
increasing	O
number	O
of	O
data	O
augmentation	O
techniques	O
have	O
been	O
proven	O
to	O
be	O
useful	O
for	O
NLP	O
tasks.	O
Building	O
upon	O
previous	O
works	O
leveraging	O
BERT	O
and	O
WordNet	O
knowledge,	O
we	O
explore	O
different	O
data	O
augmentation	O
techniques	O
on	O
context-gloss	O
pairs	O
to	O
improve	O
the	O
performance	O
of	O
WSD.	O
In	O
our	O
experiment,	O
we	O
show	O
that	O
both	O
sentence-level	O
and	O
word-level	O
augmentation	O
methods	O
are	O
effective	O
strategies	O
for	O
WSD.	O
Also,	O
we	O
find	O
out	O
that	O
performance	O
can	O
be	O
improved	O
by	O
adding	O
hypernyms'	O
glosses	O
obtained	O
from	O
a	O
lexical	O
knowledge	O
base.	O
We	O
compare	O
and	O
analyze	O
different	O
context-gloss	O
augmentation	O
techniques,	O
and	O
the	O
results	O
show	O
that	O
applying	O
back	O
translation	O
on	O
gloss	O
performs	O
the	O
best.	O

Recent	O
advancements	O
in	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(NMT)	O
models	O
have	O
proved	O
to	O
produce	O
a	O
state	O
of	O
the	O
art	O
results	O
on	O
machine	O
translation	O
for	O
low	O
resource	O
Indian	O
languages.	O
This	O
paper	O
describes	O
the	O
neural	O
machine	O
translation	O
systems	O
for	O
the	O
English-Hindi	O
language	O
presented	O
in	O
AdapMT	O
Shared	O
Task	O
ICON	O
2020.	O
The	O
shared	O
task	O
aims	O
to	O
build	O
a	O
translation	O
system	O
for	O
Indian	O
languages	O
in	O
specific	O
domains	O
like	O
Artificial	O
Intelligence	O
(AI)	O
and	O
Chemistry	O
using	O
a	O
small	O
in-domain	O
parallel	O
corpus.	O
We	O
evaluated	O
the	O
effectiveness	O
of	O
two	O
popular	O
NMT	O
models	O
i.e,	O
LSTM,	O
and	O
Transformer	O
architectures	O
for	O
the	O
English-Hindi	O
machine	O
translation	O
task	O
based	O
on	O
BLEU	O
scores.	O
We	O
train	O
these	O
models	O
primarily	O
using	O
the	O
out	O
of	O
domain	O
data	O
and	O
employ	O
simple	O
domain	O
adaptation	O
techniques	O
based	O
on	O
the	O
characteristics	O
of	O
the	O
in-domain	O
dataset.	O
The	O
fine-tuning	O
and	O
mixed-domain	O
data	O
approaches	O
are	O
used	O
for	O
domain	O
adaptation.	O
Our	O
team	O
was	O
ranked	O
first	O
in	O
the	O
chemistry	O
and	O
general	O
domain	O
En-Hi	O
translation	O
task	O
and	O
second	O
in	O
the	O
AI	O
domain	O
En-Hi	O
translation	O
task.	O

The	O
use	O
of	O
code-switched	O
languages	O
(\textit{e.g.},	O
Hinglish,	O
which	O
is	O
derived	O
by	O
the	O
blending	O
of	O
Hindi	O
with	O
the	O
English	O
language)	O
is	O
getting	O
much	O
popular	O
on	O
Twitter	O
due	O
to	O
their	O
ease	O
of	O
communication	O
in	O
native	O
languages.	O
However,	O
spelling	O
variations	O
and	O
absence	O
of	O
grammar	O
rules	O
introduce	O
ambiguity	O
and	O
make	O
it	O
difficult	O
to	O
understand	O
the	O
text	O
automatically.	O
This	O
paper	O
presents	O
the	O
Multi-Input	O
Multi-Channel	O
Transfer	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
based	O
model	O
(MIMCT)	O
to	O
detect	O
offensive	O
(hate	O
speech	O
or	O
abusive)	O
Hinglish	O
tweets	O
from	O
the	O
proposed	O
Hinglish	O
Offensive	O
Tweet	O
(HOT)	O
dataset	O
using	O
transfer	O
learning	O
coupled	O
with	O
multiple	O
feature	O
inputs.	O
Specifically,	O
it	O
takes	O
multiple	O
primary	O
word	O
embedding	O
along	O
with	O
secondary	O
extracted	O
features	O
as	O
inputs	O
to	O
train	O
a	O
multi-channel	O
CNN-LSTM	O
architecture	O
that	O
has	O
been	O
pre-trained	O
on	O
English	O
tweets	O
through	O
transfer	O
learning.	O
The	O
proposed	O
MIMCT	O
model	O
outperforms	O
the	O
baseline	O
supervised	O
classification	O
models,	O
transfer	O
learning	O
based	O
CNN	O
and	O
LSTM	O
models	O
to	O
establish	O
itself	O
as	O
the	O
state	O
of	O
the	O
art	O
in	O
the	O
unexplored	O
domain	O
of	O
Hinglish	O
offensive	O
text	O
classification.	O

This	O
report	O
describes	O
the	O
systems	O
submitted	O
to	O
the	O
first	O
and	O
second	O
tracks	O
of	O
the	O
VoxCeleb	O
Speaker	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
Challenge	O
(VoxSRC)	O
2020,	O
which	O
ranked	O
second	O
in	O
both	O
tracks.	O
Three	O
key	O
points	O
of	O
the	O
system	O
pipeline	O
are	O
explored:	O
(1)	O
investigating	O
multiple	O
CNN	O
architectures	O
including	O
ResNet,	O
Res2Net	O
and	O
dual	O
path	O
network	O
(DPN)	O
to	O
extract	O
the	O
x-vectors,	O
(2)	O
using	O
a	O
composite	O
angular	O
margin	O
softmax	O
loss	O
to	O
train	O
the	O
speaker	O
models,	O
and	O
(3)	O
applying	O
score	O
normalization	O
and	O
system	O
fusion	O
to	O
boost	O
the	O
performance.	O
Measured	O
on	O
the	O
VoxSRC-20	O
Eval	O
set,	O
the	O
best	O
submitted	O
systems	O
achieve	O
an	O
EER	O
of	O
$3.808\%$	O
and	O
a	O
MinDCF	O
of	O
$0.1958$	O
in	O
the	O
close-condition	O
track	O
1,	O
and	O
an	O
EER	O
of	O
$3.798\%$	O
and	O
a	O
MinDCF	O
of	O
$0.1942$	O
in	O
the	O
open-condition	O
track	O
2,	O
respectively.	O

Most	O
existing	O
methods	O
for	O
biomedical	O
entity	O
recognition	O
task	O
rely	O
on	O
explicitfeature	O
engineering	O
where	O
many	O
features	O
either	O
are	O
specific	O
to	O
a	O
particulartask	O
or	O
depends	O
on	O
output	O
of	O
other	O
existing	O
NLP	O
tools.	O
Neural	O
architectureshave	O
been	O
shown	O
across	O
various	O
domains	O
that	O
efforts	O
for	O
explicit	O
feature	O
designcan	O
be	O
reduced.	O
In	O
this	O
work	O
we	O
propose	O
an	O
unified	O
framework	O
usingbi-directional	O
long	O
short	O
term	O
memory	O
network	O
(BLSTM)	O
for	O
named	O
entityrecognition	O
(NER	S-RESEARCH_PROBLEM
)	O
tasks	O
in	O
biomedical	O
and	O
clinical	O
domains.	O
Three	O
importantcharacteristics	O
of	O
the	O
framework	O
are	O
as	O
follows	O
-	O
(1)	O
model	O
learns	O
contextualas	O
well	O
as	O
morphological	O
features	O
using	O
two	O
different	O
BLSTM	O
in	O
hierarchy,	O
(2)model	O
uses	O
first	O
order	O
linear	O
conditional	O
random	O
field	O
(CRF	O
)	O
in	O
its	O
outputlayer	O
in	O
cascade	O
of	O
BLSTM	O
to	O
infer	O
label	O
or	O
tag	O
sequence,	O
(3)	O
model	O
does	O
notuse	O
any	O
domain	O
specific	O
features	O
or	O
dictionary,	O
i.e.,	O
in	O
another	O
words,	O
sameset	O
of	O
features	O
are	O
used	O
in	O
the	O
three	O
NER	S-RESEARCH_PROBLEM
tasks,	O
namely,	O
disease	O
namerecognition	O
(Disease	O
NER	S-RESEARCH_PROBLEM
),	O
drug	O
name	O
recognition	O
(Drug	O
NER	S-RESEARCH_PROBLEM
)	O
and	O
clinical	O
entityrecognition	O
(Clinical	O
NER	S-RESEARCH_PROBLEM
).	O
We	O
compare	O
performance	O
of	O
the	O
proposed	O
model	O
withexisting	O
state-of-the-art	O
models	O
on	O
the	O
standard	O
benchmark	O
datasets	O
of	O
thethree	O
tasks.	O
We	O
show	O
empirically	O
that	O
the	O
proposed	O
framework	O
outperforms	O
allexisting	O
models.	O
Further	O
our	O
analysis	O
of	O
CRF	O
layer	O
and	O
word-embedding	O
obtainedusing	O
character	O
based	O
embedding	O
show	O
their	O
importance.	O

Modeling	O
sequential	O
data	O
has	O
become	O
more	O
and	O
more	O
important	O
in	O
practice.	O
Someapplications	O
are	O
autonomous	O
driving,	O
virtual	O
sensors	O
and	O
weather	O
forecasting.To	O
model	O
such	O
systems	O
so	O
called	O
recurrent	O
models	O
are	O
used.	O
In	O
this	O
article	O
weintroduce	O
two	O
new	O
Deep	O
Recurrent	O
Gaussian	O
Process	O
(DRGP)	O
models	O
based	O
on	O
theSparse	O
Spectrum	O
Gaussian	O
Process	O
(SSGP)	O
and	O
the	O
improved	O
variational	O
versioncalled	O
Variational	O
Sparse	O
Spectrum	O
Gaussian	O
Process	O
(VSSGP).	O
We	O
follow	O
therecurrent	O
structure	O
given	O
by	O
an	O
existing	O
DRGP	O
based	O
on	O
a	O
specific	O
sparseNystr\"om	O
approximation.	O
Therefore,	O
we	O
also	O
variationally	O
integrate	O
out	O
theinput-space	O
and	O
hence	O
can	O
propagate	O
uncertainty	O
through	O
the	O
layers.	O
We	O
can	O
showthat	O
for	O
the	O
resulting	O
lower	O
bound	O
an	O
optimal	O
variational	O
distribution	O
exists.Training	O
is	O
realized	O
through	O
optimizing	O
the	O
variational	O
lower	O
bound.	O
UsingDistributed	O
Variational	B-RESEARCH_PROBLEM
Inference	E-RESEARCH_PROBLEM
(DVI),	O
we	O
can	O
reduce	O
the	O
computationalcomplexity.	O
We	O
improve	O
over	O
current	O
state	O
of	O
the	O
art	O
methods	O
in	O
predictionaccuracy	O
for	O
experimental	O
data-sets	O
used	O
for	O
their	O
evaluation	O
and	O
introduce	O
anew	O
data-set	O
for	O
engine	O
control,	O
named	O
Emission.	O
Furthermore,	O
our	O
method	O
caneasily	O
be	O
adapted	O
for	O
unsupervised	O
learning,	O
e.g.	O
the	O
latent	O
variable	O
model	O
andits	O
deep	O
version.	O

Many	O
mission-critical	O
systems	O
are	O
based	O
on	O
GPU	O
for	O
inference.	O
It	O
requires	O
not	O
only	O
high	O
recognition	O
accuracy	O
but	O
also	O
low	O
latency	O
in	O
responding	O
time.	O
Although	O
many	O
studies	O
are	O
devoted	O
to	O
optimizing	O
the	O
structure	O
of	O
deep	O
models	O
for	O
efficient	O
inference,	O
most	O
of	O
them	O
do	O
not	O
leverage	O
the	O
architecture	O
of	O
\textbf{modern	O
GPU}	O
for	O
fast	O
inference,	O
leading	O
to	O
suboptimal	O
performance.	O
To	O
address	O
this	O
issue,	O
we	O
propose	O
a	O
general	O
principle	O
for	O
designing	O
GPU-efficient	O
networks	O
based	O
on	O
extensive	O
empirical	O
studies.	O
This	O
design	O
principle	O
enables	O
us	O
to	O
search	O
for	O
GPU-efficient	O
network	O
structures	O
effectively	O
by	O
a	O
simple	O
and	O
lightweight	O
method	O
as	O
opposed	O
to	O
most	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(NAS)	O
methods	O
that	O
are	O
complicated	O
and	O
computationally	O
expensive.	O
Based	O
on	O
the	O
proposed	O
framework,	O
we	O
design	O
a	O
family	O
of	O
GPU-Efficient	O
Networks,	O
or	O
GENet	O
s	O
in	O
short.	O
We	O
did	O
extensive	O
evaluations	O
on	O
multiple	O
GPU	O
platforms	O
and	O
inference	O
engines.	O
While	O
achieving	O
$\geq	O
81.3\%$	O
top-1	O
accuracy	O
on	O
ImageNet,	O
GENet	O
is	O
up	O
to	O
$6.4$	O
times	O
faster	O
than	O
EfficienNet	O
on	O
GPU.	O
It	O
also	O
outperforms	O
most	O
state-of-the-art	O
models	O
that	O
are	O
more	O
efficient	O
than	O
EfficientNet	O
in	O
high	O
precision	O
regimes.	O
Our	O
source	O
code	O
and	O
pre-trained	O
models	O
are	O
available	O
from	O
\url{https://github.com/idstcv/GPU-Efficient-Networks}.	O

Designing	O
effective	O
architectures	O
is	O
one	O
of	O
the	O
key	O
factors	O
behind	O
the	O
success	O
of	O
deep	O
neural	O
networks.	O
Existing	O
deep	O
architectures	O
are	O
either	O
manually	O
designed	O
or	O
automatically	O
searched	O
by	O
some	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(NAS)	O
methods.	O
However,	O
even	O
a	O
well-searched	O
architecture	O
may	O
still	O
contain	O
many	O
non-significant	O
or	O
redundant	O
modules	O
or	O
operations	O
(e.g.,	O
convolution	O
or	O
pooling),	O
which	O
may	O
not	O
only	O
incur	O
substantial	O
memory	O
consumption	O
and	O
computation	O
cost	O
but	O
also	O
deteriorate	O
the	O
performance.	O
Thus,	O
it	O
is	O
necessary	O
to	O
optimize	O
the	O
operations	O
inside	O
an	O
architecture	O
to	O
improve	O
the	O
performance	O
without	O
introducing	O
extra	O
computation	O
cost.	O
Unfortunately,	O
such	O
a	O
constrained	O
optimization	O
problem	O
is	O
NP-hard.	O
To	O
make	O
the	O
problem	O
feasible,	O
we	O
cast	O
the	O
optimization	O
problem	O
into	O
a	O
Markov	O
decision	O
process	O
(MDP)	O
and	O
seek	O
to	O
learn	O
a	O
Neural	O
Architecture	O
Transformer	O
(NAT)	O
to	O
replace	O
the	O
redundant	O
operations	O
with	O
the	O
more	O
computationally	O
efficient	O
ones	O
(e.g.,	O
skip	O
connection	O
or	O
directly	O
removing	O
the	O
connection).	O
Based	O
on	O
MDP,	O
we	O
learn	O
NAT	O
by	O
exploiting	O
reinforcement	O
learning	O
to	O
obtain	O
the	O
optimization	O
policies	O
w.r.t.	O
different	O
architectures.	O
To	O
verify	O
the	O
effectiveness	O
of	O
the	O
proposed	O
strategies,	O
we	O
apply	O
NAT	O
on	O
both	O
hand-crafted	O
architectures	O
and	O
NAS	O
based	O
architectures.	O
Extensive	O
experiments	O
on	O
two	O
benchmark	O
datasets,	O
i.e.,	O
CIFAR-10	O
and	O
ImageNet,	O
demonstrate	O
that	O
the	O
transformed	O
architecture	O
by	O
NAT	O
significantly	O
outperforms	O
both	O
its	O
original	O
form	O
and	O
those	O
architectures	O
optimized	O
by	O
existing	O
methods.	O

Smart	O
systems	O
for	O
Universities	O
powered	O
by	O
Artificial	O
Intelligence	O
have	O
been	O
massively	O
developed	O
to	O
help	O
humans	O
in	O
various	O
tasks.	O
The	O
chatbot	O
concept	O
is	O
not	O
something	O
new	O
in	O
today	O
society	O
which	O
is	O
developing	O
with	O
recent	O
technology.	O
College	O
students	O
or	O
candidates	O
of	O
college	O
students	O
often	O
need	O
actual	O
information	O
like	O
asking	O
for	O
something	O
to	O
customer	O
service,	O
especially	O
during	O
this	O
pandemic,	O
when	O
it	O
is	O
difficult	O
to	O
have	O
an	O
immediate	O
face-to-face	O
meeting.	O
Chatbot	S-RESEARCH_PROBLEM
s	O
are	O
functionally	O
helping	O
in	O
several	O
things	O
such	O
as	O
curriculum	O
information,	O
admission	O
for	O
new	O
students,	O
schedule	O
info	O
for	O
any	O
lecture	O
courses,	O
students	O
grade	O
information,	O
and	O
some	O
adding	O
features	O
for	O
Muslim	O
worships	O
schedule,	O
also	O
weather	O
forecast	O
information.	O
This	O
Chatbot	S-RESEARCH_PROBLEM
is	O
developed	O
by	O
Deep	O
Learning	O
models,	O
which	O
was	O
adopted	O
by	O
an	O
artificial	O
intelligence	O
model	O
that	O
replicates	O
human	O
intelligence	O
with	O
some	O
specific	O
training	O
schemes.	O
This	O
kind	O
of	O
Deep	O
Learning	O
is	O
based	O
on	O
RNN	O
which	O
has	O
some	O
specific	O
memory	O
savings	O
scheme	O
for	O
the	O
Deep	O
Learning	O
Model,	O
specifically	O
this	O
chatbot	O
using	O
LSTM	O
which	O
already	O
integrates	O
by	O
RASA	O
framework.	O
LSTM	O
is	O
also	O
known	O
as	O
Long	O
Short	O
Term	O
Memory	O
which	O
efficiently	O
saves	O
some	O
required	O
memory	O
but	O
will	O
remove	O
some	O
memory	O
that	O
is	O
not	O
needed.	O
This	O
Chatbot	S-RESEARCH_PROBLEM
uses	O
the	O
FB	O
platform	O
because	O
of	O
the	O
FB	O
users	O
have	O
already	O
reached	O
up	O
to	O
60.8%	O
of	O
its	O
entire	O
population	O
in	O
Indonesia.	O
Here's	O
the	O
chatbot	O
only	O
focuses	O
on	O
case	O
studies	O
at	O
campus	O
of	O
the	O
Magister	O
Informatics	O
FTI	O
University	O
of	O
Islamic	O
Indonesia.	O
This	O
research	O
is	O
a	O
first	O
stage	O
development	O
within	O
fairly	O
sufficient	O
simulate	O
data.	O

In	O
this	O
paper	O
we	O
consider	O
the	O
problem	O
of	O
maximizing	O
the	O
Area	O
under	O
the	O
ROC	O
curve	O
(AUC)	O
which	O
is	O
a	O
widely	O
used	O
performance	O
metric	O
in	O
imbalanced	B-RESEARCH_PROBLEM
classification	E-RESEARCH_PROBLEM
and	O
anomaly	O
detection.	O
Due	O
to	O
the	O
pairwise	O
nonlinearity	O
of	O
the	O
objective	O
function,	O
classical	O
SGD	O
algorithms	O
do	O
not	O
apply	O
to	O
the	O
task	O
of	O
AUC	O
maximization.	O
We	O
propose	O
a	O
novel	O
stochastic	O
proximal	O
algorithm	O
for	O
AUC	O
maximization	O
which	O
is	O
scalable	O
to	O
large	O
scale	O
streaming	O
data.	O
Our	O
algorithm	O
can	O
accommodate	O
general	O
penalty	O
terms	O
and	O
is	O
easy	O
to	O
implement	O
with	O
favorable	O
$O(d)$	O
space	O
and	O
per-iteration	O
time	O
complexities.	O
We	O
establish	O
a	O
high-probability	O
convergence	O
rate	O
$O(1/\sqrt{T})$	O
for	O
the	O
general	O
convex	O
setting,	O
and	O
improve	O
it	O
to	O
a	O
fast	O
convergence	O
rate	O
$O(1/T)$	O
for	O
the	O
cases	O
of	O
strongly	O
convex	O
regularizers	O
and	O
no	O
regularization	O
term	O
(without	O
strong	O
convexity).	O
Our	O
proof	O
does	O
not	O
need	O
the	O
uniform	O
boundedness	O
assumption	O
on	O
the	O
loss	O
function	O
or	O
the	O
iterates	O
which	O
is	O
more	O
fidelity	O
to	O
the	O
practice.	O
Finally,	O
we	O
perform	O
extensive	O
experiments	O
over	O
various	O
benchmark	O
data	O
sets	O
from	O
real-world	O
application	O
domains	O
which	O
show	O
the	O
superior	O
performance	O
of	O
our	O
algorithm	O
over	O
the	O
existing	O
AUC	O
maximization	O
algorithms.	O

Signal	O
alignment	O
has	O
become	O
a	O
popular	O
problem	O
in	O
robotics	O
due	O
in	O
part	O
to	O
itsfundamental	O
role	O
in	O
action	O
recognition.	O
Currently,	O
the	O
most	O
successfulalgorithms	O
for	O
signal	O
alignment	O
are	O
Dynamic	B-RESEARCH_PROBLEM
Time	I-RESEARCH_PROBLEM
Warping	E-RESEARCH_PROBLEM
(DTW	O
)	O
and	O
its	O
variant'Fast'	O
Dynamic	B-RESEARCH_PROBLEM
Time	I-RESEARCH_PROBLEM
Warping	E-RESEARCH_PROBLEM
(FastDTW	O
).	O
Here	O
we	O
introduce	O
a	O
new	O
framework	O
forsignal	O
alignment,	O
namely	O
the	O
Globally	O
Optimal	O
Reparameterization	O
Algorithm(GORA).	O
We	O
review	O
the	O
algorithm's	O
mathematical	O
foundation	O
and	O
provide	O
anumerical	O
verification	O
of	O
its	O
theoretical	O
basis.	O
We	O
compare	O
the	O
performance	O
ofGORA	O
with	O
that	O
of	O
the	O
DTW	O
and	O
FastDTW	O
algorithms,	O
in	O
terms	O
of	O
computationalefficiency	O
and	O
accuracy	O
in	O
matching	O
signals.	O
Our	O
results	O
show	O
a	O
significantimprovement	O
in	O
both	O
speed	O
and	O
accuracy	O
over	O
the	O
DTW	O
and	O
FastDTW	O
algorithms	O
andsuggest	O
that	O
GORA	O
has	O
the	O
potential	O
to	O
provide	O
a	O
highly	O
effective	O
framework	O
forsignal	O
alignment	O
and	O
action	O
recognition.	O

Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER	S-RESEARCH_PROBLEM
)	O
from	O
social	O
media	O
posts	O
is	O
a	O
challenging	O
task.	O
User	O
generated	O
content	O
that	O
forms	O
the	O
nature	O
of	O
social	O
media,	O
is	O
noisy	O
and	O
contains	O
grammatical	O
and	O
linguistic	O
errors.	O
This	O
noisy	O
content	O
makes	O
it	O
much	O
harder	O
for	O
tasks	O
such	O
as	O
named	O
entity	O
recognition.	O
We	O
propose	O
two	O
novel	O
deep	O
learning	O
approaches	O
utilizing	O
multimodal	O
deep	O
learning	O
and	O
Transformers.	O
Both	O
of	O
our	O
approaches	O
use	O
image	O
features	O
from	O
short	O
social	O
media	O
posts	O
to	O
provide	O
better	O
results	O
on	O
the	O
NER	S-RESEARCH_PROBLEM
task.	O
On	O
the	O
first	O
approach,	O
we	O
extract	O
image	O
features	O
using	O
InceptionV3	O
and	O
use	O
fusion	O
to	O
combine	O
textual	O
and	O
image	O
features.	O
This	O
presents	O
more	O
reliable	O
name	O
entity	O
recognition	O
when	O
the	O
images	O
related	O
to	O
the	O
entities	O
are	O
provided	O
by	O
the	O
user.	O
On	O
the	O
second	O
approach,	O
we	O
use	O
image	O
features	O
combined	O
with	O
text	O
and	O
feed	O
it	O
into	O
a	O
BERT	O
like	O
Transformer.	O
The	O
experimental	O
results,	O
namely,	O
the	O
precision,	O
recall	O
and	O
F1	O
score	O
metrics	O
show	O
the	O
superiority	O
of	O
our	O
work	O
compared	O
to	O
other	O
state-of-the-art	O
NER	S-RESEARCH_PROBLEM
solutions.	O

An	O
important	O
research	O
direction	O
in	O
machine	O
learning	O
has	O
centered	O
around	O
developing	O
meta-learning	O
algorithms	O
to	O
tackle	O
few-shot	O
learning.	O
An	O
especially	O
successful	O
algorithm	O
has	O
been	O
Model	O
Agnostic	O
Meta-Learning	S-RESEARCH_PROBLEM
(MAML	O
),	O
a	O
method	O
that	O
consists	O
of	O
two	O
optimization	O
loops,	O
with	O
the	O
outer	O
loop	O
finding	O
a	O
meta-initialization,	O
from	O
which	O
the	O
inner	O
loop	O
can	O
efficiently	O
learn	O
new	O
tasks.	O
Despite	O
MAML	O
's	O
popularity,	O
a	O
fundamental	O
open	O
question	O
remains	O
--	O
is	O
the	O
effectiveness	O
of	O
MAML	O
due	O
to	O
the	O
meta-initialization	O
being	O
primed	O
for	O
rapid	O
learning	O
(large,	O
efficient	O
changes	O
in	O
the	O
representations)	O
or	O
due	O
to	O
feature	O
reuse,	O
with	O
the	O
meta	O
initialization	O
already	O
containing	O
high	O
quality	O
features?	O
We	O
investigate	O
this	O
question,	O
via	O
ablation	O
studies	O
and	O
analysis	O
of	O
the	O
latent	O
representations,	O
finding	O
that	O
feature	O
reuse	O
is	O
the	O
dominant	O
factor.	O
This	O
leads	O
to	O
the	O
ANIL	O
(Almost	O
No	O
Inner	O
Loop)	O
algorithm,	O
a	O
simplification	O
of	O
MAML	O
where	O
we	O
remove	O
the	O
inner	O
loop	O
for	O
all	O
but	O
the	O
(task-specific)	O
head	O
of	O
a	O
MAML	O
-trained	O
network.	O
ANIL	O
matches	O
MAML	O
's	O
performance	O
on	O
benchmark	O
few-shot	O
image	O
classification	O
and	O
RL	O
and	O
offers	O
computational	O
improvements	O
over	O
MAML	O
.	O
We	O
further	O
study	O
the	O
precise	O
contributions	O
of	O
the	O
head	O
and	O
body	O
of	O
the	O
network,	O
showing	O
that	O
performance	O
on	O
the	O
test	O
tasks	O
is	O
entirely	O
determined	O
by	O
the	O
quality	O
of	O
the	O
learned	O
features,	O
and	O
we	O
can	O
remove	O
even	O
the	O
head	O
of	O
the	O
network	O
(the	O
NIL	O
algorithm).	O
We	O
conclude	O
with	O
a	O
discussion	O
of	O
the	O
rapid	O
learning	O
vs	O
feature	O
reuse	O
question	O
for	O
meta-learning	O
algorithms	O
more	O
broadly.	O

Most	O
of	O
the	O
recently	O
proposed	O
neural	O
models	O
for	O
named	O
entity	O
recognition	O
have	O
been	O
purely	O
data-driven,	O
with	O
a	O
strong	O
emphasis	O
on	O
getting	O
rid	O
of	O
the	O
efforts	O
for	O
collecting	O
external	O
resources	O
or	O
designing	O
hand-crafted	O
features.	O
This	O
could	O
increase	O
the	O
chance	O
of	O
overfitting	O
since	O
the	O
models	O
cannot	O
access	O
any	O
supervision	O
signal	O
beyond	O
the	O
small	O
amount	O
of	O
annotated	O
data,	O
limiting	O
their	O
power	O
to	O
generalize	O
beyond	O
the	O
annotated	O
entities.	O
In	O
this	O
work,	O
we	O
show	O
that	O
properly	O
utilizing	O
external	O
gazetteers	O
could	O
benefit	O
segmental	O
neural	O
NER	S-RESEARCH_PROBLEM
models.	O
We	O
add	O
a	O
simple	O
module	O
on	O
the	O
recently	O
proposed	O
hybrid	O
semi-Markov	O
CRF	O
architecture	O
and	O
observe	O
some	O
promising	O
results.	O

Recent	O
work	O
has	O
shown	O
the	O
efficiency	O
of	O
deep	O
learning	O
models	O
such	O
as	O
Fully	O
Convolutional	O
Networks	O
(FCN)	O
or	O
Recurrent	O
Neural	O
Networks	O
(RNN)	O
to	O
deal	O
with	O
Time	B-RESEARCH_PROBLEM
Series	I-RESEARCH_PROBLEM
Regression	E-RESEARCH_PROBLEM
(TSR)	O
problems.	O
These	O
models	O
sometimes	O
need	O
a	O
lot	O
of	O
data	O
to	O
be	O
able	O
to	O
generalize,	O
yet	O
the	O
time	O
series	O
are	O
sometimes	O
not	O
long	O
enough	O
to	O
be	O
able	O
to	O
learn	O
patterns.	O
Therefore,	O
it	O
is	O
important	O
to	O
make	O
use	O
of	O
information	O
across	O
time	O
series	O
to	O
improve	O
learning.	O
In	O
this	O
paper,	O
we	O
will	O
explore	O
the	O
idea	O
of	O
using	O
meta-learning	O
for	O
quickly	O
adapting	O
model	O
parameters	O
to	O
new	O
short-history	O
time	O
series	O
by	O
modifying	O
the	O
original	O
idea	O
of	O
Model	O
Agnostic	O
Meta-Learning	S-RESEARCH_PROBLEM
(MAML	O
)	O
\cite{finn2017model}.	O
Moreover,	O
based	O
on	O
prior	O
work	O
on	O
multimodal	O
MAML	O
\cite{vuorio2019multimodal},	O
we	O
propose	O
a	O
method	O
for	O
conditioning	O
parameters	O
of	O
the	O
model	O
through	O
an	O
auxiliary	O
network	O
that	O
encodes	O
global	O
information	O
of	O
the	O
time	O
series	O
to	O
extract	O
meta-features.	O
Finally,	O
we	O
apply	O
the	O
data	O
to	O
time	O
series	O
of	O
different	O
domains,	O
such	O
as	O
pollution	O
measurements,	O
heart-rate	O
sensors,	O
and	O
electrical	O
battery	O
data.	O
We	O
show	O
empirically	O
that	O
our	O
proposed	O
meta-learning	O
method	O
learns	O
TSR	O
with	O
few	O
data	O
fast	O
and	O
outperforms	O
the	O
baselines	O
in	O
9	O
of	O
12	O
experiments.	O

Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER	S-RESEARCH_PROBLEM
)	O
is	O
a	O
fundamental	O
Natural	O
Language	O
Processing	O
(NLP)	O
task	O
to	O
extract	O
entities	O
from	O
unstructured	O
data.	O
The	O
previous	O
methods	O
for	O
NER	S-RESEARCH_PROBLEM
were	O
based	O
on	O
machine	O
learning	O
or	O
deep	O
learning.	O
Recently,	O
pre-training	O
models	O
have	O
significantly	O
improved	O
performance	O
on	O
multiple	O
NLP	O
tasks.	O
In	O
this	O
paper,	O
firstly,	O
we	O
introduce	O
the	O
architecture	O
and	O
pre-training	O
tasks	O
of	O
four	O
common	O
pre-training	O
models:	O
BERT,	O
ERNIE,	O
ERNIE2.0-tiny,	O
and	O
RoBERTa	O
.	O
Then,	O
we	O
apply	O
these	O
pre-training	O
models	O
to	O
a	O
NER	S-RESEARCH_PROBLEM
task	O
by	O
fine-tuning,	O
and	O
compare	O
the	O
effects	O
of	O
the	O
different	O
model	O
architecture	O
and	O
pre-training	O
tasks	O
on	O
the	O
NER	S-RESEARCH_PROBLEM
task.	O
The	O
experiment	O
results	O
showed	O
that	O
RoBERTa	O
achieved	O
state-of-the-art	O
results	O
on	O
the	O
MSRA-2006	O
dataset.	O

Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(NMT)	O
in	O
low-resource	O
settings	O
and	O
ofmorphologically	O
rich	O
languages	O
is	O
made	O
difficult	O
in	O
part	O
by	O
data	O
sparsity	O
ofvocabulary	O
words.	O
Several	O
methods	O
have	O
been	O
used	O
to	O
help	O
reduce	O
this	O
sparsity,notably	O
Byte-Pair	O
Encoding	O
(BPE	O
)	O
and	O
a	O
character-based	O
CNN	O
layer	O
(charCNN).However,	O
the	O
charCNN	O
has	O
largely	O
been	O
neglected,	O
possibly	O
because	O
it	O
has	O
onlybeen	O
compared	O
to	O
BPE	O
rather	O
than	O
combined	O
with	O
it.	O
We	O
argue	O
for	O
areconsideration	O
of	O
the	O
charCNN,	O
based	O
on	O
cross-lingual	O
improvements	O
onlow-resource	O
data.	O
We	O
translate	O
from	O
8	O
languages	O
into	O
English,	O
using	O
amulti-way	O
parallel	O
collection	O
of	O
TED	O
transcripts.	O
We	O
find	O
that	O
in	O
most	O
cases,using	O
both	O
BPE	O
and	O
a	O
charCNN	O
performs	O
best,	O
while	O
in	O
Hebrew,	O
using	O
a	O
charCNNover	O
words	O
is	O
best.	O

Reinforcement	O
Learning	O
(RL)	O
is	O
an	O
area	O
of	O
machine	O
learning	O
concerned	O
with	O
enabling	O
an	O
agent	O
to	O
navigate	O
an	O
environment	O
with	O
uncertainty	O
in	O
order	O
to	O
maximize	O
some	O
notion	O
of	O
cumulative	O
long-term	O
reward.	O
In	O
this	O
paper,	O
we	O
implement	O
and	O
analyze	O
two	O
different	O
RL	O
techniques,	O
Sarsa	O
and	O
Deep	O
QLearning,	O
on	O
OpenAI	O
Gym's	O
LunarLander-v2	O
environment.	O
We	O
then	O
introduce	O
additional	O
uncertainty	O
to	O
the	O
original	O
problem	O
to	O
test	O
the	O
robustness	O
of	O
the	O
mentioned	O
techniques.	O
With	O
our	O
best	O
models,	O
we	O
are	O
able	O
to	O
achieve	O
average	O
rewards	O
of	O
170+	O
with	O
the	O
Sarsa	O
agent	O
and	O
200+	O
with	O
the	O
Deep	O
Q-Learning	S-RESEARCH_PROBLEM
agent	O
on	O
the	O
original	O
problem.	O
We	O
also	O
show	O
that	O
these	O
techniques	O
are	O
able	O
to	O
overcome	O
the	O
additional	O
uncertainities	O
and	O
achieve	O
positive	O
average	O
rewards	O
of	O
100+	O
with	O
both	O
agents.	O
We	O
then	O
perform	O
a	O
comparative	O
analysis	O
of	O
the	O
two	O
techniques	O
to	O
conclude	O
which	O
agent	O
peforms	O
better.	O

Understanding	O
the	O
dynamic	O
behavior	O
of	O
tires	O
and	O
their	O
interactions	O
with	O
road	O
plays	O
an	O
important	O
role	O
in	O
designing	O
integrated	O
vehicle	O
control	O
strategies.	O
Accordingly,	O
having	O
access	O
to	O
reliable	O
information	O
about	O
the	O
tire-road	O
interactions	O
through	O
tire	O
embedded	O
sensors	O
is	O
very	O
demanding	O
for	O
developing	O
enhanced	O
vehicle	O
control	O
systems.	O
Thus,	O
the	O
main	O
objectives	O
of	O
the	O
present	O
research	O
work	O
are	O
i.	O
to	O
analyze	O
data	O
from	O
an	O
experimental	O
accelerometer-based	O
intelligent	O
tire	O
acquired	O
over	O
a	O
wide	O
range	O
of	O
maneuvers,	O
with	O
different	O
vertical	O
loads,	O
velocities,	O
and	O
high	O
slip	O
angles;	O
and	O
ii.	O
to	O
develop	O
a	O
lateral	O
force	O
predictor	O
based	O
on	O
a	O
machine	O
learning	O
tool,	O
more	O
specifically	O
the	O
Gaussian	O
Process	O
Regression	O
(GPR	S-RESEARCH_PROBLEM
)	O
technique.	O
It	O
is	O
delineated	O
that	O
the	O
proposed	O
intelligent	O
tire	O
system	O
can	O
provide	O
reliable	O
information	O
about	O
the	O
tire-road	O
interactions	O
even	O
in	O
the	O
case	O
of	O
high	O
slip	O
angles.	O
Besides,	O
the	O
lateral	O
forces	O
model	O
based	O
on	O
GPR	S-RESEARCH_PROBLEM
can	O
predict	O
forces	O
with	O
acceptable	O
accuracy	O
and	O
provide	O
level	O
of	O
uncertainties	O
that	O
can	O
be	O
very	O
useful	O
for	O
designing	O
vehicle	O
control	O
strategies.	O

Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(NMT)	O
methodologies	O
have	O
burgeoned	O
from	O
using	O
simple	O
feed-forward	O
architectures	O
to	O
the	O
state	O
of	O
the	O
art;	O
viz.	O
BERT	O
model.	O
The	O
use	O
cases	O
of	O
NMT	O
models	O
have	O
been	O
broadened	O
from	O
just	O
language	O
translations	O
to	O
conversational	O
agents	O
(chatbots),	O
abstractive	O
text	O
summarization,	O
image	O
captioning,	O
etc.	O
which	O
have	O
proved	O
to	O
be	O
a	O
gem	O
in	O
their	O
respective	O
applications.	O
This	O
paper	O
aims	O
to	O
study	O
the	O
major	O
trends	O
in	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
,	O
the	O
state	O
of	O
the	O
art	O
models	O
in	O
the	O
domain	O
and	O
a	O
high	O
level	O
comparison	O
between	O
them.	O

As	O
an	O
emerging	O
topic	O
in	O
face	O
recognition,	O
designing	O
margin-based	O
loss	O
functions	O
can	O
increase	O
the	O
feature	O
margin	O
between	O
different	O
classes	O
for	O
enhanced	O
discriminability.	O
More	O
recently,	O
the	O
idea	O
of	O
mining-based	O
strategies	O
is	O
adopted	O
to	O
emphasize	O
the	O
misclassified	O
samples,	O
achieving	O
promising	O
results.	O
However,	O
during	O
the	O
entire	O
training	O
process,	O
the	O
prior	O
methods	O
either	O
do	O
not	O
explicitly	O
emphasize	O
the	O
sample	O
based	O
on	O
its	O
importance	O
that	O
renders	O
the	O
hard	O
samples	O
not	O
fully	O
exploited;	O
or	O
explicitly	O
emphasize	O
the	O
effects	O
of	O
semi-hard/hard	O
samples	O
even	O
at	O
the	O
early	O
training	O
stage	O
that	O
may	O
lead	O
to	O
convergence	O
issue.	O
In	O
this	O
work,	O
we	O
propose	O
a	O
novel	O
Adaptive	O
Curriculum	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
loss	O
(CurricularFace	O
)	O
that	O
embeds	O
the	O
idea	O
of	O
curriculum	O
learning	O
into	O
the	O
loss	O
function	O
to	O
achieve	O
a	O
novel	O
training	O
strategy	O
for	O
deep	O
face	O
recognition,	O
which	O
mainly	O
addresses	O
easy	O
samples	O
in	O
the	O
early	O
training	O
stage	O
and	O
hard	O
ones	O
in	O
the	O
later	O
stage.	O
Specifically,	O
our	O
CurricularFace	O
adaptively	O
adjusts	O
the	O
relative	O
importance	O
of	O
easy	O
and	O
hard	O
samples	O
during	O
different	O
training	O
stages.	O
In	O
each	O
stage,	O
different	O
samples	O
are	O
assigned	O
with	O
different	O
importance	O
according	O
to	O
their	O
corresponding	O
difficultness.	O
Extensive	O
experimental	O
results	O
on	O
popular	O
benchmarks	O
demonstrate	O
the	O
superiority	O
of	O
our	O
CurricularFace	O
over	O
the	O
state-of-the-art	O
competitors.	O

The	O
internet	O
today	O
has	O
become	O
an	O
unrivalled	O
source	O
of	O
information	O
where	O
people	O
converse	O
on	O
content	O
based	O
websites	O
such	O
as	O
Quora,	O
Reddit,	O
StackOverflow	O
and	O
Twitter	O
asking	O
doubts	O
and	O
sharing	O
knowledge	O
with	O
the	O
world.	O
A	O
major	O
arising	O
problem	O
with	O
such	O
websites	O
is	O
the	O
proliferation	O
of	O
toxic	O
comments	O
or	O
instances	O
of	O
insincerity	O
wherein	O
the	O
users	O
instead	O
of	O
maintaining	O
a	O
sincere	O
motive	O
indulge	O
in	O
spreading	O
toxic	O
and	O
divisive	O
content.	O
The	O
straightforward	O
course	O
of	O
action	O
in	O
confronting	O
this	O
situation	O
is	O
detecting	O
such	O
content	O
beforehand	O
and	O
preventing	O
it	O
from	O
subsisting	O
online.	O
In	O
recent	O
times	O
Transfer	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
in	O
Natural	O
Language	O
Processing	O
has	O
seen	O
an	O
unprecedented	O
growth.	O
Today	O
with	O
the	O
existence	O
of	O
transformers	O
and	O
various	O
state	O
of	O
the	O
art	O
innovations,	O
a	O
tremendous	O
growth	O
has	O
been	O
made	O
in	O
various	O
NLP	O
domains.	O
The	O
introduction	O
of	O
BERT	O
has	O
caused	O
quite	O
a	O
stir	O
in	O
the	O
NLP	O
community.	O
As	O
mentioned,	O
when	O
published,	O
BERT	O
dominated	O
performance	O
benchmarks	O
and	O
thereby	O
inspired	O
many	O
other	O
authors	O
to	O
experiment	O
with	O
it	O
and	O
publish	O
similar	O
models.	O
This	O
led	O
to	O
the	O
development	O
of	O
a	O
whole	O
BERT-family,	O
each	O
member	O
being	O
specialized	O
on	O
a	O
different	O
task.	O
In	O
this	O
paper	O
we	O
solve	O
the	O
Insincere	O
Questions	O
Classification	O
problem	O
by	O
fine	O
tuning	O
four	O
cutting	O
age	O
models	O
viz	O
BERT,	O
RoBERTa,	O
DistilBERT	O
and	O
ALBERT.	O

Urban	O
ride-hailing	O
demand	O
prediction	O
is	O
a	O
crucial	O
but	O
challenging	O
task	O
for	O
intelligent	O
transportation	O
system	O
construction.	O
Predictable	O
ride-hailing	O
demand	O
can	O
facilitate	O
more	O
reasonable	O
vehicle	O
scheduling	O
and	O
online	O
car-hailing	O
platform	O
dispatch.	O
Conventional	O
deep	O
learning	O
methods	O
with	O
no	O
external	O
structured	O
data	O
can	O
be	O
accomplished	O
via	O
hybrid	O
models	O
of	O
CNNs	O
and	O
RNNs	O
by	O
meshing	O
plentiful	O
pixel-level	O
labeled	O
data,	O
but	O
spatial	O
data	O
sparsity	O
and	O
limited	O
learning	O
capabilities	O
on	O
temporal	O
long-term	O
dependencies	O
are	O
still	O
two	O
striking	O
bottlenecks.	O
To	O
address	O
these	O
limitations,	O
we	O
propose	O
a	O
new	O
virtual	O
graph	O
modeling	O
method	O
to	O
focus	O
on	O
significant	O
demand	O
regions	O
and	O
a	O
novel	O
Deep	O
Multi-View	O
Spatiotemporal	O
Virtual	O
Graph	O
Neural	O
Network	O
(DMVST-VGNN)	O
to	O
strengthen	O
learning	O
capabilities	O
of	O
spatial	O
dynamics	O
and	O
temporal	O
long-term	O
dependencies.	O
Specifically,	O
DMVST-VGNN	O
integrates	O
the	O
structures	O
of	O
1D	O
Convolutional	O
Neural	O
Network,	O
Multi	O
Graph	B-RESEARCH_PROBLEM
Attention	E-RESEARCH_PROBLEM
Neural	O
Network	O
and	O
Transformer	O
layer,	O
which	O
correspond	O
to	O
short-term	O
temporal	O
dynamics	O
view,	O
spatial	O
dynamics	O
view	O
and	O
long-term	O
temporal	O
dynamics	O
view	O
respectively.	O
In	O
this	O
paper,	O
experiments	O
are	O
conducted	O
on	O
two	O
large-scale	O
New	O
York	O
City	O
datasets	O
in	O
fine-grained	O
prediction	O
scenes.	O
And	O
the	O
experimental	O
results	O
demonstrate	O
effectiveness	O
and	O
superiority	O
of	O
DMVST-VGNN	O
framework	O
in	O
significant	O
citywide	O
ride-hailing	O
demand	O
prediction.	O

A	O
representation	O
learning	O
method	O
is	O
considered	O
stable	O
if	O
it	O
consistently	O
generates	O
similar	O
representation	O
of	O
the	O
given	O
data	O
across	O
multiple	O
runs.	O
Word	O
Embedding	O
Methods	O
(WEMs)	O
are	O
a	O
class	O
of	O
representation	O
learning	O
methods	O
that	O
generate	O
dense	O
vector	O
representation	O
for	O
each	O
word	O
in	O
the	O
given	O
text	O
data.	O
The	O
central	O
idea	O
of	O
this	O
paper	O
is	O
to	O
explore	O
the	O
stability	O
measurement	O
of	O
WEMs	O
using	O
intrinsic	O
evaluation	O
based	O
on	O
word	O
similarity.	O
We	O
experiment	O
with	O
three	O
popular	O
WEMs:	O
Word2Vec,	O
GloVe	O
,	O
and	O
fastText	O
.	O
For	O
stability	O
measurement,	O
we	O
investigate	O
the	O
effect	O
of	O
five	O
parameters	O
involved	O
in	O
training	O
these	O
models.	O
We	O
perform	O
experiments	O
using	O
four	O
real-world	O
datasets	O
from	O
different	O
domains:	O
Wikipedia,	O
News,	O
Song	O
lyrics,	O
and	O
European	O
parliament	O
proceedings.	O
We	O
also	O
observe	O
the	O
effect	O
of	O
WEM	O
stability	O
on	O
three	O
downstream	O
tasks:	O
Clustering,	O
POS	S-RESEARCH_PROBLEM
tagging,	O
and	O
Fairness	S-RESEARCH_PROBLEM
evaluation.	O
Our	O
experiments	O
indicate	O
that	O
amongst	O
the	O
three	O
WEMs,	O
fastText	O
is	O
the	O
most	O
stable,	O
followed	O
by	O
GloVe	O
and	O
Word2Vec.	O

Topic	O
models	O
are	O
one	O
of	O
the	O
most	O
popular	O
methods	O
for	O
learning	O
representationsof	O
text,	O
but	O
a	O
major	O
challenge	O
is	O
that	O
any	O
change	O
to	O
the	O
topic	O
model	O
requiresmathematically	O
deriving	O
a	O
new	O
inference	O
algorithm.	O
A	O
promising	O
approach	O
toaddress	O
this	O
problem	O
is	O
autoencoding	O
variational	O
Bayes	O
(AEVB),	O
but	O
it	O
hasproven	O
diffi-	O
cult	O
to	O
apply	O
to	O
topic	O
models	O
in	O
practice.	O
We	O
present	O
what	O
is	O
toour	O
knowledge	O
the	O
first	O
effective	O
AEVB	O
based	O
inference	O
method	O
for	O
latentDirichlet	O
allocation	O
(LDA	O
),	O
which	O
we	O
call	O
Autoencoded	O
Variational	B-RESEARCH_PROBLEM
Inference	E-RESEARCH_PROBLEM
ForTopic	O
Model	O
(AVITM).	O
This	O
model	O
tackles	O
the	O
problems	O
caused	O
for	O
AEVB	O
by	O
theDirichlet	O
prior	O
and	O
by	O
component	O
collapsing.	O
We	O
find	O
that	O
AVITM	O
matchestraditional	O
methods	O
in	O
accuracy	O
with	O
much	O
better	O
inference	O
time.	O
Indeed,because	O
of	O
the	O
inference	O
network,	O
we	O
find	O
that	O
it	O
is	O
unnecessary	O
to	O
pay	O
thecomputational	O
cost	O
of	O
running	O
variational	O
optimization	O
on	O
test	O
data.	O
BecauseAVITM	O
is	O
black	O
box,	O
it	O
is	O
readily	O
applied	O
to	O
new	O
topic	O
models.	O
As	O
a	O
dramaticillustration	O
of	O
this,	O
we	O
present	O
a	O
new	O
topic	O
model	O
called	O
ProdLDA	O
,	O
thatreplaces	O
the	O
mixture	O
model	O
in	O
LDA	O
with	O
a	O
product	O
of	O
experts.	O
By	O
changing	O
onlyone	O
line	O
of	O
code	O
from	O
LDA	O
,	O
we	O
find	O
that	O
ProdLDA	O
yields	O
much	O
more	O
interpretabletopics,	O
even	O
if	O
LDA	O
is	O
trained	O
via	O
collapsed	O
Gibbs	O
sampling.	O

Multiple-choice	O
Machine	B-RESEARCH_PROBLEM
Reading	I-RESEARCH_PROBLEM
Comprehension	E-RESEARCH_PROBLEM
(MRC)	O
is	O
an	O
important	O
and	O
challenging	O
Natural	B-RESEARCH_PROBLEM
Language	I-RESEARCH_PROBLEM
Understanding	E-RESEARCH_PROBLEM
(NLU)	O
task,	O
in	O
which	O
a	O
machine	O
must	O
choose	O
the	O
answer	O
to	O
a	O
question	O
from	O
a	O
set	O
of	O
choices,	O
with	O
the	O
question	O
placed	O
in	O
context	O
of	O
text	O
passages	O
or	O
dialog.	O
In	O
the	O
last	O
a	O
couple	O
of	O
years	O
the	O
NLU	O
field	O
has	O
been	O
revolutionized	O
with	O
the	O
advent	O
of	O
models	O
based	O
on	O
the	O
Transformer	O
architecture,	O
which	O
are	O
pretrained	O
on	O
massive	O
amounts	O
of	O
unsupervised	O
data	O
and	O
then	O
fine-tuned	O
for	O
various	O
supervised	O
learning	O
NLU	O
tasks.	O
Transformer	O
models	O
have	O
come	O
to	O
dominate	O
a	O
wide	O
variety	O
of	O
leader-boards	O
in	O
the	O
NLU	O
field;	O
in	O
the	O
area	O
of	O
MRC,	O
the	O
current	O
state-of-the-art	O
model	O
on	O
the	O
DREAM	O
dataset	O
(see[Sunet	O
al.,	O
2019])	O
fine	O
tunes	O
Albert,	O
a	O
large	O
pretrained	O
Transformer	O
-based	O
model,	O
and	O
addition-ally	O
combines	O
it	O
with	O
an	O
extra	O
layer	O
of	O
multi-head	O
attention	O
between	O
context	O
and	O
question-answer[Zhuet	O
al.,	O
2020].The	O
purpose	O
of	O
this	O
note	O
is	O
to	O
document	O
a	O
new	O
state-of-the-art	O
result	O
in	O
the	O
DREAM	O
task,	O
which	O
is	O
accomplished	O
by,	O
additionally,	O
performing	O
multi-task	O
learning	O
on	O
two	O
MRC	O
multi-choice	O
reading	O
comprehension	O
tasks	O
(RACE	O
and	O
DREAM).	O

State-of-the-art	O
natural	O
language	O
processing	O
systems	O
rely	O
on	O
supervision	O
inthe	O
form	O
of	O
annotated	O
data	O
to	O
learn	O
competent	O
models.	O
These	O
models	O
aregenerally	O
trained	O
on	O
data	O
in	O
a	O
single	O
language	O
(usually	O
English),	O
and	O
cannot	O
bedirectly	O
used	O
beyond	O
that	O
language.	O
Since	O
collecting	O
data	O
in	O
every	O
language	O
isnot	O
realistic,	O
there	O
has	O
been	O
a	O
growing	O
interest	O
in	O
cross-lingual	O
languageunderstanding	O
(XLU)	O
and	O
low-resource	O
cross-language	O
transfer.	O
In	O
this	O
work,	O
weconstruct	O
an	O
evaluation	O
set	O
for	O
XLU	O
by	O
extending	O
the	O
development	O
and	O
test	O
setsof	O
the	O
Multi-Genre	O
Natural	B-RESEARCH_PROBLEM
Language	I-RESEARCH_PROBLEM
Inference	E-RESEARCH_PROBLEM
Corpus	O
(MultiNLI)	O
to	O
15languages,	O
including	O
low-resource	O
languages	O
such	O
as	O
Swahili	O
and	O
Urdu.	O
We	O
hopethat	O
our	O
dataset,	O
dubbed	O
XNLI,	O
will	O
catalyze	O
research	O
in	O
cross-lingual	O
sentenceunderstanding	O
by	O
providing	O
an	O
informative	O
standard	O
evaluation	O
task.	O
Inaddition,	O
we	O
provide	O
several	O
baselines	O
for	O
multilingual	O
sentence	O
understanding,including	O
two	O
based	O
on	O
machine	O
translation	O
systems,	O
and	O
two	O
that	O
use	O
paralleldata	O
to	O
train	O
aligned	O
multilingual	O
bag-of-words	O
and	O
LSTM	O
encoders.	O
We	O
find	O
thatXNLI	O
represents	O
a	O
practical	O
and	O
challenging	O
evaluation	O
suite,	O
and	O
that	O
directlytranslating	O
the	O
test	O
data	O
yields	O
the	O
best	O
performance	O
among	O
availablebaselines.	O

We	O
implement	O
a	O
differentiable	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(NAS)	O
method	O
inspired	O
by	O
FBNet	O
for	O
discovering	O
neural	O
networks	O
that	O
are	O
heavily	O
optimized	O
for	O
a	O
particular	O
target	O
device.	O
The	O
FBNet	O
NAS	O
method	O
discovers	O
a	O
neural	O
network	O
from	O
a	O
given	O
search	O
space	O
by	O
optimizing	O
over	O
a	O
loss	O
function	O
which	O
accounts	O
for	O
accuracy	O
and	O
target	O
device	O
latency.	O
We	O
extend	O
this	O
loss	O
function	O
by	O
adding	O
an	O
energy	O
term.	O
This	O
will	O
potentially	O
enhance	O
the	O
``hardware	O
awareness"	O
and	O
help	O
us	O
find	O
a	O
neural	O
network	O
architecture	O
that	O
is	O
optimal	O
in	O
terms	O
of	O
accuracy,	O
latency	O
and	O
energy	O
consumption,	O
given	O
a	O
target	O
device	O
(Raspberry	O
Pi	O
in	O
our	O
case).	O
We	O
name	O
our	O
trained	O
child	O
architecture	O
obtained	O
at	O
the	O
end	O
of	O
search	O
process	O
as	O
Hardware	O
Aware	O
Neural	O
Network	O
Architecture	O
(HANNA).	O
We	O
prove	O
the	O
efficacy	O
of	O
our	O
approach	O
by	O
benchmarking	O
HANNA	O
against	O
two	O
other	O
state-of-the-art	O
neural	O
networks	O
designed	O
for	O
mobile/embedded	O
applications,	O
namely	O
MobileNetv2	O
and	O
CondenseNet	O
for	O
CIFAR-10	O
dataset.	O
Our	O
results	O
show	O
that	O
HANNA	O
provides	O
a	O
speedup	O
of	O
about	O
2.5x	O
and	O
1.7x,	O
and	O
reduces	O
energy	O
consumption	O
by	O
3.8x	O
and	O
2x	O
compared	O
to	O
MobileNetv2	O
and	O
CondenseNet	O
respectively.	O
HANNA	O
is	O
able	O
to	O
provide	O
such	O
significant	O
speedup	O
and	O
energy	O
efficiency	O
benefits	O
over	O
the	O
state-of-the-art	O
baselines	O
at	O
the	O
cost	O
of	O
a	O
tolerable	O
4-5%	O
drop	O
in	O
accuracy.	O

Recent	O
advances	O
in	O
language	O
representation	O
using	O
neural	O
networks	O
have	O
made	O
it	O
viable	O
to	O
transfer	O
the	O
learned	O
internal	O
states	O
of	O
a	O
trained	O
model	O
to	O
downstream	O
natural	O
language	O
processing	O
tasks,	O
such	O
as	O
named	O
entity	O
recognition	O
(NER	S-RESEARCH_PROBLEM
)	O
and	O
question	O
answering.	O
It	O
has	O
been	O
shown	O
that	O
the	O
leverage	O
of	O
pre-trained	O
language	O
models	O
improves	O
the	O
overall	O
performance	O
on	O
many	O
tasks	O
and	O
is	O
highly	O
beneficial	O
when	O
labeled	O
data	O
is	O
scarce.	O
In	O
this	O
work,	O
we	O
train	O
Portuguese	O
BERT	O
models	O
and	O
employ	O
a	O
BERT	O
-CRF	O
architecture	O
to	O
the	O
NER	S-RESEARCH_PROBLEM
task	O
on	O
the	O
Portuguese	O
language,	O
combining	O
the	O
transfer	O
capabilities	O
of	O
BERT	O
with	O
the	O
structured	O
predictions	O
of	O
CRF.	O
We	O
explore	O
feature-based	O
and	O
fine-tuning	O
training	O
strategies	O
for	O
the	O
BERT	O
model.	O
Our	O
fine-tuning	O
approach	O
obtains	O
new	O
state-of-the-art	O
results	O
on	O
the	O
HAREM	O
I	O
dataset,	O
improving	O
the	O
F1-score	O
by	O
1	O
point	O
on	O
the	O
selective	O
scenario	O
(5	O
NE	O
classes)	O
and	O
by	O
4	O
points	O
on	O
the	O
total	O
scenario	O
(10	O
NE	O
classes).	O

Fact	O
checking	O
is	O
an	O
important	O
task	O
for	O
maintaining	O
high	O
quality	O
posts	O
and	O
improving	O
user	O
experience	O
in	O
Community	B-RESEARCH_PROBLEM
Question	I-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
forums.	O
Therefore,	O
the	O
SemEval-2019	O
task	O
8	O
is	O
aimed	O
to	O
identify	O
factual	O
question	O
(subtask	O
A)	O
and	O
detect	O
true	O
factual	O
information	O
from	O
corresponding	O
answers	O
(subtask	O
B).	O
In	O
order	O
to	O
address	O
this	O
task,	O
we	O
propose	O
a	O
system	O
based	O
on	O
the	O
BERT	O
model	O
with	O
meta	O
information	O
of	O
questions.	O
For	O
the	O
subtask	O
A,	O
the	O
outputs	O
of	O
fine-tuned	O
BERT	O
classification	O
model	O
are	O
combined	O
with	O
the	O
feature	O
of	O
length	O
of	O
questions	O
to	O
boost	O
the	O
performance.	O
For	O
the	O
subtask	O
B,	O
the	O
predictions	O
of	O
several	O
variants	O
of	O
BERT	O
model	O
encoding	O
the	O
meta	O
information	O
are	O
combined	O
to	O
create	O
an	O
ensemble	O
model.	O
Our	O
system	O
achieved	O
competitive	O
results	O
with	O
an	O
accuracy	O
of	O
0.82	O
in	O
the	O
subtask	O
A	O
and	O
0.83	O
in	O
the	O
subtask	O
B.	O
The	O
experimental	O
results	O
validate	O
the	O
effectiveness	O
of	O
our	O
system.	O

In	O
Federated	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(FL),	O
client	O
devices	O
collaboratively	O
train	O
a	O
model	O
without	O
sharing	O
the	O
private	O
data	O
present	O
on	O
the	O
devices.	O
Federated	O
Stochastic	O
Gradient	O
Descent	O
(FedSGD	O
)	O
is	O
a	O
recent	O
generalisation	O
of	O
the	O
popular	O
Federated	O
Averaging	O
algorithm.	O
Recent	O
works	O
show	O
that	O
when	O
client	O
data	O
is	O
distributed	O
heterogeneously,	O
the	O
loss	O
function	O
minimised	O
by	O
FedSGD	O
differs	O
from	O
the	O
'true'	O
loss	O
that	O
would	O
be	O
minimised	O
by	O
centralised	O
training.	O
Previous	O
works	O
propose	O
decaying	O
the	O
client	O
learning	O
rate,	O
$\gamma$,	O
to	O
allow	O
FedSGD	O
to	O
minimise	O
the	O
true	O
loss.	O
We	O
propose	O
instead	O
decaying	O
the	O
number	O
of	O
local	O
SGD	O
steps,	O
$K$,	O
that	O
clients	O
perform	O
during	O
training	O
rounds	O
to	O
allow	O
minimisation	O
of	O
the	O
true	O
loss.	O
Decaying	O
$K$	O
has	O
the	O
added	O
benefit	O
of	O
reducing	O
the	O
total	O
computation	O
that	O
clients	O
perform	O
during	O
FedSGD	O
.	O
Real-world	O
applications	O
of	O
FL	O
use	O
large	O
numbers	O
of	O
low-powered	O
smartphone	O
or	O
Internet-of-Things	O
clients,	O
so	O
reduction	O
of	O
computation	O
would	O
provide	O
significant	O
savings	O
in	O
terms	O
of	O
energy	O
and	O
time.	O
In	O
this	O
work,	O
we	O
prove	O
for	O
quadratic	O
objectives	O
that	O
annealing	O
$K$	O
allows	O
FedSGD	O
to	O
approach	O
the	O
true	O
minimiser.	O
We	O
then	O
perform	O
thorough	O
experimentation	O
on	O
three	O
benchmark	O
FL	O
datasets	O
to	O
show	O
that	O
decaying	O
$K$	O
can	O
achieve	O
the	O
same	O
generalisation	O
performance	O
as	O
decaying	O
$\gamma$,	O
but	O
with	O
up	O
to	O
$3.8\times$	O
less	O
total	O
steps	O
of	O
SGD	O
performed	O
by	O
clients.	O

Syndromic	O
surveillance	O
detects	O
and	O
monitors	O
individual	O
and	O
population	O
healthindicators	O
through	O
sources	O
such	O
as	O
emergency	O
department	O
records.	O
Automatedclassification	O
of	O
these	O
records	O
can	O
improve	O
outbreak	O
detection	O
speed	O
anddiagnosis	O
accuracy.	O
Current	O
syndromic	O
systems	O
rely	O
on	O
hand-coded	O
keyword-basedmethods	O
to	O
parse	O
written	O
fields	O
and	O
may	O
benefit	O
from	O
the	O
use	O
of	O
modernsupervised-learning	O
classifier	O
models.	O
In	O
this	O
paper	O
we	O
implement	O
two	O
recurrentneural	O
network	O
models	O
based	O
on	O
long	O
short-term	O
memory	O
(LSTM)	O
and	O
gatedrecurrent	O
unit	O
(GRU	O
)	O
cells	O
and	O
compare	O
them	O
to	O
two	O
traditional	O
bag-of-wordsclassifiers:	O
multinomial	O
naive	O
Bayes	O
(MNB)	O
and	O
a	O
support	O
vector	O
machine	O
(SVM).The	O
MNB	O
classifier	O
is	O
one	O
of	O
only	O
two	O
machine	O
learning	O
algorithms	O
currentlybeing	O
used	O
for	O
syndromic	O
surveillance.	O
All	O
four	O
models	O
are	O
trained	O
to	O
predictdiagnostic	O
code	O
groups	O
as	O
defined	O
by	O
Clinical	O
Classification	S-RESEARCH_PROBLEM
Software,	O
first	O
topredict	O
from	O
discharge	O
diagnosis,	O
then	O
from	O
chief	O
complaint	O
fields.	O
Theclassifiers	O
are	O
trained	O
on	O
3.6	O
million	O
de-identified	O
emergency	O
departmentrecords	O
from	O
a	O
single	O
United	O
States	O
jurisdiction.	O
We	O
compare	O
performance	O
ofthese	O
models	O
primarily	O
using	O
the	O
F1	O
score.	O
Using	O
discharge	O
diagnoses,	O
the	O
LSTMclassifier	O
performs	O
best,	O
though	O
all	O
models	O
exhibit	O
an	O
F1	O
score	O
above	O
96.00.The	O
GRU	O
performs	O
best	O
on	O
chief	O
complaints	O
(F1=47.38),	O
and	O
MNB	O
with	O
bigramsperforms	O
worst	O
(F1=39.40).	O
Certain	O
syndrome	O
types	O
are	O
easier	O
to	O
detect	O
thanothers.	O
For	O
examples,	O
chief	O
complaints	O
using	O
the	O
GRU	O
model	O
predictsalcohol-related	O
disorders	O
well	O
(F1=78.91)	O
but	O
predicts	O
influenza	O
poorly(F1=14.80).	O
In	O
all	O
instances,	O
the	O
RNN	O
models	O
outperformed	O
the	O
bag-of-wordclassifiers,	O
suggesting	O
deep	O
learning	O
models	O
could	O
substantially	O
improve	O
theautomatic	O
classification	O
of	O
unstructured	O
text	O
for	O
syndromic	O
surveillance.	O

Recent	O
research	O
in	O
self-supervised	O
learning	O
(SSL)	O
has	O
shown	O
its	O
capability	O
in	O
learning	O
useful	O
semantic	O
representations	O
from	O
images	O
for	O
classification	O
tasks.	O
Through	O
our	O
work,	O
we	O
study	O
the	O
usefulness	O
of	O
SSL	O
for	O
Fine-Grained	B-RESEARCH_PROBLEM
Visual	I-RESEARCH_PROBLEM
Categorization	E-RESEARCH_PROBLEM
(FGVC).	O
FGVC	O
aims	O
to	O
distinguish	O
objects	O
of	O
visually	O
similar	O
sub	O
categories	O
within	O
a	O
general	O
category.	O
The	O
small	O
inter-class,	O
but	O
large	O
intra-class	O
variations	O
within	O
the	O
dataset	O
makes	O
it	O
a	O
challenging	O
task.	O
The	O
limited	O
availability	O
of	O
annotated	O
labels	O
for	O
such	O
a	O
fine-grained	O
data	O
encourages	O
the	O
need	O
for	O
SSL,	O
where	O
additional	O
supervision	O
can	O
boost	O
learning	O
without	O
the	O
cost	O
of	O
extra	O
annotations.	O
Our	O
baseline	O
achieves	O
$86.36\%$	O
top-1	O
classification	O
accuracy	O
on	O
CUB-200-2011	O
dataset	O
by	O
utilizing	O
random	O
crop	O
augmentation	O
during	O
training	O
and	O
center	O
crop	O
augmentation	O
during	O
testing.	O
In	O
this	O
work,	O
we	O
explore	O
the	O
usefulness	O
of	O
various	O
pretext	O
tasks,	O
specifically,	O
rotation,	O
pretext	O
invariant	O
representation	O
learning	O
(PIRL	O
),	O
and	O
deconstruction	O
and	O
construction	O
learning	O
(DCL)	O
for	O
FGVC.	O
Rotation	O
as	O
an	O
auxiliary	O
task	O
promotes	O
the	O
model	O
to	O
learn	O
global	O
features,	O
and	O
diverts	O
it	O
from	O
focusing	O
on	O
the	O
subtle	O
details.	O
PIRL	O
that	O
uses	O
jigsaw	O
patches	O
attempts	O
to	O
focus	O
on	O
discriminative	O
local	O
regions,	O
but	O
struggles	O
to	O
accurately	O
localize	O
them.	O
DCL	O
helps	O
in	O
learning	O
local	O
discriminating	O
features	O
and	O
outperforms	O
the	O
baseline	O
by	O
achieving	O
$87.41\%$	O
top-1	O
accuracy.	O
The	O
deconstruction	O
learning	O
forces	O
the	O
model	O
to	O
focus	O
on	O
local	O
object	O
parts,	O
while	O
reconstruction	O
learning	O
helps	O
in	O
learning	O
the	O
correlation	O
between	O
the	O
parts.	O
We	O
perform	O
extensive	O
experiments	O
to	O
reason	O
our	O
findings.	O
Our	O
code	O
is	O
available	O
at	O
https://github.com/mmaaz60/ssl_for_fgvc.	O

Sentiment	B-RESEARCH_PROBLEM
Analysis	E-RESEARCH_PROBLEM
for	O
Indian	O
Languages	O
(SAIL)-Code	O
Mixed	O
tools	O
contest	O
aimedat	O
identifying	O
the	O
sentence	O
level	O
sentiment	O
polarity	O
of	O
the	O
code-mixed	O
datasetof	O
Indian	O
languages	O
pairs	O
(Hi-En,	O
Ben-Hi-En).	O
Hi-En	O
dataset	O
is	O
henceforthreferred	O
to	O
as	O
HI-EN	O
and	O
Ben-Hi-En	O
dataset	O
as	O
BN-EN	O
respectively.	O
For	O
this,	O
wesubmitted	O
four	O
models	O
for	O
sentiment	O
analysis	O
of	O
code-mixed	O
HI-EN	O
and	O
BN-ENdatasets.	O
The	O
first	O
model	O
was	O
an	O
ensemble	O
voting	O
classifier	O
consisting	O
of	O
threeclassifiers	O
-	O
linear	O
SVM	O
,	O
logistic	O
regression	O
and	O
random	O
forests	O
while	O
thesecond	O
one	O
was	O
a	O
linear	O
SVM	O
.	O
Both	O
the	O
models	O
used	O
TF-IDF	O
feature	O
vectors	O
ofcharacter	O
n-grams	O
where	O
n	O
ranged	O
from	O
2	O
to	O
6.	O
We	O
used	O
scikit-learn	O
(sklearn)machine	O
learning	O
library	O
for	O
implementing	O
both	O
the	O
approaches.	O
Run1	O
wasobtained	O
from	O
the	O
voting	O
classifier	O
and	O
Run2	O
used	O
the	O
linear	O
SVM	O
model	O
forproducing	O
the	O
results.	O
Out	O
of	O
the	O
four	O
submitted	O
outputs	O
Run2	O
outperformed	O
Run1in	O
both	O
the	O
datasets.	O
We	O
finished	O
first	O
in	O
the	O
contest	O
for	O
both	O
HI-EN	O
with	O
anF-score	O
of	O
0.569	O
and	O
BN-EN	O
with	O
an	O
F-score	O
of	O
0.526.	O

In	O
this	O
paper,	O
we	O
present	O
our	O
approaches	O
and	O
results	O
for	O
SemEval-2020	O
Task	O
12,	O
Multilingual	O
Offensive	O
Language	B-RESEARCH_PROBLEM
Identification	E-RESEARCH_PROBLEM
in	O
Social	O
Media	O
(OffensEval	O
2020).	O
The	O
OffensEval	O
2020	O
had	O
three	O
subtasks:	O
A)	O
Identifying	O
the	O
tweets	O
to	O
be	O
offensive	O
(OFF)	O
or	O
non-offensive	O
(NOT)	O
for	O
Arabic,	O
Danish,	O
English,	O
Greek,	O
and	O
Turkish	O
languages,	O
B)	O
Detecting	O
if	O
the	O
offensive	O
tweet	O
is	O
targeted	O
(TIN)	O
or	O
untargeted	O
(UNT)	O
for	O
the	O
English	O
language,	O
and	O
C)	O
Categorizing	O
the	O
offensive	O
targeted	O
tweets	O
into	O
three	O
classes,	O
namely:	O
individual	O
(IND),	O
Group	O
(GRP),	O
or	O
Other	O
(OTH)	O
for	O
the	O
English	O
language.	O
We	O
participate	O
in	O
all	O
the	O
subtasks	O
A,	O
B,	O
and	O
C.	O
In	O
our	O
solution,	O
first	O
we	O
use	O
the	O
pre-trained	O
BERT	O
model	O
for	O
all	O
subtasks,	O
A,	O
B,	O
and	O
C	O
and	O
then	O
we	O
apply	O
the	O
BiLSTM	O
model	O
with	O
attention	O
mechanism	O
(Attn-BiLSTM	O
)	O
for	O
the	O
same.	O
Our	O
result	O
demonstrates	O
that	O
the	O
pre-trained	O
model	O
is	O
not	O
giving	O
good	O
results	O
for	O
all	O
types	O
of	O
languages	O
and	O
is	O
compute	O
and	O
memory	O
intensive	O
whereas	O
the	O
Attn-BiLSTM	O
model	O
is	O
fast	O
and	O
gives	O
good	O
accuracy	O
with	O
fewer	O
resources.	O
The	O
Attn-BiLSTM	O
model	O
is	O
giving	O
better	O
accuracy	O
for	O
Arabic	O
and	O
Greek	O
where	O
the	O
pre-trained	O
model	O
is	O
not	O
able	O
to	O
capture	O
the	O
complete	O
context	O
of	O
these	O
languages	O
due	O
to	O
lower	O
vocab-size.	O

Question-answering	O
plays	O
an	O
important	O
role	O
in	O
e-commerce	O
as	O
it	O
allows	O
potential	O
customers	O
to	O
actively	O
seek	O
crucial	O
information	O
about	O
products	O
or	O
services	O
to	O
help	O
their	O
purchase	O
decision	O
making.	O
Inspired	O
by	O
the	O
recent	O
success	O
of	O
machine	O
reading	O
comprehension	O
(MRC)	O
on	O
formal	O
documents,	O
this	O
paper	O
explores	O
the	O
potential	O
of	O
turning	O
customer	O
reviews	O
into	O
a	O
large	O
source	O
of	O
knowledge	O
that	O
can	O
be	O
exploited	O
to	O
answer	O
user	O
questions.~We	O
call	O
this	O
problem	O
Review	O
Reading	B-RESEARCH_PROBLEM
Comprehension	E-RESEARCH_PROBLEM
(RRC).	O
To	O
the	O
best	O
of	O
our	O
knowledge,	O
no	O
existing	O
work	O
has	O
been	O
done	O
on	O
RRC.	O
In	O
this	O
work,	O
we	O
first	O
build	O
an	O
RRC	O
dataset	O
called	O
ReviewRC	O
based	O
on	O
a	O
popular	O
benchmark	O
for	O
aspect-based	O
sentiment	O
analysis.	O
Since	O
ReviewRC	O
has	O
limited	O
training	O
examples	O
for	O
RRC	O
(and	O
also	O
for	O
aspect-based	O
sentiment	O
analysis),	O
we	O
then	O
explore	O
a	O
novel	O
post-training	O
approach	O
on	O
the	O
popular	O
language	O
model	O
BERT	O
to	O
enhance	O
the	O
performance	O
of	O
fine-tuning	O
of	O
BERT	O
for	O
RRC.	O
To	O
show	O
the	O
generality	O
of	O
the	O
approach,	O
the	O
proposed	O
post-training	O
is	O
also	O
applied	O
to	O
some	O
other	O
review-based	O
tasks	O
such	O
as	O
aspect	O
extraction	O
and	O
aspect	O
sentiment	O
classification	O
in	O
aspect-based	O
sentiment	O
analysis.	O
Experimental	O
results	O
demonstrate	O
that	O
the	O
proposed	O
post-training	O
is	O
highly	O
effective.	O
The	O
datasets	O
and	O
code	O
are	O
available	O
at	O
https://www.cs.uic.edu/~hxu/.	O

In	O
this	O
paper,	O
we	O
consider	O
the	O
problem	O
of	O
Robust	O
Matrix	B-RESEARCH_PROBLEM
Completion	E-RESEARCH_PROBLEM
(RMC)	O
where	O
the	O
goal	O
is	O
to	O
recover	O
a	O
low-rank	O
matrix	O
by	O
observing	O
a	O
small	O
number	O
of	O
its	O
entries	O
out	O
of	O
which	O
a	O
few	O
can	O
be	O
arbitrarily	O
corrupted.	O
We	O
propose	O
a	O
simple	O
projected	O
gradient	O
descent-based	O
method	O
to	O
estimate	O
the	O
low-rank	O
matrix	O
that	O
alternately	O
performs	O
a	O
projected	O
gradient	O
descent	O
step	O
and	O
cleans	O
up	O
a	O
few	O
of	O
the	O
corrupted	O
entries	O
using	O
hard-thresholding.	O
Our	O
algorithm	O
solves	O
RMC	O
using	O
nearly	O
optimal	O
number	O
of	O
observations	O
while	O
tolerating	O
a	O
nearly	O
optimal	O
number	O
of	O
corruptions.	O
Our	O
result	O
also	O
implies	O
significant	O
improvement	O
over	O
the	O
existing	O
time	O
complexity	O
bounds	O
for	O
the	O
low-rank	O
matrix	O
completion	O
problem.	O
Finally,	O
an	O
application	O
of	O
our	O
result	O
to	O
the	O
robust	O
PCA	O
problem	O
(low-rank+sparse	O
matrix	O
separation)	O
leads	O
to	O
nearly	O
linear	O
time	O
(in	O
matrix	O
dimensions)	O
algorithm	O
for	O
the	O
same;	O
existing	O
state-of-the-art	O
methods	O
require	O
quadratic	O
time.	O
Our	O
empirical	O
results	O
corroborate	O
our	O
theoretical	O
results	O
and	O
show	O
that	O
even	O
for	O
moderate	O
sized	O
problems,	O
our	O
method	O
for	O
robust	O
PCA	O
is	O
an	O
order	O
of	O
magnitude	O
faster	O
than	O
the	O
existing	O
methods.	O

This	O
paper	O
provides	O
a	O
report	O
on	O
our	O
solution	O
including	O
model	O
selection,	O
tuning	O
strategy	O
and	O
results	O
obtained	O
for	O
Global	O
Road	B-RESEARCH_PROBLEM
Damage	I-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
Challenge.	O
This	O
Big	O
Data	O
Cup	O
Challenge	O
was	O
held	O
as	O
a	O
part	O
of	O
IEEE	O
International	O
Conference	O
on	O
Big	O
Data	O
2020.	O
We	O
assess	O
single	O
and	O
multi-stage	O
network	O
architectures	O
for	O
object	O
detection	O
and	O
provide	O
a	O
benchmark	O
using	O
popular	O
state-of-the-art	O
open-source	O
PyTorch	O
frameworks	O
like	O
Detectron2	O
and	O
Yolov5.	O
Data	O
preparation	O
for	O
provided	O
Road	O
Damage	O
training	O
dataset,	O
captured	O
using	O
smartphone	O
camera	O
from	O
Czech,	O
India	O
and	O
Japan	O
is	O
discussed.	O
We	O
studied	O
the	O
effect	O
of	O
training	O
on	O
a	O
per	O
country	O
basis	O
with	O
respect	O
to	O
a	O
single	O
generalizable	O
model.	O
We	O
briefly	O
describe	O
the	O
tuning	O
strategy	O
for	O
the	O
experiments	O
conducted	O
on	O
two-stage	O
Faster	O
R-CNN	O
with	O
Deep	O
Residual	O
Network	O
(Resnet)	O
and	O
Feature	O
Pyramid	O
Network	O
(FPN)	O
backbone.	O
Additionally,	O
we	O
compare	O
this	O
to	O
a	O
one-stage	O
Yolov5	O
model	O
with	O
Cross	O
Stage	O
Partial	O
Network	O
(CSPNet)	O
backbone.	O
We	O
show	O
a	O
mean	O
F1	O
score	O
of	O
0.542	O
on	O
Test2	O
and	O
0.536	O
on	O
Test1	O
datasets	O
using	O
a	O
multi-stage	O
Faster	O
R-CNN	O
model,	O
with	O
Resnet-50	O
and	O
Resnet-101	O
backbones	O
respectively.	O
This	O
shows	O
the	O
generalizability	O
of	O
the	O
Resnet-50	O
model	O
when	O
compared	O
to	O
its	O
more	O
complex	O
counterparts.	O
Experiments	O
were	O
conducted	O
using	O
Google	O
Colab	O
having	O
K80	O
and	O
a	O
Linux	O
PC	O
with	O
1080Ti,	O
NVIDIA	O
consumer	O
grade	O
GPU.	O
A	O
PyTorch	O
based	O
Detectron2	O
code	O
to	O
preprocess,	O
train,	O
test	O
and	O
submit	O
the	O
Avg	O
F1	O
score	O
to	O
is	O
made	O
available	O
at	O
https://github.com/vishwakarmarhl/rdd2020	O

The	O
CNN-based	O
methods	O
have	O
achieved	O
impressive	O
results	O
in	O
medical	O
image	O
segmentation,	O
but	O
it	O
failed	O
to	O
capture	O
the	O
long-range	O
dependencies	O
due	O
to	O
the	O
inherent	O
locality	O
of	O
convolution	O
operation.	O
Transformer	O
-based	O
methods	O
are	O
popular	O
in	O
vision	O
tasks	O
recently	O
because	O
of	O
its	O
capacity	O
of	O
long-range	O
dependencies	O
and	O
get	O
a	O
promising	O
performance.	O
However,	O
it	O
lacks	O
in	O
modeling	O
local	O
context,	O
although	O
some	O
works	O
attempted	O
to	O
embed	O
convolutional	O
layer	O
to	O
overcome	O
this	O
problem	O
and	O
achieved	O
some	O
improvement,	O
but	O
it	O
makes	O
the	O
feature	O
inconsistent	O
and	O
fails	O
to	O
leverage	O
the	O
natural	O
multi-scale	O
features	O
of	O
hierarchical	O
transformer,	O
which	O
limit	O
the	O
performance	O
of	O
models.	O
In	O
this	O
paper,	O
taking	O
medical	O
image	O
segmentation	O
as	O
an	O
example,	O
we	O
present	O
MISSFormer,	O
an	O
effective	O
and	O
powerful	O
Medical	B-RESEARCH_PROBLEM
Image	I-RESEARCH_PROBLEM
Segmentation	E-RESEARCH_PROBLEM
tranSFormer.	O
MISSFormer	O
is	O
a	O
hierarchical	O
encoder-decoder	O
network	O
and	O
has	O
two	O
appealing	O
designs:	O
1)	O
A	O
feed	O
forward	O
network	O
is	O
redesigned	O
with	O
the	O
proposed	O
Enhanced	O
Transformer	O
Block,	O
which	O
makes	O
features	O
aligned	O
adaptively	O
and	O
enhances	O
the	O
long-range	O
dependencies	O
and	O
local	O
context.	O
2)	O
We	O
proposed	O
Enhanced	O
Transformer	O
Context	O
Bridge,	O
a	O
context	O
bridge	O
with	O
the	O
enhanced	O
transformer	O
block	O
to	O
model	O
the	O
long-range	O
dependencies	O
and	O
local	O
context	O
of	O
multi-scale	O
features	O
generated	O
by	O
our	O
hierarchical	O
transformer	O
encoder.	O
Driven	O
by	O
these	O
two	O
designs,	O
the	O
MISSFormer	O
shows	O
strong	O
capacity	O
to	O
capture	O
more	O
valuable	O
dependencies	O
and	O
context	O
in	O
medical	O
image	O
segmentation.	O
The	O
experiments	O
on	O
multi-organ	O
and	O
cardiac	O
segmentation	O
tasks	O
demonstrate	O
the	O
superiority,	O
effectiveness	O
and	O
robustness	O
of	O
our	O
MISSFormer,	O
the	O
exprimental	O
results	O
of	O
MISSFormer	O
trained	O
from	O
scratch	O
even	O
outperforms	O
state-of-the-art	O
methods	O
pretrained	O
on	O
ImageNet,	O
and	O
the	O
core	O
designs	O
can	O
be	O
generalized	O
to	O
other	O
visual	O
segmentation	O
tasks.	O
The	O
code	O
will	O
be	O
released	O
in	O
Github.	O

Moving	O
object	O
detection	O
has	O
been	O
a	O
central	O
topic	O
of	O
discussion	O
in	O
computer	O
vision	O
for	O
its	O
wide	O
range	O
of	O
applications	O
like	O
in	O
self-driving	O
cars,	O
video	O
surveillance,	O
security,	O
and	O
enforcement.	O
Neuromorphic	O
Vision	O
Sensors	O
(NVS)	O
are	O
bio-inspired	O
sensors	O
that	O
mimic	O
the	O
working	O
of	O
the	O
human	O
eye.	O
Unlike	O
conventional	O
frame-based	O
cameras,	O
these	O
sensors	O
capture	O
a	O
stream	O
of	O
asynchronous	O
'events'	O
that	O
pose	O
multiple	O
advantages	O
over	O
the	O
former,	O
like	O
high	O
dynamic	O
range,	O
low	O
latency,	O
low	O
power	O
consumption,	O
and	O
reduced	O
motion	O
blur.	O
However,	O
these	O
advantages	O
come	O
at	O
a	O
high	O
cost,	O
as	O
the	O
event	O
camera	O
data	O
typically	O
contains	O
more	O
noise	O
and	O
has	O
low	O
resolution.	O
Moreover,	O
as	O
event-based	O
cameras	O
can	O
only	O
capture	O
the	O
relative	O
changes	O
in	O
brightness	O
of	O
a	O
scene,	O
event	O
data	O
do	O
not	O
contain	O
usual	O
visual	O
information	O
(like	O
texture	O
and	O
color)	O
as	O
available	O
in	O
video	O
data	O
from	O
normal	O
cameras.	O
So,	O
moving	O
object	O
detection	O
in	O
event-based	O
cameras	O
becomes	O
an	O
extremely	O
challenging	O
task.	O
In	O
this	O
paper,	O
we	O
present	O
an	O
unsupervised	O
Graph	O
Spectral	O
Clustering	O
technique	O
for	O
Moving	B-RESEARCH_PROBLEM
Object	I-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
in	O
Event-based	O
data	O
(GSCEventMOD).	O
We	O
additionally	O
show	O
how	O
the	O
optimum	O
number	O
of	O
moving	O
objects	O
can	O
be	O
automatically	O
determined.	O
Experimental	O
comparisons	O
on	O
publicly	O
available	O
datasets	O
show	O
that	O
the	O
proposed	O
GSCEventMOD	O
algorithm	O
outperforms	O
a	O
number	O
of	O
state-of-the-art	O
techniques	O
by	O
a	O
maximum	O
margin	O
of	O
30%.	O

Currently,	O
deep	O
learning	O
approaches	O
are	O
superior	O
in	O
natural	O
language	O
processing	O
due	O
to	O
their	O
ability	O
to	O
extract	O
informative	O
features	O
and	O
patterns	O
from	O
languages.	O
Two	O
most	O
successful	O
neural	O
architectures	O
are	O
LSTM	O
and	O
transformers,	O
the	O
latter	O
mostly	O
used	O
in	O
the	O
form	O
of	O
large	O
pretrained	O
language	O
models	O
such	O
as	O
BERT	O
.	O
While	O
cross-lingual	O
approaches	O
are	O
on	O
the	O
rise,	O
a	O
vast	O
majority	O
of	O
current	O
natural	O
language	O
processing	O
techniques	O
is	O
designed	O
and	O
applied	O
to	O
English,	O
and	O
less-resourced	O
languages	O
are	O
lagging	O
behind.	O
In	O
morphologically	O
rich	O
languages,	O
plenty	O
of	O
information	O
is	O
conveyed	O
through	O
changes	O
in	O
morphology,	O
e.g.,	O
through	O
different	O
prefixes	O
and	O
suffixes	O
modifying	O
stems	O
of	O
words.	O
The	O
existing	O
neural	O
approaches	O
do	O
not	O
explicitly	O
use	O
the	O
information	O
on	O
word	O
morphology.	O
We	O
analyze	O
the	O
effect	O
of	O
adding	O
morphological	O
features	O
to	O
LSTM	O
and	O
BERT	O
models.	O
We	O
use	O
three	O
tasks	O
available	O
in	O
many	O
less-resourced	O
languages:	O
named	O
entity	O
recognition	O
(NER	S-RESEARCH_PROBLEM
),	O
dependency	O
parsing	O
(DP),	O
and	O
comment	O
filtering	O
(CF).	O
We	O
construct	O
sensible	O
baselines	O
involving	O
LSTM	O
and	O
BERT	O
models,	O
which	O
we	O
adjust	O
by	O
adding	O
additional	O
input	O
in	O
the	O
form	O
of	O
part	O
of	O
speech	O
(POS)	O
tags	O
and	O
universal	O
features.	O
We	O
compare	O
the	O
obtained	O
models	O
across	O
subsets	O
of	O
eight	O
languages.	O
Our	O
results	O
suggest	O
that	O
adding	O
morphological	O
features	O
has	O
mixed	O
effects	O
depending	O
on	O
the	O
quality	O
of	O
features	O
and	O
the	O
task.	O
The	O
features	O
improve	O
the	O
performance	O
of	O
LSTM	O
-based	O
models	O
on	O
the	O
NER	S-RESEARCH_PROBLEM
and	O
DP	O
tasks,	O
while	O
they	O
do	O
not	O
benefit	O
the	O
performance	O
on	O
the	O
CF	O
task.	O
For	O
BERT	O
-based	O
models,	O
the	O
added	O
morphological	O
features	O
only	O
improve	O
the	O
performance	O
on	O
DP	O
when	O
they	O
are	O
of	O
high	O
quality,	O
while	O
they	O
do	O
not	O
show	O
any	O
practical	O
improvement	O
when	O
they	O
are	O
predicted.	O
As	O
in	O
NER	S-RESEARCH_PROBLEM
and	O
CF	O
datasets	O
manually	O
checked	O
features	O
are	O
not	O
available,	O
we	O
only	O
experiment	O
with	O
the	O
predicted	O
morphological	O
features	O
and	O
find	O
that	O
they	O
do	O
not	O
cause	O
any	O
practical	O
improvement	O
in	O
performance.	O

Standard	O
informativeness	O
measures	O
used	O
to	O
evaluate	O
Automatic	O
Text	B-RESEARCH_PROBLEM
Summarization	E-RESEARCH_PROBLEM
mostly	O
rely	O
on	O
n-gram	O
overlapping	O
between	O
the	O
automatic	O
summary	O
and	O
the	O
reference	O
summaries.	O
These	O
measures	O
differ	O
from	O
the	O
metric	O
they	O
use	O
(cosine,	O
ROUGE,	O
Kullback-Leibler,	O
Logarithm	O
Similarity,	O
etc.)	O
and	O
the	O
bag	O
of	O
terms	O
they	O
consider	O
(single	O
words,	O
word	O
n-grams,	O
entities,	O
nuggets,	O
etc.).	O
Recent	O
word	O
embedding	O
approaches	O
offer	O
a	O
continuous	O
alternative	O
to	O
discrete	O
approaches	O
based	O
on	O
the	O
presence/absence	O
of	O
a	O
text	O
unit.	O
Informativeness	O
measures	O
have	O
been	O
extended	O
to	O
Focus	O
Information	B-RESEARCH_PROBLEM
Retrieval	E-RESEARCH_PROBLEM
evaluation	O
involving	O
a	O
user's	O
information	O
need	O
represented	O
by	O
short	O
queries.	O
In	O
particular	O
for	O
the	O
task	O
of	O
CLEF-INEX	O
Tweet	O
Contextualization,	O
tweet	O
contents	O
have	O
been	O
considered	O
as	O
queries.	O
In	O
this	O
paper	O
we	O
define	O
the	O
concept	O
of	O
Interestingness	O
as	O
a	O
generalization	O
of	O
Informativeness,	O
whereby	O
the	O
information	O
need	O
is	O
diverse	O
and	O
formalized	O
as	O
an	O
unknown	O
set	O
of	O
implicit	O
queries.	O
We	O
then	O
study	O
the	O
ability	O
of	O
state	O
of	O
the	O
art	O
Informativeness	O
measures	O
to	O
cope	O
with	O
this	O
generalization.	O
Lately	O
we	O
show	O
that	O
with	O
this	O
new	O
framework,	O
standard	O
word	O
embeddings	O
outperforms	O
discrete	O
measures	O
only	O
on	O
uni-grams,	O
however	O
bi-grams	O
seems	O
to	O
be	O
a	O
key	O
point	O
of	O
interestingness	O
evaluation.	O
Lastly	O
we	O
prove	O
that	O
the	O
CLEF-INEX	O
Tweet	O
Contextualization	O
2012	O
Logarithm	O
Similarity	O
measure	O
provides	O
best	O
results.	O

Collaborative	O
personalization,	O
such	O
as	O
through	O
learned	O
user	O
representations	O
(embeddings),	O
can	O
improve	O
the	O
prediction	O
accuracy	O
of	O
neural-network-based	O
models	O
significantly.	O
We	O
propose	O
Federated	O
User	O
Representation	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(FURL),	O
a	O
simple,	O
scalable,	O
privacy-preserving	O
and	O
resource-efficient	O
way	O
to	O
utilize	O
existing	O
neural	O
personalization	O
techniques	O
in	O
the	O
Federated	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(FL)	O
setting.	O
FURL	O
divides	O
model	O
parameters	O
into	O
federated	O
and	O
private	O
parameters.	O
Private	O
parameters,	O
such	O
as	O
private	O
user	O
embeddings,	O
are	O
trained	O
locally,	O
but	O
unlike	O
federated	O
parameters,	O
they	O
are	O
not	O
transferred	O
to	O
or	O
averaged	O
on	O
the	O
server.	O
We	O
show	O
theoretically	O
that	O
this	O
parameter	O
split	O
does	O
not	O
affect	O
training	O
for	O
most	O
model	O
personalization	O
approaches.	O
Storing	O
user	O
embeddings	O
locally	O
not	O
only	O
preserves	O
user	O
privacy,	O
but	O
also	O
improves	O
memory	O
locality	O
of	O
personalization	O
compared	O
to	O
on-server	O
training.	O
We	O
evaluate	O
FURL	O
on	O
two	O
datasets,	O
demonstrating	O
a	O
significant	O
improvement	O
in	O
model	O
quality	O
with	O
8%	O
and	O
51%	O
performance	O
increases,	O
and	O
approximately	O
the	O
same	O
level	O
of	O
performance	O
as	O
centralized	O
training	O
with	O
only	O
0%	O
and	O
4%	O
reductions.	O
Furthermore,	O
we	O
show	O
that	O
user	O
embeddings	O
learned	O
in	O
FL	O
and	O
the	O
centralized	O
setting	O
have	O
a	O
very	O
similar	O
structure,	O
indicating	O
that	O
FURL	O
can	O
learn	O
collaboratively	O
through	O
the	O
shared	O
parameters	O
while	O
preserving	O
user	O
privacy.	O

Keyword	B-RESEARCH_PROBLEM
Spotting	E-RESEARCH_PROBLEM
(KWS)	O
is	O
a	O
significant	O
branch	O
of	O
Automatic	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(ASR)	O
and	O
has	O
been	O
widely	O
used	O
in	O
edge	O
computing	O
devices.	O
The	O
goal	O
of	O
KWS	O
is	O
to	O
provide	O
high	O
accuracy	O
with	O
a	O
low	O
False	O
Alarm	O
Rate	O
(FAR),	O
while	O
reducing	O
the	O
costs	O
of	O
memory,	O
computation,	O
and	O
latency.	O
However,	O
limited	O
resources	O
are	O
challenging	O
for	O
KWS	O
applications	O
on	O
edge	O
computing	O
devices.	O
Lightweight	O
models	O
and	O
structures	O
for	O
deep	O
learning	O
have	O
achieved	O
good	O
results	O
in	O
the	O
KWS	O
branch	O
while	O
maintaining	O
efficient	O
performances.	O
In	O
this	O
paper,	O
we	O
present	O
a	O
new	O
Convolutional	O
Recurrent	O
Neural	O
Network	O
(CRNN)	O
architecture	O
named	O
EdgeCRNN	O
for	O
edge	O
computing	O
devices.	O
EdgeCRNN,	O
which	O
is	O
based	O
on	O
depthwise	O
separable	O
convolution	O
and	O
residual	O
structure,	O
uses	O
a	O
feature	O
enhanced	O
method.	O
On	O
the	O
Google	O
Speech	O
Commands	O
Dataset,	O
the	O
experimental	O
results	O
depict	O
that	O
EdgeCRNN	O
can	O
test	O
11.1	O
audio	O
data	O
per	O
second	O
on	O
Raspberry	O
Pi	O
3B+,	O
which	O
is	O
2.2	O
times	O
than	O
that	O
of	O
Tpool2.	O
Compared	O
with	O
Tpool2,	O
the	O
accuracy	O
of	O
EdgeCRNN	O
reaches	O
98.05%	O
whilst	O
its	O
performance	O
is	O
also	O
competitive.	O

Image	O
compression	O
is	O
a	O
widely	O
used	O
technique	O
to	O
reduce	O
the	O
spatial	O
redundancy	O
in	O
images.	O
Recently,	O
learning	O
based	O
image	O
compression	O
has	O
achieved	O
significant	O
progress	O
by	O
using	O
the	O
powerful	O
representation	O
ability	O
from	O
neural	O
networks.	O
However,	O
the	O
current	O
state-of-the-art	O
learning	O
based	O
image	O
compression	O
methods	O
suffer	O
from	O
the	O
huge	O
computational	O
cost,	O
which	O
limits	O
their	O
capacity	O
for	O
practical	O
applications.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
unified	O
framework	O
called	O
Efficient	O
Deep	O
Image	B-RESEARCH_PROBLEM
Compression	E-RESEARCH_PROBLEM
(EDIC)	O
based	O
on	O
three	O
new	O
technologies,	O
including	O
a	O
channel	O
attention	O
module,	O
a	O
Gaussian	O
mixture	O
model	O
and	O
a	O
decoder-side	O
enhancement	O
module.	O
Specifically,	O
we	O
design	O
an	O
auto-encoder	O
style	O
network	O
for	O
learning	O
based	O
image	O
compression.	O
To	O
improve	O
the	O
coding	O
efficiency,	O
we	O
exploit	O
the	O
channel	O
relationship	O
between	O
latent	O
representations	O
by	O
using	O
the	O
channel	O
attention	O
module.	O
Besides,	O
the	O
Gaussian	O
mixture	O
model	O
is	O
introduced	O
for	O
the	O
entropy	O
model	O
and	O
improves	O
the	O
accuracy	O
for	O
bitrate	O
estimation.	O
Furthermore,	O
we	O
introduce	O
the	O
decoder-side	O
enhancement	O
module	O
to	O
further	O
improve	O
image	O
compression	O
performance.	O
Our	O
EDIC	O
method	O
can	O
also	O
be	O
readily	O
incorporated	O
with	O
the	O
Deep	O
Video	B-RESEARCH_PROBLEM
Compression	E-RESEARCH_PROBLEM
(DVC)	O
framework	O
to	O
further	O
improve	O
the	O
video	O
compression	O
performance.	O
Simultaneously,	O
our	O
EDIC	O
method	O
boosts	O
the	O
coding	O
performance	O
significantly	O
while	O
bringing	O
slightly	O
increased	O
computational	O
cost.	O
More	O
importantly,	O
experimental	O
results	O
demonstrate	O
that	O
the	O
proposed	O
approach	O
outperforms	O
the	O
current	O
state-of-the-art	O
image	O
compression	O
methods	O
and	O
is	O
up	O
to	O
more	O
than	O
150	O
times	O
faster	O
in	O
terms	O
of	O
decoding	O
speed	O
when	O
compared	O
with	O
Minnen's	O
method.	O
The	O
proposed	O
framework	O
also	O
successfully	O
improves	O
the	O
performance	O
of	O
the	O
recent	O
deep	O
video	O
compression	O
system	O
DVC.	O
Our	O
code	O
will	O
be	O
released	O
at	O
https://github.com/liujiaheng/compression.	O

We	O
present	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(NMT)	O
training	O
using	O
document-level	O
metrics	O
with	O
batch-level	O
documents.	O
Previous	O
sequence-objective	O
approaches	O
to	O
NMT	O
training	O
focus	O
exclusively	O
on	O
sentence-level	O
metrics	O
like	O
sentence	O
BLEU	O
which	O
do	O
not	O
correspond	O
to	O
the	O
desired	O
evaluation	O
metric,	O
typically	O
document	O
BLEU.	O
Meanwhile	O
research	O
into	O
document-level	O
NMT	O
training	O
focuses	O
on	O
data	O
or	O
model	O
architecture	O
rather	O
than	O
training	O
procedure.	O
We	O
find	O
that	O
each	O
of	O
these	O
lines	O
of	O
research	O
has	O
a	O
clear	O
space	O
in	O
it	O
for	O
the	O
other,	O
and	O
propose	O
merging	O
them	O
with	O
a	O
scheme	O
that	O
allows	O
a	O
document-level	O
evaluation	O
metric	O
to	O
be	O
used	O
in	O
the	O
NMT	O
training	O
objective.	O
We	O
first	O
sample	O
pseudo-documents	O
from	O
sentence	O
samples.	O
We	O
then	O
approximate	O
the	O
expected	O
document	O
BLEU	O
gradient	O
with	O
Monte	O
Carlo	O
sampling	O
for	O
use	O
as	O
a	O
cost	O
function	O
in	O
Minimum	O
Risk	O
Training	O
(MRT).	O
This	O
two-level	O
sampling	O
procedure	O
gives	O
NMT	O
performance	O
gains	O
over	O
sequence	O
MRT	O
and	O
maximum-likelihood	O
training.	O
We	O
demonstrate	O
that	O
training	O
is	O
more	O
robust	O
for	O
document-level	O
metrics	O
than	O
with	O
sequence	O
metrics.	O
We	O
further	O
demonstrate	O
improvements	O
on	O
NMT	O
with	O
TER	O
and	O
Grammatical	B-RESEARCH_PROBLEM
Error	I-RESEARCH_PROBLEM
Correction	E-RESEARCH_PROBLEM
(GEC)	O
using	O
GLEU,	O
both	O
metrics	O
used	O
at	O
the	O
document	O
level	O
for	O
evaluations.	O

Deep	O
and	O
large	O
pre-trained	O
language	O
models	O
are	O
the	O
state-of-the-art	O
for	O
various	O
natural	O
language	O
processing	O
tasks.	O
However,	O
the	O
huge	O
size	O
of	O
these	O
models	O
could	O
be	O
a	O
deterrent	O
to	O
use	O
them	O
in	O
practice.	O
Some	O
recent	O
and	O
concurrent	O
works	O
use	O
knowledge	O
distillation	O
to	O
compress	O
these	O
huge	O
models	O
into	O
shallow	O
ones.	O
In	O
this	O
work	O
we	O
study	O
knowledge	O
distillation	O
with	O
a	O
focus	O
on	O
multi-lingual	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER	S-RESEARCH_PROBLEM
).	O
In	O
particular,	O
we	O
study	O
several	O
distillation	O
strategies	O
and	O
propose	O
a	O
stage-wise	O
optimization	O
scheme	O
leveraging	O
teacher	O
internal	O
representations	O
that	O
is	O
agnostic	O
of	O
teacher	O
architecture	O
and	O
show	O
that	O
it	O
outperforms	O
strategies	O
employed	O
in	O
prior	O
works.	O
Additionally,	O
we	O
investigate	O
the	O
role	O
of	O
several	O
factors	O
like	O
the	O
amount	O
of	O
unlabeled	O
data,	O
annotation	O
resources,	O
model	O
architecture	O
and	O
inference	O
latency	O
to	O
name	O
a	O
few.	O
We	O
show	O
that	O
our	O
approach	O
leads	O
to	O
massive	O
compression	O
of	O
MBERT-like	O
teacher	O
models	O
by	O
upto	O
35x	O
in	O
terms	O
of	O
parameters	O
and	O
51x	O
in	O
terms	O
of	O
latency	O
for	O
batch	O
inference	O
while	O
retaining	O
95%	O
of	O
its	O
F1-score	O
for	O
NER	S-RESEARCH_PROBLEM
over	O
41	O
languages.	O

This	O
paper	O
presents	O
the	O
machine	O
learning	O
architecture	O
of	O
the	O
Snips	O
VoicePlatform,	O
a	O
software	O
solution	O
to	O
perform	O
Spoken	B-RESEARCH_PROBLEM
Language	I-RESEARCH_PROBLEM
Understanding	E-RESEARCH_PROBLEM
onmicroprocessors	O
typical	O
of	O
IoT	O
devices.	O
The	O
embedded	O
inference	O
is	O
fast	O
andaccurate	O
while	O
enforcing	O
privacy	O
by	O
design,	O
as	O
no	O
personal	O
user	O
data	O
is	O
evercollected.	O
Focusing	O
on	O
Automatic	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
and	O
Natural	O
LanguageUnderstanding,	O
we	O
detail	O
our	O
approach	O
to	O
training	O
high-performance	O
MachineLearning	O
models	O
that	O
are	O
small	O
enough	O
to	O
run	O
in	O
real-time	O
on	O
small	O
devices.Additionally,	O
we	O
describe	O
a	O
data	O
generation	O
procedure	O
that	O
provides	O
sufficient,high-quality	O
training	O
data	O
without	O
compromising	O
user	O
privacy.	O

Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
is	O
one	O
of	O
the	O
research	O
fields	O
of	O
ComputationalLinguistics.	O
The	O
objective	O
of	O
many	O
MT	O
Researchers	O
is	O
to	O
develop	O
an	O
MT	O
Systemthat	O
produce	O
good	O
quality	O
and	O
high	O
accuracy	O
output	O
translations	O
and	O
which	O
alsocovers	O
maximum	O
language	O
pairs.	O
As	O
internet	O
and	O
Globalization	O
is	O
increasing	O
dayby	O
day,	O
we	O
need	O
a	O
way	O
that	O
improves	O
the	O
quality	O
of	O
translation.	O
For	O
thisreason,	O
we	O
have	O
developed	O
a	O
Classifier	O
based	O
Text	B-RESEARCH_PROBLEM
Simplification	E-RESEARCH_PROBLEM
Model	O
forEnglish-Hindi	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
Systems.	O
We	O
have	O
used	O
support	O
vector	O
machinesand	O
Na\"ive	O
Bayes	O
Classifier	O
to	O
develop	O
this	O
model.	O
We	O
have	O
also	O
evaluated	O
theperformance	O
of	O
these	O
classifiers.	O

Motif	O
discovery	O
is	O
a	O
fundamental	O
step	O
in	O
data	O
mining	O
tasks	O
for	O
time-series	O
data	O
such	O
as	O
clustering,	O
classification	O
and	O
anomaly	O
detection.	O
Even	O
though	O
many	O
papers	O
have	O
addressed	O
the	O
problem	O
of	O
how	O
to	O
find	O
motifs	O
in	O
time-series	O
by	O
proposing	O
new	O
motif	O
discovery	O
algorithms,	O
not	O
much	O
work	O
has	O
been	O
done	O
on	O
the	O
exploration	O
of	O
the	O
motifs	O
extracted	O
by	O
these	O
algorithms.	O
In	O
this	O
paper,	O
we	O
argue	O
that	O
visually	O
exploring	O
time-series	O
motifs	O
computed	O
by	O
motif	O
discovery	O
algorithms	O
can	O
be	O
useful	O
to	O
understand	O
and	O
debug	O
results.	O
To	O
explore	O
the	O
output	O
of	O
motif	O
discovery	O
algorithms,	O
we	O
propose	O
the	O
use	O
of	O
an	O
adapted	O
Self-Organizing	O
Map,	O
the	O
DTW-SOM,	O
on	O
the	O
list	O
of	O
motif's	O
centers.	O
In	O
short,	O
DTW-SOM	O
is	O
a	O
vanilla	O
Self-Organizing	O
Map	O
with	O
three	O
main	O
differences,	O
namely	O
(1)	O
the	O
use	O
the	O
Dynamic	B-RESEARCH_PROBLEM
Time	I-RESEARCH_PROBLEM
Warping	E-RESEARCH_PROBLEM
distance	O
instead	O
of	O
the	O
Euclidean	O
distance,	O
(2)	O
the	O
adoption	O
of	O
two	O
new	O
network	O
initialization	O
routines	O
(a	O
random	O
sample	O
initialization	O
and	O
an	O
anchor	O
initialization)	O
and	O
(3)	O
the	O
adjustment	O
of	O
the	O
Adaptation	O
phase	O
of	O
the	O
training	O
to	O
work	O
with	O
variable-length	O
time-series	O
sequences.	O
We	O
test	O
DTW-SOM	O
in	O
a	O
synthetic	O
motif	O
dataset	O
and	O
two	O
real	O
time-series	O
datasets	O
from	O
the	O
UCR	O
Time	B-RESEARCH_PROBLEM
Series	I-RESEARCH_PROBLEM
Classification	E-RESEARCH_PROBLEM
Archive.	O
After	O
an	O
exploration	O
of	O
results,	O
we	O
conclude	O
that	O
DTW-SOM	O
is	O
capable	O
of	O
extracting	O
relevant	O
information	O
from	O
a	O
set	O
of	O
motifs	O
and	O
display	O
it	O
in	O
a	O
visualization	O
that	O
is	O
space-efficient.	O

QTRAN	O
is	O
a	O
multi-agent	O
reinforcement	O
learning	O
(MARL)	O
algorithm	O
capable	O
of	O
learning	O
the	O
largest	O
class	O
of	O
joint-action	O
value	O
functions	O
up	O
to	O
date.	O
However,	O
despite	O
its	O
strong	O
theoretical	O
guarantee,	O
it	O
has	O
shown	O
poor	O
empirical	O
performance	O
in	O
complex	O
environments,	O
such	O
as	O
Starcraft	S-RESEARCH_PROBLEM
Multi-Agent	O
Challenge	O
(SMAC	S-RESEARCH_PROBLEM
).	O
In	O
this	O
paper,	O
we	O
identify	O
the	O
performance	O
bottleneck	O
of	O
QTRAN	O
and	O
propose	O
a	O
substantially	O
improved	O
version,	O
coined	O
QTRAN++.	O
Our	O
gains	O
come	O
from	O
(i)	O
stabilizing	O
the	O
training	O
objective	O
of	O
QTRAN,	O
(ii)	O
removing	O
the	O
strict	O
role	O
separation	O
between	O
the	O
action-value	O
estimators	O
of	O
QTRAN,	O
and	O
(iii)	O
introducing	O
a	O
multi-head	O
mixing	O
network	O
for	O
value	O
transformation.	O
Through	O
extensive	O
evaluation,	O
we	O
confirm	O
that	O
our	O
diagnosis	O
is	O
correct,	O
and	O
QTRAN++	O
successfully	O
bridges	O
the	O
gap	O
between	O
empirical	O
performance	O
and	O
theoretical	O
guarantee.	O
In	O
particular,	O
QTRAN++	O
newly	O
achieves	O
state-of-the-art	O
performance	O
in	O
the	O
SMAC	S-RESEARCH_PROBLEM
environment.	O
The	O
code	O
will	O
be	O
released.	O

Methods	O
for	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
and	O
Disambiguation	O
(NER	S-RESEARCH_PROBLEM
D)	O
perform	O
NER	S-RESEARCH_PROBLEM
and	O
NED	O
in	O
two	O
separate	O
stages.	O
Therefore,	O
NED	O
may	O
be	O
penalized	O
with	O
respect	O
to	O
precision	O
by	O
NER	S-RESEARCH_PROBLEM
false	O
positives,	O
and	O
suffers	O
in	O
recall	O
from	O
NER	S-RESEARCH_PROBLEM
false	O
negatives.	O
Conversely,	O
NED	O
does	O
not	O
fully	O
exploit	O
information	O
computed	O
by	O
NER	S-RESEARCH_PROBLEM
such	O
as	O
types	O
of	O
mentions.	O
This	O
paper	O
presents	O
J-NER	S-RESEARCH_PROBLEM
D,	O
a	O
new	O
approach	O
to	O
perform	O
NER	S-RESEARCH_PROBLEM
and	O
NED	O
jointly,	O
by	O
means	O
of	O
a	O
probabilistic	O
graphical	O
model	O
that	O
captures	O
mention	O
spans,	O
mention	O
types,	O
and	O
the	O
mapping	O
of	O
mentions	O
to	O
entities	O
in	O
a	O
knowledge	O
base.	O
We	O
present	O
experiments	O
with	O
different	O
kinds	O
of	O
texts	O
from	O
the	O
CoNLL{'}03,	O
ACE{'}05,	O
and	O
ClueWeb{'}09-FACC1	O
corpora.	O
J-NER	S-RESEARCH_PROBLEM
D	O
consistently	O
outperforms	O
state-of-the-art	O
competitors	O
in	O
end-to-end	O
NER	S-RESEARCH_PROBLEM
D	O
precision,	O
recall,	O
and	O
F1.	O

Few-Shot	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(FSL)	O
algorithms	O
are	O
commonly	O
trained	O
through	O
Meta-Learning	S-RESEARCH_PROBLEM
(ML),	O
which	O
exposes	O
models	O
to	O
batches	O
of	O
tasks	O
sampled	O
from	O
a	O
meta-dataset	O
to	O
mimic	O
tasks	O
seen	O
during	O
evaluation.	O
However,	O
the	O
standard	O
training	O
procedures	O
overlook	O
the	O
real-world	O
dynamics	O
where	O
classes	O
commonly	O
occur	O
at	O
different	O
frequencies.	O
While	O
it	O
is	O
generally	O
understood	O
that	O
class	O
imbalance	O
harms	O
the	O
performance	O
of	O
supervised	O
methods,	O
limited	O
research	O
examines	O
the	O
impact	O
of	O
imbalance	O
on	O
the	O
FSL	O
evaluation	O
task.	O
Our	O
analysis	O
compares	O
10	O
state-of-the-art	O
meta-learning	O
and	O
FSL	O
methods	O
on	O
different	O
imbalance	O
distributions	O
and	O
rebalancing	O
techniques.	O
Our	O
results	O
reveal	O
that	O
1)	O
some	O
FSL	O
methods	O
display	O
a	O
natural	O
disposition	O
against	O
imbalance	O
while	O
most	O
other	O
approaches	O
produce	O
a	O
performance	O
drop	O
by	O
up	O
to	O
17\%	O
compared	O
to	O
the	O
balanced	O
task	O
without	O
the	O
appropriate	O
mitigation;	O
2)	O
contrary	O
to	O
popular	O
belief,	O
many	O
meta-learning	O
algorithms	O
will	O
not	O
automatically	O
learn	O
to	O
balance	O
from	O
exposure	O
to	O
imbalanced	O
training	O
tasks;	O
3)	O
classical	O
rebalancing	O
strategies,	O
such	O
as	O
random	O
oversampling,	O
can	O
still	O
be	O
very	O
effective,	O
leading	O
to	O
state-of-the-art	O
performances	O
and	O
should	O
not	O
be	O
overlooked;	O
4)	O
FSL	O
methods	O
are	O
more	O
robust	O
against	O
meta-dataset	O
imbalance	O
than	O
imbalance	O
at	O
the	O
task-level	O
with	O
a	O
similar	O
imbalance	O
ratio	O
($\rho<20$),	O
with	O
the	O
effect	O
holding	O
even	O
in	O
long-tail	O
datasets	O
under	O
a	O
larger	O
imbalance	O
($\rho=65$).	O

In	O
order	O
to	O
answer	O
semantically-complicated	O
questions	O
about	O
an	O
image,	O
a	O
Visual	B-RESEARCH_PROBLEM
Question	I-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
(VQA)	O
model	O
needs	O
to	O
fully	O
understand	O
the	O
visual	O
scene	O
in	O
the	O
image,	O
especially	O
the	O
interactive	O
dynamics	O
between	O
different	O
objects.	O
We	O
propose	O
a	O
Relation-aware	O
Graph	B-RESEARCH_PROBLEM
Attention	E-RESEARCH_PROBLEM
Network	O
(ReGAT),	O
which	O
encodes	O
each	O
image	O
into	O
a	O
graph	O
and	O
models	O
multi-type	O
inter-object	O
relations	O
via	O
a	O
graph	O
attention	O
mechanism,	O
to	O
learn	O
question-adaptive	O
relation	O
representations.	O
Two	O
types	O
of	O
visual	O
object	O
relations	O
are	O
explored:	O
(i)	O
Explicit	O
Relations	O
that	O
represent	O
geometric	O
positions	O
and	O
semantic	O
interactions	O
between	O
objects;	O
and	O
(ii)	O
Implicit	O
Relations	O
that	O
capture	O
the	O
hidden	O
dynamics	O
between	O
image	O
regions.	O
Experiments	O
demonstrate	O
that	O
ReGAT	O
outperforms	O
prior	O
state-of-the-art	O
approaches	O
on	O
both	O
VQA	O
2.0	O
and	O
VQA-CP	O
v2	O
datasets.	O
We	O
further	O
show	O
that	O
ReGAT	O
is	O
compatible	O
to	O
existing	O
VQA	O
architectures,	O
and	O
can	O
be	O
used	O
as	O
a	O
generic	O
relation	O
encoder	O
to	O
boost	O
the	O
model	O
performance	O
for	O
VQA.	O

Automatic	O
Language	B-RESEARCH_PROBLEM
Identification	E-RESEARCH_PROBLEM
(LI)	O
or	O
Dialect	B-RESEARCH_PROBLEM
Identification	E-RESEARCH_PROBLEM
(DI)	O
of	O
short	O
texts	O
of	O
closely	O
related	O
languages	O
or	O
dialects,	O
is	O
one	O
of	O
the	O
primary	O
steps	O
in	O
many	O
natural	O
language	O
processing	O
pipelines.	O
Language	O
identification	O
is	O
considered	O
a	O
solved	O
task	O
in	O
many	O
cases;	O
however,	O
in	O
the	O
case	O
of	O
very	O
closely	O
related	O
languages,	O
or	O
in	O
an	O
unsupervised	O
scenario	O
(where	O
the	O
languages	O
are	O
not	O
known	O
in	O
advance),	O
performance	O
is	O
still	O
poor.	O
In	O
this	O
paper,	O
we	O
propose	O
the	O
Unsupervised	O
Deep	O
Language	O
and	O
Dialect	B-RESEARCH_PROBLEM
Identification	E-RESEARCH_PROBLEM
(UDLDI)	O
method,	O
which	O
can	O
simultaneously	O
learn	O
sentence	O
embeddings	O
and	O
cluster	O
assignments	O
from	O
short	O
texts.	O
The	O
UDLDI	O
model	O
understands	O
the	O
sentence	O
constructions	O
of	O
languages	O
by	O
applying	O
attention	O
to	O
character	O
relations	O
which	O
helps	O
to	O
optimize	O
the	O
clustering	O
of	O
languages.	O
We	O
have	O
performed	O
our	O
experiments	O
on	O
three	O
short-text	O
datasets	O
for	O
different	O
language	O
families,	O
each	O
consisting	O
of	O
closely	O
related	O
languages	O
or	O
dialects,	O
with	O
very	O
minimal	O
training	O
sets.	O
Our	O
experimental	O
evaluations	O
on	O
these	O
datasets	O
have	O
shown	O
significant	O
improvement	O
over	O
state-of-the-art	O
unsupervised	O
methods	O
and	O
our	O
model	O
has	O
outperformed	O
state-of-the-art	O
LI	O
and	O
DI	O
systems	O
in	O
supervised	O
settings.	O

Keyword	B-RESEARCH_PROBLEM
Extraction	E-RESEARCH_PROBLEM
is	O
an	O
important	O
task	O
in	O
several	O
text	O
analysis	O
endeavors.In	O
this	O
paper,	O
we	O
present	O
a	O
critical	O
discussion	O
of	O
the	O
issues	O
and	O
challengesingraph-based	O
keyword	O
extraction	O
methods,	O
along	O
with	O
comprehensive	O
empiricalanalysis.	O
We	O
propose	O
a	O
parameterless	O
method	O
for	O
constructing	O
graph	O
of	O
text	O
thatcaptures	O
the	O
contextual	O
relation	O
between	O
words.	O
A	O
novel	O
word	O
scoring	O
method	O
isalso	O
proposed	O
based	O
on	O
the	O
connection	O
between	O
concepts.	O
We	O
demonstrate	O
thatboth	O
proposals	O
are	O
individually	O
superior	O
to	O
those	O
followed	O
by	O
thestate-of-the-art	O
graph-based	O
keyword	O
extraction	O
algorithms.	O
Combination	O
of	O
theproposed	O
graph	B-RESEARCH_PROBLEM
construction	E-RESEARCH_PROBLEM
and	O
scoring	O
methods	O
leads	O
to	O
a	O
novel,	O
parameterlesskeyword	O
extraction	O
method	O
(sCAKE)	O
based	O
on	O
semantic	O
connectivity	O
of	O
words	O
inthe	O
document.	O
Motivated	O
by	O
limited	O
availability	O
of	O
NLP	O
tools	O
for	O
several	O
languages,	O
we	O
alsodesign	O
and	O
present	O
a	O
language-agnostic	O
keyword	O
extraction	O
(LAKE)	O
method.	O
Weeliminate	O
the	O
need	O
of	O
NLP	O
tools	O
by	O
using	O
a	O
statistical	O
filter	O
to	O
identifycandidate	O
keywords	O
before	O
constructing	O
the	O
graph.	O
We	O
show	O
that	O
the	O
resultingmethod	O
is	O
a	O
competent	O
solution	O
for	O
extracting	O
keywords	O
from	O
documentsoflanguages	O
lacking	O
sophisticated	O
NLP	O
support.	O

Recent	O
years	O
have	O
witnessed	O
an	O
upsurge	O
of	O
research	O
interests	O
and	O
applications	O
of	O
machine	O
learning	O
on	O
graphs.	O
Automated	O
machine	O
learning	O
(AutoML	S-RESEARCH_PROBLEM
)	O
on	O
graphs	O
is	O
on	O
the	O
horizon	O
to	O
automatically	O
design	O
the	O
optimal	O
machine	O
learning	O
algorithm	O
for	O
a	O
given	O
graph	O
task.	O
However,	O
none	O
of	O
the	O
existing	O
libraries	O
can	O
fully	O
support	O
AutoML	S-RESEARCH_PROBLEM
on	O
graphs.	O
To	O
fill	O
this	O
gap,	O
we	O
present	O
Automated	O
Graph	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(AutoGL),	O
the	O
first	O
library	O
for	O
automated	O
machine	O
learning	O
on	O
graphs.	O
AutoGL	O
is	O
open-source,	O
easy	O
to	O
use,	O
and	O
flexible	O
to	O
be	O
extended.	O
Specifically,	O
we	O
propose	O
an	O
automated	O
machine	O
learning	O
pipeline	O
for	O
graph	O
data	O
containing	O
four	O
modules:	O
auto	O
feature	O
engineering,	O
model	O
training,	O
hyper-parameter	O
optimization,	O
and	O
auto	O
ensemble.	O
For	O
each	O
module,	O
we	O
provide	O
numerous	O
state-of-the-art	O
methods	O
and	O
flexible	O
base	O
classes	O
and	O
APIs,	O
which	O
allow	O
easy	O
customization.	O
We	O
further	O
provide	O
experimental	O
results	O
to	O
showcase	O
the	O
usage	O
of	O
our	O
AutoGL	O
library.	O

In	O
recent	O
literature,	O
contextual	O
pretrained	O
Language	O
Models	O
(LMs)	O
demonstrated	O
their	O
potential	O
in	O
generalizing	O
the	O
knowledge	O
to	O
several	O
Natural	O
Language	O
Processing	O
(NLP)	O
tasks	O
including	O
supervised	O
Word	B-RESEARCH_PROBLEM
Sense	I-RESEARCH_PROBLEM
Disambiguation	E-RESEARCH_PROBLEM
(WSD),	O
a	O
challenging	O
problem	O
in	O
the	O
field	O
of	O
Natural	B-RESEARCH_PROBLEM
Language	I-RESEARCH_PROBLEM
Understanding	E-RESEARCH_PROBLEM
(NLU).	O
However,	O
word	O
representations	O
from	O
these	O
models	O
are	O
still	O
very	O
dense,	O
costly	O
in	O
terms	O
of	O
memory	O
footprint,	O
as	O
well	O
as	O
minimally	O
interpretable.	O
In	O
order	O
to	O
address	O
such	O
issues,	O
we	O
propose	O
a	O
new	O
supervised	O
biologically	O
inspired	O
technique	O
for	O
transferring	O
large	O
pre-trained	O
language	O
model	O
representations	O
into	O
a	O
compressed	O
representation,	O
for	O
the	O
case	O
of	O
WSD.	O
Our	O
produced	O
representation	O
contributes	O
to	O
increase	O
the	O
general	O
interpretability	O
of	O
the	O
framework	O
and	O
to	O
decrease	O
memory	O
footprint,	O
while	O
enhancing	O
performance.	O

Deformable	O
Image	B-RESEARCH_PROBLEM
Registration	E-RESEARCH_PROBLEM
(DIR)	O
can	O
benefit	O
from	O
additional	O
guidance	O
using	O
corresponding	O
landmarks	O
in	O
the	O
images.	O
However,	O
the	O
benefits	O
thereof	O
are	O
largely	O
understudied,	O
especially	O
due	O
to	O
the	O
lack	O
of	O
automatic	O
detection	O
methods	O
for	O
corresponding	O
landmarks	O
in	O
three-dimensional	O
(3D)	O
medical	O
images.	O
In	O
this	O
work,	O
we	O
present	O
a	O
Deep	O
Convolutional	O
Neural	O
Network	O
(DCNN),	O
called	O
DCNN-Match,	O
that	O
learns	O
to	O
predict	O
landmark	O
correspondences	O
in	O
3D	O
images	O
in	O
a	O
self-supervised	O
manner.	O
We	O
explored	O
five	O
variants	O
of	O
DCNN-Match	O
that	O
use	O
different	O
loss	O
functions	O
and	O
tested	O
DCNN-Match	O
separately	O
as	O
well	O
as	O
in	O
combination	O
with	O
the	O
open-source	O
registration	O
software	O
Elastix	O
to	O
assess	O
its	O
impact	O
on	O
a	O
common	O
DIR	O
approach.	O
We	O
employed	O
lower-abdominal	O
Computed	B-RESEARCH_PROBLEM
Tomography	I-RESEARCH_PROBLEM
(CT)	E-RESEARCH_PROBLEM
scans	O
from	O
cervical	O
cancer	O
patients:	O
121	O
pelvic	O
CT	O
scan	O
pairs	O
containing	O
simulated	O
elastic	O
transformations	O
and	O
11	O
pairs	O
demonstrating	O
clinical	O
deformations.	O
Our	O
results	O
show	O
significant	O
improvement	O
in	O
DIR	O
performance	O
when	O
landmark	O
correspondences	O
predicted	O
by	O
DCNN-Match	O
were	O
used	O
in	O
case	O
of	O
simulated	O
as	O
well	O
as	O
clinical	O
deformations.	O
We	O
also	O
observed	O
that	O
the	O
spatial	O
distribution	O
of	O
the	O
automatically	O
identified	O
landmarks	O
and	O
the	O
associated	O
matching	O
errors	O
affect	O
the	O
extent	O
of	O
improvement	O
in	O
DIR.	O
Finally,	O
DCNN-Match	O
was	O
found	O
to	O
generalize	O
well	O
to	O
Magnetic	O
Resonance	O
Imaging	O
(MRI)	O
scans	O
without	O
requiring	O
retraining,	O
indicating	O
easy	O
applicability	O
to	O
other	O
datasets.	O

Incorporating	O
external	O
knowledge	O
into	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER	S-RESEARCH_PROBLEM
)	O
systems	O
has	O
been	O
widely	O
studied	O
in	O
the	O
generic	O
domain.	O
In	O
this	O
paper,	O
we	O
focus	O
on	O
clinical	O
domain	O
where	O
only	O
limited	O
data	O
is	O
accessible	O
and	O
interpretability	O
is	O
important.	O
Recent	O
advancement	O
in	O
technology	O
and	O
the	O
acceleration	O
of	O
clinical	O
trials	O
has	O
resulted	O
in	O
the	O
discovery	O
of	O
new	O
drugs,	O
procedures	O
as	O
well	O
as	O
medical	O
conditions.	O
These	O
factors	O
motivate	O
towards	O
building	O
robust	O
zero-shot	O
NER	S-RESEARCH_PROBLEM
systems	O
which	O
can	O
quickly	O
adapt	O
to	O
new	O
medical	O
terminology.	O
We	O
propose	O
an	O
auxiliary	O
gazetteer	O
model	O
and	O
fuse	O
it	O
with	O
an	O
NER	S-RESEARCH_PROBLEM
system,	O
which	O
results	O
in	O
better	O
robustness	O
and	O
interpretability	O
across	O
different	O
clinical	O
datasets.	O
Our	O
gazetteer	O
based	O
fusion	O
model	O
is	O
data	O
efficient,	O
achieving	O
+1.7	O
micro-F1	O
gains	O
on	O
the	O
i2b2	O
dataset	O
using	O
20%	O
training	O
data,	O
and	O
brings	O
+	O
4.7	O
micro-F1	O
gains	O
on	O
novel	O
entity	O
mentions	O
never	O
presented	O
during	O
training.	O
Moreover,	O
our	O
fusion	O
model	O
is	O
able	O
to	O
quickly	O
adapt	O
to	O
new	O
mentions	O
in	O
gazetteers	O
without	O
re-training	O
and	O
the	O
gains	O
from	O
the	O
proposed	O
fusion	O
model	O
are	O
transferable	O
to	O
related	O
datasets.	O

Benefiting	O
from	O
the	O
powerful	O
expressive	O
capability	O
of	O
graphs,	O
graph-based	O
approaches	O
have	O
achieved	O
impressive	O
performance	O
in	O
various	O
biomedical	O
applications.	O
Most	O
existing	O
methods	O
tend	O
to	O
define	O
the	O
adjacency	O
matrix	O
among	O
samples	O
manually	O
based	O
on	O
meta-features,	O
and	O
then	O
obtain	O
the	O
node	O
embeddings	O
for	O
downstream	O
tasks	O
by	O
Graph	B-RESEARCH_PROBLEM
Representation	I-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(GRL).	O
However,	O
it	O
is	O
not	O
easy	O
for	O
these	O
approaches	O
to	O
generalize	O
to	O
unseen	O
samples.	O
Meanwhile,	O
the	O
complex	O
correlation	O
between	O
modalities	O
is	O
also	O
ignored.	O
As	O
a	O
result,	O
these	O
factors	O
inevitably	O
yield	O
the	O
inadequacy	O
of	O
providing	O
valid	O
information	O
about	O
the	O
patient's	O
condition	O
for	O
a	O
reliable	O
diagnosis.	O
In	O
this	O
paper,	O
we	O
propose	O
an	O
end-to-end	O
Multimodal	O
Graph	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
framework	O
(MMGL)	O
for	O
disease	O
prediction.	O
To	O
effectively	O
exploit	O
the	O
rich	O
information	O
across	O
multi-modality	O
associated	O
with	O
diseases,	O
amodal-attentional	O
multi-modal	O
fusion	O
is	O
proposed	O
to	O
integrate	O
the	O
features	O
of	O
each	O
modality	O
by	O
leveraging	O
the	O
correlation	O
and	O
complementarity	O
between	O
the	O
modalities.	O
Furthermore,	O
instead	O
of	O
defining	O
the	O
adjacency	O
matrix	O
manually	O
as	O
existing	O
methods,	O
the	O
latent	O
graph	O
structure	O
can	O
be	O
captured	O
through	O
a	O
novel	O
way	O
of	O
adaptive	O
graph	O
learning.	O
It	O
could	O
be	O
jointly	O
optimized	O
with	O
the	O
prediction	O
model,	O
thus	O
revealing	O
the	O
intrinsic	O
connections	O
among	O
samples.	O
Unlike	O
the	O
previous	O
transductive	O
methods,	O
our	O
model	O
is	O
also	O
applicable	O
to	O
the	O
scenario	O
of	O
inductive	O
learning	O
for	O
those	O
unseen	O
data.	O
An	O
extensive	O
group	O
of	O
experiments	O
on	O
two	O
disease	O
prediction	O
problems	O
is	O
then	O
carefully	O
designed	O
and	O
presented,	O
demonstrating	O
that	O
MMGL	O
obtains	O
more	O
favorable	O
performances.	O
In	O
addition,	O
we	O
also	O
visualize	O
and	O
analyze	O
the	O
learned	O
graph	O
structure	O
to	O
provide	O
more	O
reliable	O
decision	O
support	O
for	O
doctors	O
in	O
real	O
medical	O
applications	O
and	O
inspiration	O
for	O
disease	O
research.	O

Recent	O
advances	O
in	O
Unsupervised	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(UNMT)	O
have	O
minimized	O
the	O
gap	O
between	O
supervised	O
and	O
unsupervised	O
machine	O
translation	O
performance	O
for	O
closely	O
related	O
language	O
pairs.	O
However,	O
the	O
situation	O
is	O
very	O
different	O
for	O
distant	O
language	O
pairs.	O
Lack	O
of	O
lexical	O
overlap	O
and	O
low	O
syntactic	O
similarities	O
such	O
as	O
between	O
English	O
and	O
Indo-Aryan	O
languages	O
leads	O
to	O
poor	O
translation	O
quality	O
in	O
existing	O
UNMT	O
systems.	O
In	O
this	O
paper,	O
we	O
show	O
that	O
initializing	O
the	O
embedding	O
layer	O
of	O
UNMT	O
models	O
with	O
cross-lingual	O
embeddings	O
shows	O
significant	O
improvements	O
in	O
BLEU	O
score	O
over	O
existing	O
approaches	O
with	O
embeddings	O
randomly	O
initialized.	O
Further,	O
static	O
embeddings	O
(freezing	O
the	O
embedding	O
layer	O
weights)	O
lead	O
to	O
better	O
gains	O
compared	O
to	O
updating	O
the	O
embedding	O
layer	O
weights	O
during	O
training	O
(non-static).	O
We	O
experimented	O
using	O
Masked	O
Sequence	O
to	O
Sequence	O
(MASS)	O
and	O
Denoising	S-RESEARCH_PROBLEM
Autoencoder	O
(DAE)	O
UNMT	O
approaches	O
for	O
three	O
distant	O
language	O
pairs.	O
The	O
proposed	O
cross-lingual	O
embedding	O
initialization	O
yields	O
BLEU	O
score	O
improvement	O
of	O
as	O
much	O
as	O
ten	O
times	O
over	O
the	O
baseline	O
for	O
English-Hindi,	O
English-Bengali,	O
and	O
English-Gujarati.	O
Our	O
analysis	O
shows	O
the	O
importance	O
of	O
cross-lingual	O
embedding,	O
comparisons	O
between	O
approaches,	O
and	O
the	O
scope	O
of	O
improvements	O
in	O
these	O
systems.	O

In	O
the	O
last	O
years,	O
there	O
have	O
been	O
significant	O
developments	O
in	O
the	O
area	O
of	O
Question	B-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
over	O
Knowledge	B-RESEARCH_PROBLEM
Graphs	E-RESEARCH_PROBLEM
(KGQA).	O
Despite	O
all	O
the	O
notable	O
advancements,	O
current	O
KGQA	O
datasets	O
only	O
provide	O
the	O
answers	O
as	O
the	O
direct	O
output	O
result	O
of	O
the	O
formal	O
query,	O
rather	O
than	O
full	O
sentences	O
incorporating	O
question	O
context.	O
For	O
achieving	O
coherent	O
answers	O
sentence	O
with	O
the	O
question's	O
vocabulary,	O
template-based	O
verbalization	O
so	O
are	O
usually	O
employed	O
for	O
a	O
better	O
representation	O
of	O
answers,	O
which	O
in	O
turn	O
require	O
extensive	O
expert	O
intervention.	O
Thus,	O
making	O
way	O
for	O
machine	O
learning	O
approaches;	O
however,	O
there	O
is	O
a	O
scarcity	O
of	O
datasets	O
that	O
empower	O
machine	O
learning	O
models	O
in	O
this	O
area.	O
Hence,	O
we	O
provide	O
the	O
VANiLLa	O
dataset	O
which	O
aims	O
at	O
reducing	O
this	O
gap	O
by	O
offering	O
answers	O
in	O
natural	O
language	O
sentences.	O
The	O
answer	O
sentences	O
in	O
this	O
dataset	O
are	O
syntactically	O
and	O
semantically	O
closer	O
to	O
the	O
question	O
than	O
to	O
the	O
triple	O
fact.	O
Our	O
dataset	O
consists	O
of	O
over	O
100k	O
simple	O
questions	O
adapted	O
from	O
the	O
CSQA	O
and	O
SimpleQuestionsWikidata	O
datasets	O
and	O
generated	O
using	O
a	O
semi-automatic	O
framework.	O
We	O
also	O
present	O
results	O
of	O
training	O
our	O
dataset	O
on	O
multiple	O
baseline	O
models	O
adapted	O
from	O
current	O
state-of-the-art	O
Natural	O
Language	O
Generation	O
(NLG)	O
architectures.	O
We	O
believe	O
that	O
this	O
dataset	O
will	O
allow	O
researchers	O
to	O
focus	O
on	O
finding	O
suitable	O
methodologies	O
and	O
architectures	O
for	O
answer	O
verbalization.	O

Voice	O
assistants	O
provide	O
users	O
a	O
new	O
way	O
of	O
interacting	O
with	O
digital	O
products,	O
allowing	O
them	O
to	O
retrieve	O
information	O
and	O
complete	O
tasks	O
with	O
an	O
increased	O
sense	O
of	O
control	O
and	O
flexibility.	O
Such	O
products	O
are	O
comprised	O
of	O
several	O
machine	O
learning	O
models,	O
like	O
Speech-to-Text	O
transcription,	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
and	O
Resolution,	O
and	O
Text	O
Classification.	O
Building	O
a	O
voice	B-RESEARCH_PROBLEM
assistant	E-RESEARCH_PROBLEM
from	O
scratch	O
takes	O
the	O
prolonged	O
efforts	O
of	O
several	O
teams	O
constructing	O
numerous	O
models	O
and	O
orchestrating	O
between	O
components.	O
Alternatives	O
such	O
as	O
using	O
third-party	O
vendors	O
or	O
re-purposing	O
existing	O
models	O
may	O
be	O
considered	O
to	O
shorten	O
time-to-market	O
and	O
development	O
costs.	O
However,	O
each	O
option	O
has	O
its	O
benefits	O
and	O
drawbacks.	O
We	O
present	O
key	O
insights	O
from	O
building	O
a	O
voice	O
search	O
assistant	O
for	O
Booking.com	O
search	O
and	O
recommendation	O
system.	O
Our	O
paper	O
compares	O
the	O
achieved	O
performance	O
and	O
development	O
efforts	O
in	O
dedicated	O
tailor-made	O
solutions	O
against	O
existing	O
re-purposed	O
models.	O
We	O
share	O
and	O
discuss	O
our	O
data-driven	O
decisions	O
about	O
implementation	O
trade-offs	O
and	O
their	O
estimated	O
outcomes	O
in	O
hindsight,	O
showing	O
that	O
a	O
fully	O
functional	O
machine	O
learning	O
product	O
can	O
be	O
built	O
from	O
existing	O
models.	O

Robots	O
are	O
becoming	O
everyday	O
devices,	O
increasing	O
their	O
interaction	O
with	O
humans.	O
To	O
make	O
human-machine	O
interaction	O
more	O
natural,	O
cognitive	O
features	O
like	O
Visual	O
Voice	O
Activity	B-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
(VVAD),	O
which	O
can	O
detect	O
whether	O
a	O
person	O
is	O
speaking	O
or	O
not,	O
given	O
visual	O
input	O
of	O
a	O
camera,	O
need	O
to	O
be	O
implemented.	O
Neural	O
networks	O
are	O
state	O
of	O
the	O
art	O
for	O
tasks	O
in	O
Image	O
Processing,	O
Time	B-RESEARCH_PROBLEM
Series	E-RESEARCH_PROBLEM
Prediction,	O
Natural	O
Language	O
Processing	O
and	O
other	O
domains.	O
Those	O
Networks	O
require	O
large	O
quantities	O
of	O
labeled	O
data.	O
Currently	O
there	O
are	O
not	O
many	O
datasets	O
for	O
the	O
task	O
of	O
VVAD.	O
In	O
this	O
work	O
we	O
created	O
a	O
large	O
scale	O
dataset	O
called	O
the	O
VVAD-LRS3	O
dataset,	O
derived	O
by	O
automatic	O
annotations	O
from	O
the	O
LRS3	O
dataset.	O
The	O
VVAD-LRS3	O
dataset	O
contains	O
over	O
44K	O
samples,	O
over	O
three	O
times	O
the	O
next	O
competitive	O
dataset	O
(WildVVAD).	O
We	O
evaluate	O
different	O
baselines	O
on	O
four	O
kinds	O
of	O
features:	O
facial	O
and	O
lip	O
images,	O
and	O
facial	O
and	O
lip	O
landmark	O
features.	O
With	O
a	O
Convolutional	O
Neural	O
Network	O
Long	O
Short	O
Term	O
Memory	O
(CNN	O
LSTM)	O
on	O
facial	O
images	O
an	O
accuracy	O
of	O
92%	O
was	O
reached	O
on	O
the	O
test	O
set.	O
A	O
study	O
with	O
humans	O
showed	O
that	O
they	O
reach	O
an	O
accuracy	O
of	O
87.93%	O
on	O
the	O
test	O
set.	O

Sound	B-RESEARCH_PROBLEM
Event	I-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
and	O
Audio	B-RESEARCH_PROBLEM
Classification	E-RESEARCH_PROBLEM
tasks	O
are	O
traditionally	O
addressed	O
through	O
time-frequency	O
representations	O
of	O
audio	O
signals	O
such	O
as	O
spectrograms.	O
However,	O
the	O
emergence	O
of	O
deep	O
neural	O
networks	O
as	O
efficient	O
feature	O
extractors	O
has	O
enabled	O
the	O
direct	O
use	O
of	O
audio	O
signals	O
for	O
classification	O
purposes.	O
In	O
this	O
paper,	O
we	O
attempt	O
to	O
recognize	O
musical	O
instruments	O
in	O
polyphonic	O
audio	O
by	O
only	O
feeding	O
their	O
raw	O
waveforms	O
into	O
deep	O
learning	O
models.	O
Various	O
recurrent	O
and	O
convolutional	O
architectures	O
incorporating	O
residual	O
connections	O
are	O
examined	O
and	O
parameterized	O
in	O
order	O
to	O
build	O
end-to-end	O
classi-fiers	O
with	O
low	O
computational	O
cost	O
and	O
only	O
minimal	O
preprocessing.	O
We	O
obtain	O
competitive	O
classification	O
scores	O
and	O
useful	O
instrument-wise	O
insight	O
through	O
the	O
IRMAS	O
test	O
set,	O
utilizing	O
a	O
parallel	O
CNN-BiGRU	O
model	O
with	O
multiple	O
residual	O
connections,	O
while	O
maintaining	O
a	O
significantly	O
reduced	O
number	O
of	O
trainable	O
parameters.	O

This	O
paper	O
describes	O
Netmarble's	O
submission	O
to	O
WMT21	O
Automatic	B-RESEARCH_PROBLEM
Post-Editing	E-RESEARCH_PROBLEM
(APE)	O
Shared	O
Task	O
for	O
the	O
English-German	O
language	O
pair.	O
First,	O
we	O
propose	O
a	O
Curriculum	O
Training	O
Strategy	O
in	O
training	O
stages.	O
Facebook	O
Fair's	O
WMT19	O
news	O
translation	O
model	O
was	O
chosen	O
to	O
engage	O
the	O
large	O
and	O
powerful	O
pre-trained	O
neural	O
networks.	O
Then,	O
we	O
post-train	O
the	O
translation	O
model	O
with	O
different	O
levels	O
of	O
data	O
at	O
each	O
training	O
stages.	O
As	O
the	O
training	O
stages	O
go	O
on,	O
we	O
make	O
the	O
system	O
learn	O
to	O
solve	O
multiple	O
tasks	O
by	O
adding	O
extra	O
information	O
at	O
different	O
training	O
stages	O
gradually.	O
We	O
also	O
show	O
a	O
way	O
to	O
utilize	O
the	O
additional	O
data	O
in	O
large	O
volume	O
for	O
APE	O
tasks.	O
For	O
further	O
improvement,	O
we	O
apply	O
Multi-Task	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
Strategy	O
with	O
the	O
Dynamic	O
Weight	O
Average	O
during	O
the	O
fine-tuning	O
stage.	O
To	O
fine-tune	O
the	O
APE	O
corpus	O
with	O
limited	O
data,	O
we	O
add	O
some	O
related	O
subtasks	O
to	O
learn	O
a	O
unified	O
representation.	O
Finally,	O
for	O
better	O
performance,	O
we	O
leverage	O
external	O
translations	O
as	O
augmented	O
machine	O
translation	O
(MT)	O
during	O
the	O
post-training	O
and	O
fine-tuning.	O
As	O
experimental	O
results	O
show,	O
our	O
APE	O
system	O
significantly	O
improves	O
the	O
translations	O
of	O
provided	O
MT	O
results	O
by	O
-2.848	O
and	O
+3.74	O
on	O
the	O
development	O
dataset	O
in	O
terms	O
of	O
TER	O
and	O
BLEU,	O
respectively.	O
It	O
also	O
demonstrates	O
its	O
effectiveness	O
on	O
the	O
test	O
dataset	O
with	O
higher	O
quality	O
than	O
the	O
development	O
dataset.	O

In	O
this	O
paper	O
we	O
propose	O
a	O
new	O
approach	O
to	O
evaluate	O
the	O
informativeness	O
oftranscriptions	O
coming	O
from	O
Automatic	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
systems.	O
This	O
approach,based	O
in	O
the	O
notion	O
of	O
informativeness,	O
is	O
focused	O
on	O
the	O
framework	O
ofAutomatic	O
Text	B-RESEARCH_PROBLEM
Summarization	E-RESEARCH_PROBLEM
performed	O
over	O
these	O
transcriptions.	O
At	O
a	O
firstglance	O
we	O
estimate	O
the	O
informative	O
content	O
of	O
the	O
various	O
automatictranscriptions,	O
then	O
we	O
explore	O
the	O
capacity	O
of	O
Automatic	O
Text	B-RESEARCH_PROBLEM
Summarization	E-RESEARCH_PROBLEM
toovercome	O
the	O
informative	O
loss.	O
To	O
do	O
this	O
we	O
use	O
an	O
automatic	O
summaryevaluation	O
protocol	O
without	O
reference	O
(based	O
on	O
the	O
informative	O
content),	O
whichcomputes	O
the	O
divergence	O
between	O
probability	O
distributions	O
of	O
different	O
textualrepresentations:	O
manual	O
and	O
automatic	O
transcriptions	O
and	O
their	O
summaries.	O
Aftera	O
set	O
of	O
evaluations	O
this	O
analysis	O
allowed	O
us	O
to	O
judge	O
both	O
the	O
quality	O
of	O
thetranscriptions	O
in	O
terms	O
of	O
informativeness	O
and	O
to	O
assess	O
the	O
ability	O
ofautomatic	O
text	O
summarization	O
to	O
compensate	O
the	O
problems	O
raised	O
during	O
thetranscription	O
phase.	O

Conventional	O
spoken	O
language	O
translation	O
(SLT)	O
systems	O
are	O
pipeline	O
based	O
systems,	O
where	O
we	O
have	O
an	O
Automatic	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(ASR)	O
system	O
to	O
convert	O
the	O
modality	O
of	O
source	O
from	O
speech	O
to	O
text	O
and	O
a	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(MT)	O
systems	O
to	O
translate	O
source	O
text	O
to	O
text	O
in	O
target	O
language.	O
Recent	O
progress	O
in	O
the	O
sequence-sequence	O
architectures	O
have	O
reduced	O
the	O
performance	O
gap	O
between	O
the	O
pipeline	O
based	O
SLT	O
systems	O
(cascaded	O
ASR-MT)	O
and	O
End-to-End	O
approaches.	O
Though	O
End-to-End	O
and	O
cascaded	O
ASR-MT	O
systems	O
are	O
reaching	O
to	O
the	O
comparable	O
levels	O
of	O
performances,	O
we	O
can	O
see	O
a	O
large	O
performance	O
gap	O
using	O
the	O
ASR	O
hypothesis	O
and	O
oracle	O
text	O
w.r.t	O
MT	O
models.	O
This	O
performance	O
gap	O
indicates	O
that	O
the	O
MT	O
systems	O
are	O
prone	O
to	O
large	O
performance	O
degradation	O
due	O
to	O
noisy	O
ASR	O
hypothesis	O
as	O
opposed	O
to	O
oracle	O
text	O
transcript.	O
In	O
this	O
work	O
this	O
degradation	O
in	O
the	O
performance	O
is	O
reduced	O
by	O
creating	O
an	O
end	O
to-end	O
differentiable	O
pipeline	O
between	O
the	O
ASR	O
and	O
MT	O
systems.	O
In	O
this	O
work,	O
we	O
train	O
SLT	O
systems	O
with	O
ASR	O
objective	O
as	O
an	O
auxiliary	O
loss	O
and	O
both	O
the	O
networks	O
are	O
connected	O
through	O
the	O
neural	O
hidden	O
representations.	O
This	O
train	O
ing	O
would	O
have	O
an	O
End-to-End	O
differentiable	O
path	O
w.r.t	O
to	O
the	O
final	O
objective	O
function	O
as	O
well	O
as	O
utilize	O
the	O
ASR	O
objective	O
for	O
better	O
performance	O
of	O
the	O
SLT	O
systems.	O
This	O
architecture	O
has	O
improved	O
from	O
BLEU	O
from	O
36.8	O
to	O
44.5.	O
Due	O
to	O
the	O
Multi-task	O
training	O
the	O
model	O
also	O
generates	O
the	O
ASR	O
hypothesis	O
which	O
are	O
used	O
by	O
a	O
pre-trained	O
MT	O
model.	O
Combining	O
the	O
proposed	O
systems	O
with	O
the	O
MT	O
model	O
has	O
increased	O
the	O
BLEU	O
score	O
by	O
1.	O
All	O
the	O
experiments	O
are	O
reported	O
on	O
English-Portuguese	O
speech	O
translation	O
task	O
using	O
How2	O
corpus.	O
The	O
final	O
BLEU	O
score	O
is	O
on-par	O
with	O
the	O
best	O
speech	O
translation	O
system	O
on	O
How2	O
dataset	O
with	O
no	O
additional	O
training	O
data	O
and	O
language	O
model	O
and	O
much	O
less	O
parameters.	O

In	O
this	O
paper	O
,	O
we	O
tackle	O
Sentiment	B-RESEARCH_PROBLEM
Analysis	E-RESEARCH_PROBLEM
conditioned	O
on	O
a	O
Topic	O
inTwitter	O
data	O
using	O
Deep	O
Learning	O
.	O
We	O
propose	O
a	O
2-tier	O
approach	O
:	O
In	O
the	O
firstphase	O
we	O
create	O
our	O
own	O
Word	B-RESEARCH_PROBLEM
Embeddings	E-RESEARCH_PROBLEM
and	O
see	O
that	O
they	O
do	O
perform	O
betterthan	O
state-of-the-art	O
embeddings	O
when	O
used	O
with	O
standard	O
classifiers.	O
We	O
thenperform	O
inference	O
on	O
these	O
embeddings	O
to	O
learn	O
more	O
about	O
a	O
word	O
with	O
respectto	O
all	O
the	O
topics	O
being	O
considered,	O
and	O
also	O
the	O
top	O
n-influencing	O
words	O
foreach	O
topic.	O
In	O
the	O
second	O
phase	O
we	O
use	O
these	O
embeddings	O
to	O
predict	O
thesentiment	O
of	O
the	O
tweet	O
with	O
respect	O
to	O
a	O
given	O
topic,	O
and	O
all	O
other	O
topicsunder	O
discussion.	O

Multilingual	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(MNMT)	O
trains	O
a	O
single	O
NMT	O
model	O
that	O
supports	O
translation	O
between	O
multiple	O
languages,	O
rather	O
than	O
training	O
separate	O
models	O
for	O
different	O
languages.	O
Learning	O
a	O
single	O
model	O
can	O
enhance	O
the	O
low-resource	O
translation	O
by	O
leveraging	O
data	O
from	O
multiple	O
languages.	O
However,	O
the	O
performance	O
of	O
an	O
MNMT	O
model	O
is	O
highly	O
dependent	O
on	O
the	O
type	O
of	O
languages	O
used	O
in	O
training,	O
as	O
transferring	O
knowledge	O
from	O
a	O
diverse	O
set	O
of	O
languages	O
degrades	O
the	O
translation	O
performance	O
due	O
to	O
negative	O
transfer.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
Hierarchical	O
Knowledge	B-RESEARCH_PROBLEM
Distillation	E-RESEARCH_PROBLEM
(HKD)	O
approach	O
for	O
MNMT	O
which	O
capitalises	O
on	O
language	O
groups	O
generated	O
according	O
to	O
typological	O
features	O
and	O
phylogeny	O
of	O
languages	O
to	O
overcome	O
the	O
issue	O
of	O
negative	O
transfer.	O
HKD	O
generates	O
a	O
set	O
of	O
multilingual	O
teacher-assistant	O
models	O
via	O
a	O
selective	O
knowledge	O
distillation	O
mechanism	O
based	O
on	O
the	O
language	O
groups,	O
and	O
then	O
distils	O
the	O
ultimate	O
multilingual	O
model	O
from	O
those	O
assistants	O
in	O
an	O
adaptive	O
way.	O
Experimental	O
results	O
derived	O
from	O
the	O
TED	O
dataset	O
with	O
53	O
languages	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
approach	O
in	O
avoiding	O
the	O
negative	O
transfer	O
effect	O
in	O
MNMT,	O
leading	O
to	O
an	O
improved	O
translation	O
performance	O
(about	O
1	O
BLEU	O
score	O
on	O
average)	O
compared	O
to	O
strong	O
baselines.	O

Image	O
classification	O
with	O
deep	O
neural	O
networks	O
is	O
typically	O
restricted	O
to	O
images	O
of	O
small	O
dimensionality	O
such	O
as	O
224	O
x	O
244	O
in	O
Resnet	O
models	O
[24].	O
This	O
limitation	O
excludes	O
the	O
4000	O
x	O
3000	O
dimensional	O
images	O
that	O
are	O
taken	O
by	O
modern	O
smartphone	O
cameras	O
and	O
smart	O
devices.	O
In	O
this	O
work,	O
we	O
aim	O
to	O
mitigate	O
the	O
prohibitive	O
inferential	O
and	O
memory	O
costs	O
of	O
operating	O
in	O
such	O
large	O
dimensional	O
spaces.	O
To	O
sample	O
from	O
the	O
high-resolution	O
original	O
input	O
distribution,	O
we	O
propose	O
using	O
a	O
smaller	O
proxy	O
distribution	O
to	O
learn	O
the	O
co-ordinates	O
that	O
correspond	O
to	O
regions	O
of	O
interest	O
in	O
the	O
high-dimensional	O
space.	O
We	O
introduce	O
a	O
new	O
principled	O
variational	O
lower	O
bound	O
that	O
captures	O
the	O
relationship	O
of	O
the	O
proxy	O
distribution's	O
posterior	O
and	O
the	O
original	O
image's	O
co-ordinate	O
space	O
in	O
a	O
way	O
that	O
maximizes	O
the	O
conditional	O
classification	O
likelihood.	O
We	O
empirically	O
demonstrate	O
on	O
one	O
synthetic	O
benchmark	O
and	O
one	O
real	O
world	O
large	O
resolution	O
DSLR	O
camera	O
image	O
dataset	O
that	O
our	O
method	O
produces	O
comparable	O
results	O
with	O
~10x	O
faster	O
inference	O
and	O
lower	O
memory	O
consumption	O
than	O
a	O
model	O
that	O
utilizes	O
the	O
entire	O
original	O
input	O
distribution.	O
Finally,	O
we	O
experiment	O
with	O
a	O
more	O
complex	O
setting	O
using	O
mini-maps	O
from	O
Starcraft	B-RESEARCH_PROBLEM
II	E-RESEARCH_PROBLEM
[56]	O
to	O
infer	O
the	O
number	O
of	O
characters	O
in	O
a	O
complex	O
3d-rendered	O
scene.	O
Even	O
in	O
such	O
complicated	O
scenes	O
our	O
model	O
provides	O
strong	O
localization:	O
a	O
feature	O
missing	O
from	O
traditional	O
classification	O
models.	O

Spoken	B-RESEARCH_PROBLEM
Dialogue	I-RESEARCH_PROBLEM
Systems	E-RESEARCH_PROBLEM
(SDS)	O
have	O
great	O
commercial	O
potential	O
as	O
they	O
promise	O
to	O
revolutionise	O
the	O
way	O
in	O
which	O
humans	O
interact	O
with	O
machines.	O
The	O
advent	O
of	O
deep	O
learning	O
led	O
to	O
substantial	O
developments	O
in	O
this	O
area	O
of	O
NLP	O
research,	O
and	O
the	O
goal	O
of	O
this	O
tutorial	O
is	O
to	O
familiarise	O
the	O
research	O
community	O
with	O
the	O
recent	O
advances	O
in	O
what	O
some	O
call	O
the	O
most	O
difficult	O
problem	O
in	O
NLP.	O
From	O
a	O
research	O
perspective,	O
the	O
design	O
of	O
spoken	O
dialogue	O
systems	O
provides	O
a	O
number	O
of	O
significant	O
challenges,	O
as	O
these	O
systems	O
depend	O
on:	O
a)	O
solving	O
several	O
difficult	O
NLP	O
and	O
decision-making	O
tasks;	O
and	O
b)	O
combining	O
these	O
into	O
a	O
functional	O
dialogue	O
system	O
pipeline.	O
A	O
key	O
long-term	O
goal	O
of	O
dialogue	O
system	O
research	O
is	O
to	O
enable	O
open-domain	O
systems	O
that	O
can	O
converse	O
about	O
arbitrary	O
topics	O
and	O
assist	O
humans	O
with	O
completing	O
a	O
wide	O
range	O
of	O
tasks.	O
Furthermore,	O
such	O
systems	O
need	O
to	O
autonomously	O
learn	O
on-line	O
to	O
improve	O
their	O
performance	O
and	O
recover	O
from	O
errors	O
using	O
both	O
signals	O
from	O
their	O
environment	O
and	O
from	O
implicit	O
and	O
explicit	O
user	O
feedback.	O
While	O
the	O
design	O
of	O
such	O
systems	O
has	O
traditionally	O
been	O
modular,	O
domain	O
and	O
language-specific,	O
advances	O
in	O
deep	O
learning	O
have	O
alleviated	O
many	O
of	O
the	O
design	O
problems.	O
The	O
main	O
purpose	O
of	O
this	O
tutorial	O
is	O
to	O
encourage	O
dialogue	O
research	O
in	O
the	O
NLP	O
community	O
by	O
providing	O
the	O
research	O
background,	O
a	O
survey	O
of	O
available	O
resources,	O
and	O
giving	O
key	O
insights	O
to	O
application	O
of	O
state-of-the-art	O
SDS	O
methodology	O
into	O
industry-scale	O
conversational	O
AI	O
systems.	O
We	O
plan	O
to	O
introduce	O
researchers	O
to	O
the	O
pipeline	O
framework	O
for	O
modelling	O
goal-oriented	O
dialogue	O
systems,	O
which	O
includes	O
three	O
key	O
components:	O
1)	O
Language	O
Understanding;	O
2)	O
Dialogue	O
Management;	O
and	O
3)	O
Language	O
Generation.	O
The	O
differences	O
between	O
goal-oriented	O
dialogue	O
systems	O
and	O
chat-bot	O
style	O
conversational	O
agents	O
will	O
be	O
explained	O
in	O
order	O
to	O
show	O
the	O
motivation	O
behind	O
the	O
design	O
of	O
both,	O
with	O
the	O
main	O
focus	O
on	O
the	O
pipeline	O
SDS	O
framework.	O
For	O
each	O
key	O
component,	O
we	O
will	O
define	O
the	O
research	O
problem,	O
provide	O
a	O
brief	O
literature	O
review	O
and	O
introduce	O
the	O
current	O
state-of-the-art	O
approaches.	O
Complementary	O
resources	O
(e.g.	O
available	O
datasets	O
and	O
toolkits)	O
will	O
also	O
be	O
discussed.	O
Finally,	O
future	O
work,	O
outstanding	O
challenges,	O
and	O
current	O
industry	O
practices	O
will	O
be	O
presented.	O
All	O
of	O
the	O
presented	O
material	O
will	O
be	O
made	O
available	O
online	O
for	O
future	O
reference.	O

The	O
use	O
of	O
the	O
internet	O
as	O
a	O
fast	O
medium	O
of	O
spreading	O
fake	O
news	O
reinforces	O
the	O
need	O
for	O
computational	O
tools	O
that	O
combat	O
it.	O
Techniques	O
that	O
train	O
fake	O
news	O
classifiers	O
exist,	O
but	O
they	O
all	O
assume	O
an	O
abundance	O
of	O
resources	O
including	O
large	O
labeled	O
datasets	O
and	O
expert-curated	O
corpora,	O
which	O
low-resource	O
languages	O
may	O
not	O
have.	O
In	O
this	O
work,	O
we	O
make	O
two	O
main	O
contributions:	O
First,	O
we	O
alleviate	O
resource	O
scarcity	O
by	O
constructing	O
the	O
first	O
expertly-curated	O
benchmark	O
dataset	O
for	O
fake	O
news	O
detection	O
in	O
Filipino,	O
which	O
we	O
call	O
"Fake	O
News	O
Filipino."	O
Second,	O
we	O
benchmark	O
Transfer	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(TL)	O
techniques	O
and	O
show	O
that	O
they	O
can	O
be	O
used	O
to	O
train	O
robust	O
fake	O
news	O
classifiers	O
from	O
little	O
data,	O
achieving	O
91%	O
accuracy	O
on	O
our	O
fake	O
news	O
dataset,	O
reducing	O
the	O
error	O
by	O
14%	O
compared	O
to	O
established	O
few-shot	O
baselines.	O
Furthermore,	O
lifting	O
ideas	O
from	O
multitask	O
learning,	O
we	O
show	O
that	O
augmenting	O
transformer-based	O
transfer	O
techniques	O
with	O
auxiliary	O
language	O
modeling	O
losses	O
improves	O
their	O
performance	O
by	O
adapting	O
to	O
writing	O
style.	O
Using	O
this,	O
we	O
improve	O
TL	O
performance	O
by	O
4-6%,	O
achieving	O
an	O
accuracy	O
of	O
96%	O
on	O
our	O
best	O
model.	O
Lastly,	O
we	O
show	O
that	O
our	O
method	O
generalizes	O
well	O
to	O
different	O
types	O
of	O
news	O
articles,	O
including	O
political	O
news,	O
entertainment	O
news,	O
and	O
opinion	O
articles.	O

Multimodal	B-RESEARCH_PROBLEM
Sentiment	I-RESEARCH_PROBLEM
Analysis	E-RESEARCH_PROBLEM
(MuSe)	O
2021	O
is	O
a	O
challenge	O
focusing	O
on	O
the	O
tasks	O
of	O
sentiment	O
and	O
emotion,	O
as	O
well	O
as	O
physiological-emotion	O
and	O
emotion-based	O
stress	O
recognition	O
through	O
more	O
comprehensively	O
integrating	O
the	O
audio-visual,	O
language,	O
and	O
biological	O
signal	O
modalities.	O
The	O
purpose	O
of	O
MuSe	O
2021	O
is	O
to	O
bring	O
together	O
communities	O
from	O
different	O
disciplines;	O
mainly,	O
the	O
audio-visual	O
emotion	O
recognition	O
community	O
(signal-based),	O
the	O
sentiment	O
analysis	O
community	O
(symbol-based),	O
and	O
the	O
health	O
informatics	O
community.	O
We	O
present	O
four	O
distinct	O
sub-challenges:	O
MuSe-Wilder	O
and	O
MuSe-Stress	O
which	O
focus	O
on	O
continuous	O
emotion	O
(valence	O
and	O
arousal)	O
prediction;	O
MuSe-Sent,	O
in	O
which	O
participants	O
recognise	O
five	O
classes	O
each	O
for	O
valence	O
and	O
arousal;	O
and	O
MuSe-Physio,	O
in	O
which	O
the	O
novel	O
aspect	O
of	O
`physiological-emotion'	O
is	O
to	O
be	O
predicted.	O
For	O
this	O
years'	O
challenge,	O
we	O
utilise	O
the	O
MuSe-CaR	O
dataset	O
focusing	O
on	O
user-generated	O
reviews	O
and	O
introduce	O
the	O
Ulm-TSST	O
dataset,	O
which	O
displays	O
people	O
in	O
stressful	O
depositions.	O
This	O
paper	O
also	O
provides	O
detail	O
on	O
the	O
state-of-the-art	O
feature	O
sets	O
extracted	O
from	O
these	O
datasets	O
for	O
utilisation	O
by	O
our	O
baseline	O
model,	O
a	O
Long	O
Short-Term	O
Memory-Recurrent	O
Neural	O
Network.	O
For	O
each	O
sub-challenge,	O
a	O
competitive	O
baseline	O
for	O
participants	O
is	O
set;	O
namely,	O
on	O
test,	O
we	O
report	O
a	O
Concordance	O
Correlation	O
Coefficient	O
(CCC)	O
of	O
.4616	O
CCC	O
for	O
MuSe-Wilder;	O
.4717	O
CCC	O
for	O
MuSe-Stress,	O
and	O
.4606	O
CCC	O
for	O
MuSe-Physio.	O
For	O
MuSe-Sent	O
an	O
F1	O
score	O
of	O
32.82	O
%	O
is	O
obtained.	O

Unsupervised	O
and	O
semi-supervised	O
learning	O
are	O
important	O
problems	O
that	O
are	O
especially	O
challenging	O
with	O
complex	O
data	O
like	O
natural	O
images.	O
Progress	O
on	O
these	O
problems	O
would	O
accelerate	O
if	O
we	O
had	O
access	O
to	O
appropriate	O
generative	O
models	O
under	O
which	O
to	O
pose	O
the	O
associated	O
inference	O
tasks.	O
Inspired	O
by	O
the	O
success	O
of	O
Convolutional	O
Neural	O
Networks	O
(CNNs)	O
for	O
supervised	O
prediction	O
in	O
images,	O
we	O
design	O
the	O
Neural	B-RESEARCH_PROBLEM
Rendering	E-RESEARCH_PROBLEM
Model	O
(NRM),	O
a	O
new	O
hierarchical	O
probabilistic	O
generative	O
model	O
whose	O
inference	O
calculations	O
correspond	O
to	O
those	O
in	O
a	O
CNN.	O
The	O
NRM	O
introduces	O
a	O
small	O
set	O
of	O
latent	O
variables	O
at	O
each	O
level	O
of	O
the	O
model	O
and	O
enforces	O
dependencies	O
among	O
all	O
the	O
latent	O
variables	O
via	O
a	O
conjugate	O
prior	O
distribution.	O
The	O
conjugate	O
prior	O
yields	O
a	O
new	O
regularizer	O
for	O
learning	O
based	O
on	O
the	O
paths	O
rendered	O
in	O
the	O
generative	O
model	O
for	O
training	O
CNNs?the	O
Rendering	O
Path	O
Normalization	O
(RPN).	O
We	O
demonstrate	O
that	O
this	O
regularizer	O
improves	O
generalization	O
both	O
in	O
theory	O
and	O
in	O
practice.	O
Likelihood	O
estimation	O
in	O
the	O
NRM	O
yields	O
the	O
new	O
Max-Min	O
cross	O
entropy	O
training	O
loss,	O
which	O
suggests	O
a	O
new	O
deep	O
network	O
architecture?the	O
Max-	O
Min	O
network?which	O
exceeds	O
or	O
matches	O
the	O
state-of-art	O
for	O
semi-supervised	O
and	O
supervised	O
learning	O
on	O
SVHN,	O
CIFAR10,	O
and	O
CIFAR100.	O

In	O
this	O
paper	O
we	O
describe	O
a	O
non-expert	O
setup	O
for	O
Vietnamese	O
speech	O
recognition	O
system	O
using	O
Kaldi	O
toolkit.	O
We	O
collected	O
a	O
speech	O
corpus	O
over	O
fifteen	O
hours	O
from	O
about	O
fifty	O
Vietnamese	O
native	O
speakers	O
and	O
using	O
it	O
to	O
test	O
the	O
feasibility	O
of	O
our	O
setup.	O
The	O
essential	O
linguistic	O
components	O
for	O
the	O
Automatic	O
Speech	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(ASR)	O
system	O
was	O
prepared	O
basing	O
on	O
the	O
written	O
form	O
of	O
the	O
language	O
instead	O
of	O
expertise	O
knowledge	O
on	O
linguistic	O
and	O
phonology	O
as	O
commonly	O
seen	O
in	O
rich	O
resource	O
languages	O
like	O
English.	O
The	O
modeling	O
of	O
tones	O
by	O
integrating	O
them	O
into	O
the	O
phoneme	O
and	O
using	O
the	O
phonetic	O
decision	O
tree	O
is	O
also	O
discussed.	O
Experimental	O
results	O
showed	O
this	O
setup	O
for	O
ASR	O
systems	O
does	O
yield	O
competitive	O
results	O
while	O
still	O
have	O
potentials	O
for	O
further	O
improvements.	O

This	O
work	O
attempts	O
to	O
tackle	O
the	O
problem	O
of	O
domain	O
generalization	O
(DG)	O
via	O
learning	O
to	O
reduce	O
domain	O
shift	O
with	O
an	O
episodic	O
training	O
procedure.	O
In	O
particular,	O
we	O
measure	O
the	O
domain	O
shift	O
with	O
$\mathcal{Y}$-discrepancy	O
and	O
learn	O
to	O
optimize	O
$\mathcal{Y}$-discrepancy	O
between	O
the	O
unseen	O
target	O
domain	O
and	O
source	O
domains	O
only	O
using	O
source-domain	O
samples.	O
Theoretically,	O
we	O
give	O
a	O
PAC-style	O
generalization	O
bound	O
for	O
discrepancy-optimal	O
meta-learning	O
and	O
further	O
make	O
comparisons	O
with	O
other	O
DG	O
bounds	O
including	O
ERM	O
and	O
domain-invariant	O
learning.	O
The	O
theoretical	O
analyses	O
show	O
that	O
there	O
is	O
a	O
tradeoff	O
between	O
classification	O
performance	O
and	O
computational	O
complexity	O
for	O
discrepancy-optimal	O
meta-learning.	O
The	O
theoretical	O
results	O
also	O
shed	O
light	O
on	O
a	O
bilevel	B-RESEARCH_PROBLEM
optimization	E-RESEARCH_PROBLEM
algorithm	O
for	O
DG.	O
Empirically,	O
we	O
evaluate	O
the	O
algorithm	O
with	O
DomainBed	O
and	O
achieves	O
state-of-the-art	O
results	O
on	O
two	O
DG	O
benchmarks.	O

Automatic	O
License	B-RESEARCH_PROBLEM
Plate	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(ALPR)	O
is	O
a	O
challenging	O
area	O
of	O
researchdue	O
to	O
its	O
importance	O
to	O
variety	O
of	O
commercial	O
applications.	O
The	O
overallproblem	O
may	O
be	O
subdivided	O
into	O
two	O
key	O
modules,	O
firstly,	O
localization	O
oflicense	O
plates	O
from	O
vehicle	O
images,	O
and	O
secondly,	O
optical	O
character	O
recognitionof	O
extracted	O
license	O
plates.	O
In	O
the	O
current	O
work,	O
we	O
have	O
concentrated	O
on	O
thefirst	O
part	O
of	O
the	O
problem,	O
i.e.,	O
localization	O
of	O
license	O
plate	O
regions	O
fromIndian	O
commercial	O
vehicles	O
as	O
a	O
significant	O
step	O
towards	O
development	O
of	O
acomplete	O
ALPR	O
system	O
for	O
Indian	O
vehicles.	O
The	O
technique	O
is	O
based	O
on	O
color	O
basedsegmentation	O
of	O
vehicle	O
images	O
and	O
identification	O
of	O
potential	O
license	O
plateregions.	O
True	O
license	O
plates	O
are	O
finally	O
localized	O
based	O
on	O
four	O
spatial	O
andhorizontal	O
contrast	O
features.	O
The	O
technique	O
successfully	O
localizes	O
the	O
actuallicense	O
plates	O
in	O
73.4%	O
images.	O

Accuracy	O
predictor	O
is	O
a	O
key	O
component	O
in	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(NAS)	O
for	O
ranking	O
architectures.	O
Building	O
a	O
high-quality	O
accuracy	O
predictor	O
usually	O
costs	O
enormous	O
computation.	O
To	O
address	O
this	O
issue,	O
instead	O
of	O
using	O
an	O
accuracy	O
predictor,	O
we	O
propose	O
a	O
novel	O
zero-shot	O
index	O
dubbed	O
Zen-Score	O
to	O
rank	O
the	O
architectures.	O
The	O
Zen-Score	O
represents	O
the	O
network	O
expressivity	O
and	O
positively	O
correlates	O
with	O
the	O
model	O
accuracy.	O
The	O
calculation	O
of	O
Zen-Score	O
only	O
takes	O
a	O
few	O
forward	O
inferences	O
through	O
a	O
randomly	O
initialized	O
network,	O
without	O
training	O
network	O
parameters.	O
Built	O
upon	O
the	O
Zen-Score,	O
we	O
further	O
propose	O
a	O
new	O
NAS	O
algorithm,	O
termed	O
as	O
Zen-NAS,	O
by	O
maximizing	O
the	O
Zen-Score	O
of	O
the	O
target	O
network	O
under	O
given	O
inference	O
budgets.	O
Within	O
less	O
than	O
half	O
GPU	O
day,	O
Zen-NAS	O
is	O
able	O
to	O
directly	O
search	O
high	O
performance	O
architectures	O
in	O
a	O
data-free	O
style.	O
Comparing	O
with	O
previous	O
NAS	O
methods,	O
the	O
proposed	O
Zen-NAS	O
is	O
magnitude	O
times	O
faster	O
on	O
multiple	O
server-side	O
and	O
mobile-side	O
GPU	O
platforms	O
with	O
state-of-the-art	O
accuracy	O
on	O
ImageNet.	O
Searching	O
and	O
training	O
code	O
as	O
well	O
as	O
pre-trained	O
models	O
are	O
available	O
from	O
https://github.com/idstcv/ZenNAS.	O

Recently,	O
along	O
with	O
the	O
rapid	O
development	O
of	O
mobile	O
communication	O
technology,	O
edge	O
computing	O
theory	O
and	O
techniques	O
have	O
been	O
attracting	O
more	O
and	O
more	O
attentions	O
from	O
global	O
researchers	O
and	O
engineers,	O
which	O
can	O
significantly	O
bridge	O
the	O
capacity	O
of	O
cloud	O
and	O
requirement	O
of	O
devices	O
by	O
the	O
network	O
edges,	O
and	O
thus	O
can	O
accelerate	O
the	O
content	O
deliveries	O
and	O
improve	O
the	O
quality	O
of	O
mobile	O
services.	O
In	O
order	O
to	O
bring	O
more	O
intelligence	O
to	O
the	O
edge	O
systems,	O
compared	O
to	O
traditional	O
optimization	O
methodology,	O
and	O
driven	O
by	O
the	O
current	O
deep	O
learning	O
techniques,	O
we	O
propose	O
to	O
integrate	O
the	O
Deep	O
Reinforcement	O
Learning	O
techniques	O
and	O
Federated	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
framework	O
with	O
the	O
mobile	O
edge	O
systems,	O
for	O
optimizing	O
the	O
mobile	O
edge	O
computing,	O
caching	O
and	O
communication.	O
And	O
thus,	O
we	O
design	O
the	O
"In-Edge	O
AI"	O
framework	O
in	O
order	O
to	O
intelligently	O
utilize	O
the	O
collaboration	O
among	O
devices	O
and	O
edge	O
nodes	O
to	O
exchange	O
the	O
learning	O
parameters	O
for	O
a	O
better	O
training	O
and	O
inference	O
of	O
the	O
models,	O
and	O
thus	O
to	O
carry	O
out	O
dynamic	O
system-level	O
optimization	O
and	O
application-level	O
enhancement	O
while	O
reducing	O
the	O
unnecessary	O
system	O
communication	O
load.	O
"In-Edge	O
AI"	O
is	O
evaluated	O
and	O
proved	O
to	O
have	O
near-optimal	O
performance	O
but	O
relatively	O
low	O
overhead	O
of	O
learning,	O
while	O
the	O
system	O
is	O
cognitive	O
and	O
adaptive	O
to	O
the	O
mobile	O
communication	O
systems.	O
Finally,	O
we	O
discuss	O
several	O
related	O
challenges	O
and	O
opportunities	O
for	O
unveiling	O
a	O
promising	O
upcoming	O
future	O
of	O
"In-Edge	O
AI".	O

We	O
propose	O
a	O
framework	O
for	O
compressing	O
state-of-the-art	O
Single	O
Shot	O
MultiBoxDetector	O
(SSD).	O
The	O
framework	O
addresses	O
compression	O
in	O
the	O
following	O
stages:Sparsity	O
Induction,	O
Filter	O
Selection,	O
and	O
Filter	O
Pruning.	O
In	O
the	O
SparsityInduction	O
stage,	O
the	O
object	O
detector	O
model	O
is	O
sparsified	O
via	O
an	O
improved	O
globalthreshold.	O
In	O
Filter	O
Selection	O
&	O
Pruning	O
stage,	O
we	O
select	O
and	O
remove	O
filtersusing	O
sparsity	O
statistics	O
of	O
filter	O
weights	O
in	O
two	O
consecutive	O
convolutionallayers.	O
This	O
results	O
in	O
the	O
model	O
with	O
the	O
size	O
smaller	O
than	O
most	O
existingcompact	O
architectures.	O
We	O
evaluate	O
the	O
performance	O
of	O
our	O
framework	O
withmultiple	O
datasets	O
and	O
compare	O
over	O
multiple	O
methods.	O
Experimental	O
results	O
showthat	O
our	O
method	O
achieves	O
state-of-the-art	O
compression	O
of	O
6.7X	O
and	O
4.9X	O
onPASCAL	O
VOC	O
dataset	O
on	O
models	O
SSD300	O
and	O
SSD512	O
respectively.	O
We	O
further	O
showthat	O
the	O
method	O
produces	O
maximum	O
compression	O
of	O
26X	O
with	O
SSD512	O
on	O
GermanTraffic	O
Sign	O
Detection	O
Benchmark	O
(GTSDB).	O
Additionally,	O
we	O
also	O
empiricallyshow	O
our	O
method's	O
adaptability	O
for	O
classification	O
based	O
architecture	O
VGG16	O
ondatasets	O
CIFAR	O
and	O
German	O
Traffic	B-RESEARCH_PROBLEM
Sign	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
Benchmark	O
(GTSRB)	O
achievinga	O
compression	O
rate	O
of	O
125X	O
and	O
200X	O
with	O
the	O
reduction	O
in	O
flops	O
by	O
90.50%	O
and96.6%	O
respectively	O
with	O
no	O
loss	O
of	O
accuracy.	O
In	O
addition	O
to	O
this,	O
our	O
methoddoes	O
not	O
require	O
any	O
special	O
libraries	O
or	O
hardware	O
support	O
for	O
the	O
resultingcompressed	O
models.	O

Models	O
with	O
transparent	O
inner	O
structure	O
and	O
high	O
classification	O
performance	O
are	O
required	O
to	O
reduce	O
potential	O
risk	O
and	O
provide	O
trust	O
for	O
users	O
in	O
domains	O
like	O
health	O
care,	O
finance,	O
security,	O
etc.	O
However,	O
existing	O
models	O
are	O
hard	O
to	O
simultaneously	O
satisfy	O
the	O
above	O
two	O
properties.	O
In	O
this	O
paper,	O
we	O
propose	O
a	O
new	O
hierarchical	O
rule-based	O
model	O
for	O
classification	O
tasks,	O
named	O
Concept	O
Rule	O
Sets	O
(CRS),	O
which	O
has	O
both	O
a	O
strong	O
expressive	O
ability	O
and	O
a	O
transparent	O
inner	O
structure.	O
To	O
address	O
the	O
challenge	O
of	O
efficiently	O
learning	O
the	O
non-differentiable	O
CRS	O
model,	O
we	O
propose	O
a	O
novel	O
neural	O
network	O
architecture,	O
Multilayer	O
Logical	O
Perceptron	O
(MLLP),	O
which	O
is	O
a	O
continuous	O
version	O
of	O
CRS.	O
Using	O
MLLP	O
and	O
the	O
Random	O
Binarization	S-RESEARCH_PROBLEM
(RB)	O
method	O
we	O
proposed,	O
we	O
can	O
search	O
the	O
discrete	O
solution	O
of	O
CRS	O
in	O
continuous	O
space	O
using	O
gradient	O
descent	O
and	O
ensure	O
the	O
discrete	O
CRS	O
acts	O
almost	O
the	O
same	O
as	O
the	O
corresponding	O
continuous	O
MLLP.	O
Experiments	O
on	O
12	O
public	O
data	O
sets	O
show	O
that	O
CRS	O
outperforms	O
the	O
state-of-the-art	O
approaches	O
and	O
the	O
complexity	O
of	O
the	O
learned	O
CRS	O
is	O
close	O
to	O
the	O
simple	O
decision	O
tree.	O
Source	O
code	O
is	O
available	O
at	O
https://github.com/12wang3/mllp.	O

Federated	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(FL)	O
is	O
a	O
privacy-protected	O
machine	O
learning	O
paradigm	O
that	O
allows	O
model	O
to	O
be	O
trained	O
directly	O
at	O
the	O
edge	O
without	O
uploading	O
data.	O
One	O
of	O
the	O
biggest	O
challenges	O
faced	O
by	O
FL	O
in	O
practical	O
applications	O
is	O
the	O
heterogeneity	O
of	O
edge	O
node	O
data,	O
which	O
will	O
slow	O
down	O
the	O
convergence	O
speed	O
and	O
degrade	O
the	O
performance	O
of	O
the	O
model.	O
For	O
the	O
above	O
problems,	O
a	O
representative	O
solution	O
is	O
to	O
add	O
additional	O
constraints	O
in	O
the	O
local	O
training,	O
such	O
as	O
FedProx,	O
FedCurv	O
and	O
FedCL.	O
However,	O
the	O
above	O
algorithms	O
still	O
have	O
room	O
for	O
improvement.	O
We	O
propose	O
to	O
use	O
the	O
aggregation	O
of	O
all	O
models	O
obtained	O
in	O
the	O
past	O
as	O
new	O
constraint	O
target	O
to	O
further	O
improve	O
the	O
performance	O
of	O
such	O
algorithms.	O
Experiments	O
in	O
various	O
settings	O
demonstrate	O
that	O
our	O
method	O
significantly	O
improves	O
the	O
convergence	O
speed	O
and	O
performance	O
of	O
the	O
model.	O

Ordinal	O
Classification	S-RESEARCH_PROBLEM
(OC)	O
is	O
an	O
important	O
classification	O
task	O
where	O
the	O
classes	O
are	O
ordinal.	O
For	O
example,	O
an	O
OC	O
task	O
for	O
sentiment	O
analysis	O
could	O
have	O
the	O
following	O
classes:	O
highly	O
positive,	O
positive,	O
neutral,	O
negative,	O
highly	O
negative.	O
Clearly,	O
evaluation	O
measures	O
for	O
an	O
OC	O
task	O
should	O
penalise	O
misclassifications	O
by	O
considering	O
the	O
ordinal	O
nature	O
of	O
the	O
classes.	O
Ordinal	O
Quantification	O
(OQ)	O
is	O
a	O
related	O
task	O
where	O
the	O
gold	O
data	O
is	O
a	O
distribution	O
over	O
ordinal	O
classes,	O
and	O
the	O
system	O
is	O
required	O
to	O
estimate	O
this	O
distribution.	O
Evaluation	O
measures	O
for	O
an	O
OQ	O
task	O
should	O
also	O
take	O
the	O
ordinal	O
nature	O
of	O
the	O
classes	O
into	O
account.	O
However,	O
for	O
both	O
OC	O
and	O
OQ,	O
there	O
are	O
only	O
a	O
small	O
number	O
of	O
known	O
evaluation	O
measures	O
that	O
meet	O
this	O
basic	O
requirement.	O
In	O
the	O
present	O
study,	O
we	O
utilise	O
data	O
from	O
the	O
SemEval	O
and	O
NTCIR	O
communities	O
to	O
clarify	O
the	O
properties	O
of	O
nine	O
evaluation	O
measures	O
in	O
the	O
context	O
of	O
OC	O
tasks,	O
and	O
six	O
measures	O
in	O
the	O
context	O
of	O
OQ	O
tasks.	O

With	O
the	O
aim	O
of	O
promoting	O
and	O
understanding	O
the	O
multilingual	O
version	O
of	O
image	O
search,	O
we	O
leverage	O
visual	O
object	O
detection	O
and	O
propose	O
a	O
model	O
with	O
diverse	O
multi-head	O
attention	O
to	O
learn	O
grounded	O
multilingual	O
multimodal	O
representations.	O
Specifically,	O
our	O
model	O
attends	O
to	O
different	O
types	O
of	O
textual	O
semantics	O
in	O
two	O
languages	O
and	O
visual	O
objects	O
for	O
fine-grained	O
alignments	O
between	O
sentences	O
and	O
images.	O
We	O
introduce	O
a	O
new	O
objective	O
function	O
which	O
explicitly	O
encourages	O
attention	O
diversity	O
to	O
learn	O
an	O
improved	O
visual-semantic	O
embedding	O
space.	O
We	O
evaluate	O
our	O
model	O
in	O
the	O
German-Image	O
and	O
English-Image	O
matching	O
tasks	O
on	O
the	O
Multi30K	O
dataset,	O
and	O
in	O
the	O
Semantic	B-RESEARCH_PROBLEM
Textual	I-RESEARCH_PROBLEM
Similarity	E-RESEARCH_PROBLEM
task	O
with	O
the	O
English	O
descriptions	O
of	O
visual	O
content.	O
Results	O
show	O
that	O
our	O
model	O
yields	O
a	O
significant	O
performance	O
gain	O
over	O
other	O
methods	O
in	O
all	O
of	O
the	O
three	O
tasks.	O

Supervised	O
contour	O
detection	O
methods	O
usually	O
require	O
many	O
labeled	O
trainingimages	O
to	O
obtain	O
satisfactory	O
performance.	O
However,	O
a	O
large	O
set	O
of	O
annotateddata	O
might	O
be	O
unavailable	O
or	O
extremely	O
labor	O
intensive.	O
In	O
this	O
paper,	O
weinvestigate	O
the	O
usage	O
of	O
semi-supervised	O
learning	O
(SSL)	O
to	O
obtain	O
competitivedetection	O
accuracy	O
with	O
very	O
limited	O
training	O
data	O
(three	O
labeled	O
images).Specifically,	O
we	O
propose	O
a	O
semi-supervised	O
structured	O
ensemble	O
learningapproach	O
for	O
contour	O
detection	O
built	O
on	O
structured	O
random	O
forests	O
(SRF).	O
Toallow	O
SRF	O
to	O
be	O
applicable	O
to	O
unlabeled	O
data,	O
we	O
present	O
an	O
effective	O
sparserepresentation	O
approach	O
to	O
capture	O
inherent	O
structure	O
in	O
image	O
patches	O
byfinding	O
a	O
compact	O
and	O
discriminative	O
low-dimensional	O
subspace	O
representation	O
inan	O
unsupervised	O
manner,	O
enabling	O
the	O
incorporation	O
of	O
abundant	O
unlabeledpatches	O
with	O
their	O
estimated	O
structured	O
labels	O
to	O
help	O
SRF	O
perform	O
better	O
nodesplitting.	O
We	O
re-examine	O
the	O
role	O
of	O
sparsity	O
and	O
propose	O
a	O
novel	O
and	O
fastsparse	O
coding	O
algorithm	O
to	O
boost	O
the	O
overall	O
learning	O
efficiency.	O
To	O
the	O
bestof	O
our	O
knowledge,	O
this	O
is	O
the	O
first	O
attempt	O
to	O
apply	O
SSL	O
for	O
contour	O
detection.Extensive	O
experiments	O
on	O
the	O
BSDS500	S-RESEARCH_PROBLEM
segmentation	O
dataset	O
and	O
the	O
NYU	O
Depthdataset	O
demonstrate	O
the	O
superiority	O
of	O
the	O
proposed	O
method.	O

We	O
investigate	O
the	O
problem	O
of	O
recovering	O
a	O
partially	O
observed	O
high-rank	O
matrix	O
whose	O
columns	O
obey	O
a	O
nonlinear	O
structure	O
such	O
as	O
a	O
union	O
of	O
subspaces,	O
an	O
algebraic	O
variety	O
or	O
grouped	O
in	O
clusters.	O
The	O
recovery	O
problem	O
is	O
formulated	O
as	O
the	O
rank	O
minimization	O
of	O
a	O
nonlinear	O
feature	O
map	O
applied	O
to	O
the	O
original	O
matrix,	O
which	O
is	O
then	O
further	O
approximated	O
by	O
a	O
constrained	O
non-convex	O
optimization	O
problem	O
involving	O
the	O
Grassmann	O
manifold.	O
We	O
propose	O
two	O
sets	O
of	O
algorithms,	O
one	O
arising	O
from	O
Riemannian	B-RESEARCH_PROBLEM
optimization	E-RESEARCH_PROBLEM
and	O
the	O
other	O
as	O
an	O
alternating	O
minimization	O
scheme,	O
both	O
of	O
which	O
include	O
first-	O
and	O
second-order	O
variants.	O
Both	O
sets	O
of	O
algorithms	O
have	O
theoretical	O
guarantees.	O
In	O
particular,	O
for	O
the	O
alternating	O
minimization,	O
we	O
establish	O
global	O
convergence	O
and	O
worst-case	O
complexity	O
bounds.	O
Additionally,	O
using	O
the	O
Kurdyka-Lojasiewicz	O
property,	O
we	O
show	O
that	O
the	O
alternating	O
minimization	O
converges	O
to	O
a	O
unique	O
limit	O
point.	O
We	O
provide	O
extensive	O
numerical	O
results	O
for	O
the	O
recovery	O
of	O
union	O
of	O
subspaces	O
and	O
clustering	O
under	O
entry	O
sampling	O
and	O
dense	O
Gaussian	O
sampling.	O
Our	O
methods	O
are	O
competitive	O
with	O
existing	O
approaches	O
and,	O
in	O
particular,	O
high	O
accuracy	O
is	O
achieved	O
in	O
the	O
recovery	O
using	O
Riemannian	O
second-order	O
methods.	O

There	O
is	O
mounting	O
evidence	O
of	O
a	O
link	O
between	O
the	O
properties	O
ofelectroencephalograms	O
(EEG	S-RESEARCH_PROBLEM
s)	O
of	O
depressive	O
patients	O
and	O
the	O
outcome	O
ofpharmacotherapy.	O
The	O
goal	O
of	O
this	O
study	O
was	O
to	O
develop	O
an	O
EEG	S-RESEARCH_PROBLEM
biomarker	O
ofantidepressant	O
treatment	O
response	O
which	O
would	O
require	O
only	O
a	O
single	O
EEG	S-RESEARCH_PROBLEM
measurement.	O
We	O
recorded	O
resting,	O
21-channel	O
EEG	S-RESEARCH_PROBLEM
in	O
17	O
inpatients	O
sufferingfrom	O
bipolar	O
depression	O
in	O
eyes	O
closed	O
and	O
eyes	O
open	O
conditions.	O
The	O
EEG	S-RESEARCH_PROBLEM
measurement	O
was	O
performed	O
at	O
the	O
end	O
of	O
the	O
short	O
washout	O
period	O
which	O
followedpreviously	O
unsuccessful	O
pharmacotherapy.	O
We	O
calculated	O
the	O
normalized	O
waveletpower	O
of	O
alpha	O
rhythm	O
using	O
two	O
referential	O
montages	O
and	O
an	O
average	O
referencemontage.	O
In	O
particular,	O
in	O
the	O
occipital	O
(O1,	O
O2,	O
Oz)	O
channels	O
the	O
waveletpower	O
of	O
responders	O
was	O
up	O
to	O
84%	O
higher	O
than	O
that	O
of	O
nonresponders.	O
Using	O
anovel	O
classification	O
algorithm	O
we	O
were	O
able	O
to	O
correctly	O
predict	O
the	O
outcome	O
oftreatment	O
with	O
90%	O
sensitivity	O
and	O
100%	O
specificity.	O
The	O
proposed	O
biomarkerrequires	O
only	O
a	O
single	O
EEG	S-RESEARCH_PROBLEM
measurement	O
and	O
consequently	O
is	O
intrinsicallydifferent	O
from	O
biomarkers	O
which	O
exploit	O
the	O
changes	O
in	O
prefrontal	O
EEG	S-RESEARCH_PROBLEM
inducedby	O
pharmacotherapy	O
over	O
a	O
given	O
time.	O

Classification	S-RESEARCH_PROBLEM
of	O
partially	O
occluded	O
images	O
is	O
a	O
highly	O
challenging	O
computer	O
vision	O
problem	O
even	O
for	O
the	O
cutting	O
edge	O
deep	O
learning	O
technologies.	O
To	O
achieve	O
a	O
robust	O
image	O
classification	O
for	O
occluded	O
images,	O
this	O
paper	O
proposes	O
a	O
novel	O
scheme	O
using	O
subspace	O
decomposition	O
based	O
estimation	O
(SDBE).	O
The	O
proposed	O
SDBE-based	O
classification	O
scheme	O
first	O
employs	O
a	O
base	O
convolutional	O
neural	O
network	O
to	O
extract	O
the	O
deep	O
feature	O
vector	O
(DFV)	O
and	O
then	O
utilizes	O
the	O
SDBE	O
to	O
compute	O
the	O
DFV	O
of	O
the	O
original	O
occlusion-free	O
image	O
for	O
classification.	O
The	O
SDBE	O
is	O
performed	O
by	O
projecting	O
the	O
DFV	O
of	O
the	O
occluded	O
image	O
onto	O
the	O
linear	O
span	O
of	O
a	O
class	O
dictionary	O
(CD)	O
along	O
the	O
linear	O
span	O
of	O
an	O
occlusion	O
error	O
dictionary	O
(OED).	O
The	O
CD	O
and	O
OED	O
are	O
constructed	O
respectively	O
by	O
concatenating	O
the	O
DFVs	O
of	O
a	O
training	O
set	O
and	O
the	O
occlusion	O
error	O
vectors	O
of	O
an	O
extra	O
set	O
of	O
image	O
pairs.	O
Two	O
implementations	O
of	O
the	O
SDBE	O
are	O
studied	O
in	O
this	O
paper:	O
the	O
$l_1$-norm	O
and	O
the	O
squared	O
$l_2$-norm	O
regularized	O
least-squares	O
estimates.	O
By	O
employing	O
the	O
ResNet-152,	O
pre-trained	O
on	O
the	O
ILSVRC2012	O
training	O
set,	O
as	O
the	O
base	O
network,	O
the	O
proposed	O
SBDE-based	O
classification	O
scheme	O
is	O
extensively	O
evaluated	O
on	O
the	O
Caltech-101	O
and	O
ILSVRC2012	O
datasets.	O
Extensive	O
experimental	O
results	O
demonstrate	O
that	O
the	O
proposed	O
SDBE-based	O
scheme	O
dramatically	O
boosts	O
the	O
classification	O
accuracy	O
for	O
occluded	O
images,	O
and	O
achieves	O
around	O
$22.25\%$	O
increase	O
in	O
classification	O
accuracy	O
under	O
$20\%$	O
occlusion	O
on	O
the	O
ILSVRC2012	O
dataset.	O

In	O
this	O
study	O
we	O
estimate	O
the	O
heart	O
rate	O
from	O
face	O
videos	O
for	O
student	O
assessment.	O
This	O
information	O
could	O
be	O
very	O
valuable	O
to	O
track	O
their	O
status	O
along	O
time	O
and	O
also	O
to	O
estimate	O
other	O
data	O
such	O
as	O
their	O
attention	O
level	O
or	O
the	O
presence	O
of	O
stress	O
that	O
may	O
be	O
caused	O
by	O
cheating	O
attempts.	O
The	O
recent	O
edBBplat,	O
a	O
platform	O
for	O
student	O
behavior	O
modelling	O
in	O
remote	O
education,	O
is	O
considered	O
in	O
this	O
study1.	O
This	O
platform	O
permits	O
to	O
capture	O
several	O
signals	O
from	O
a	O
set	O
of	O
sensors	O
that	O
capture	O
biometric	O
and	O
behavioral	O
data:	O
RGB	O
and	O
near	O
infrared	O
cameras,	O
microphone,	O
EEG	S-RESEARCH_PROBLEM
band,	O
mouse,	O
smartwatch,	O
and	O
keyboard,	O
among	O
others.	O
In	O
the	O
experimental	O
framework	O
of	O
this	O
study,	O
we	O
focus	O
on	O
the	O
RGB	O
and	O
near-infrared	O
video	O
sequences	O
for	O
performing	O
heart	O
rate	O
estimation	O
applying	O
remote	O
photoplethysmography	O
techniques.	O
The	O
experiments	O
include	O
behavioral	O
and	O
physiological	O
data	O
from	O
25	O
different	O
students	O
completing	O
a	O
collection	O
of	O
tasks	O
related	O
to	O
e-learning.	O
Our	O
proposed	O
face	O
heart	O
rate	O
estimation	O
approach	O
is	O
compared	O
with	O
the	O
heart	O
rate	O
provided	O
by	O
the	O
smartwatch,	O
achieving	O
very	O
promising	O
results	O
for	O
its	O
future	O
deployment	O
in	O
e-learning	O
applications.	O

Communication	O
complexity	O
and	O
privacy	O
are	O
the	O
two	O
key	O
challenges	O
in	O
Federated	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
where	O
the	O
goal	O
is	O
to	O
perform	O
a	O
distributed	O
learning	O
through	O
a	O
large	O
volume	O
of	O
devices.	O
In	O
this	O
work,	O
we	O
introduce	O
FedSKETCH	O
and	O
FedSKETCHGATE	O
algorithms	O
to	O
address	O
both	O
challenges	O
in	O
Federated	O
learning	O
jointly,	O
where	O
these	O
algorithms	O
are	O
intended	O
to	O
be	O
used	O
for	O
homogeneous	O
and	O
heterogeneous	O
data	O
distribution	O
settings	O
respectively.	O
The	O
key	O
idea	O
is	O
to	O
compress	O
the	O
accumulation	O
of	O
local	O
gradients	O
using	O
count	O
sketch,	O
therefore,	O
the	O
server	O
does	O
not	O
have	O
access	O
to	O
the	O
gradients	O
themselves	O
which	O
provides	O
privacy.	O
Furthermore,	O
due	O
to	O
the	O
lower	O
dimension	O
of	O
sketching	O
used,	O
our	O
method	O
exhibits	O
communication-efficiency	O
property	O
as	O
well.	O
We	O
provide,	O
for	O
the	O
aforementioned	O
schemes,	O
sharp	O
convergence	O
guarantees.	O
Finally,	O
we	O
back	O
up	O
our	O
theory	O
with	O
various	O
set	O
of	O
experiments.	O

Predicting	O
the	O
future	O
motion	O
of	O
vehicles	O
has	O
been	O
studied	O
using	O
various	O
techniques,	O
including	O
stochastic	O
policies,	O
generative	O
models,	O
and	O
regression.	O
Recent	O
work	O
has	O
shown	O
that	O
classification	O
over	O
a	O
trajectory	O
set,	O
which	O
approximates	O
possible	O
motions,	O
achieves	O
state-of-the-art	O
performance	O
and	O
avoids	O
issues	O
like	O
mode	O
collapse.	O
However,	O
map	O
information	O
and	O
the	O
physical	O
relationships	O
between	O
nearby	O
trajectories	O
is	O
not	O
fully	O
exploited	O
in	O
this	O
formulation.	O
We	O
build	O
on	O
classification-based	O
approaches	O
to	O
motion	B-RESEARCH_PROBLEM
prediction	E-RESEARCH_PROBLEM
by	O
adding	O
an	O
auxiliary	O
loss	O
that	O
penalizes	O
off-road	O
predictions.	O
This	O
auxiliary	O
loss	O
can	O
easily	O
be	O
pretrained	O
using	O
only	O
map	O
information	O
(e.g.,	O
off-road	O
area),	O
which	O
significantly	O
improves	O
performance	O
on	O
small	O
datasets.	O
We	O
also	O
investigate	O
weighted	O
cross-entropy	O
losses	O
to	O
capture	O
spatial-temporal	O
relationships	O
among	O
trajectories.	O
Our	O
final	O
contribution	O
is	O
a	O
detailed	O
comparison	O
of	O
classification	O
and	O
ordinal	O
regression	O
on	O
two	O
public	O
self-driving	O
datasets.	O

We	O
study	O
the	O
problem	O
of	O
named	O
entity	O
recognition	O
(NER	S-RESEARCH_PROBLEM
)	O
from	O
electronicmedical	O
records,	O
which	O
is	O
one	O
of	O
the	O
most	O
fundamental	O
and	O
critical	O
problems	O
formedical	O
text	O
mining.	O
Medical	O
records	O
which	O
are	O
written	O
by	O
clinicians	O
fromdifferent	O
specialties	O
usually	O
contain	O
quite	O
different	O
terminologies	O
and	O
writingstyles.	O
The	O
difference	O
of	O
specialties	O
and	O
the	O
cost	O
of	O
human	O
annotation	O
makes	O
itparticularly	O
difficult	O
to	O
train	O
a	O
universal	O
medical	O
NER	S-RESEARCH_PROBLEM
system.	O
In	O
this	O
paper,we	O
propose	O
a	O
label-aware	O
double	O
transfer	O
learning	O
framework	O
(La-DTL)	O
forcross-specialty	O
NER	S-RESEARCH_PROBLEM
,	O
so	O
that	O
a	O
medical	O
NER	S-RESEARCH_PROBLEM
system	O
designed	O
for	O
one	O
specialtycould	O
be	O
conveniently	O
applied	O
to	O
another	O
one	O
with	O
minimal	O
annotation	O
efforts.The	O
transferability	O
is	O
guaranteed	O
by	O
two	O
components:	O
(i)	O
we	O
propose	O
label-awareMMD	O
for	O
feature	O
representation	O
transfer,	O
and	O
(ii)	O
we	O
perform	O
parameter	O
transferwith	O
a	O
theoretical	O
upper	O
bound	O
which	O
is	O
also	O
label	O
aware.	O
We	O
conduct	O
extensiveexperiments	O
on	O
12	O
cross-specialty	O
NER	S-RESEARCH_PROBLEM
tasks.	O
The	O
experimental	O
resultsdemonstrate	O
that	O
La-DTL	O
provides	O
consistent	O
accuracy	O
improvement	O
over	O
strongbaselines.	O
Besides,	O
the	O
promising	O
experimental	O
results	O
on	O
non-medical	O
NER	S-RESEARCH_PROBLEM
scenarios	O
indicate	O
that	O
La-DTL	O
is	O
potential	O
to	O
be	O
seamlessly	O
adapted	O
to	O
a	O
widerange	O
of	O
NER	S-RESEARCH_PROBLEM
tasks.	O

In	O
Autonomous	B-RESEARCH_PROBLEM
Driving	E-RESEARCH_PROBLEM
(AD)	O
systems,	O
perception	O
is	O
both	O
security	O
and	O
safety	O
critical.	O
Despite	O
various	O
prior	O
studies	O
on	O
its	O
security	O
issues,	O
all	O
of	O
them	O
only	O
consider	O
attacks	O
on	O
camera-	O
or	O
LiDAR-based	O
AD	O
perception	O
alone.	O
However,	O
production	O
AD	O
systems	O
today	O
predominantly	O
adopt	O
a	O
Multi-Sensor	O
Fusion	O
(MSF)	O
based	O
design,	O
which	O
in	O
principle	O
can	O
be	O
more	O
robust	O
against	O
these	O
attacks	O
under	O
the	O
assumption	O
that	O
not	O
all	O
fusion	O
sources	O
are	O
(or	O
can	O
be)	O
attacked	O
at	O
the	O
same	O
time.	O
In	O
this	O
paper,	O
we	O
present	O
the	O
first	O
study	O
of	O
security	O
issues	O
of	O
MSF-based	O
perception	O
in	O
AD	O
systems.	O
We	O
directly	O
challenge	O
the	O
basic	O
MSF	O
design	O
assumption	O
above	O
by	O
exploring	O
the	O
possibility	O
of	O
attacking	O
all	O
fusion	O
sources	O
simultaneously.	O
This	O
allows	O
us	O
for	O
the	O
first	O
time	O
to	O
understand	O
how	O
much	O
security	O
guarantee	O
MSF	O
can	O
fundamentally	O
provide	O
as	O
a	O
general	O
defense	O
strategy	O
for	O
AD	O
perception.	O
We	O
formulate	O
the	O
attack	O
as	O
an	O
optimization	O
problem	O
to	O
generate	O
a	O
physically-realizable,	O
adversarial	O
3D-printed	O
object	O
that	O
misleads	O
an	O
AD	O
system	O
to	O
fail	O
in	O
detecting	O
it	O
and	O
thus	O
crash	O
into	O
it.	O
We	O
propose	O
a	O
novel	O
attack	O
pipeline	O
that	O
addresses	O
two	O
main	O
design	O
challenges:	O
(1)	O
non-differentiable	O
target	O
camera	O
and	O
LiDAR	O
sensing	O
systems,	O
and	O
(2)	O
non-differentiable	O
cell-level	O
aggregated	O
features	O
popularly	O
used	O
in	O
LiDAR-based	O
AD	O
perception.	O
We	O
evaluate	O
our	O
attack	O
on	O
MSF	O
included	O
in	O
representative	O
open-source	O
industry-grade	O
AD	O
systems	O
in	O
real-world	O
driving	O
scenarios.	O
Our	O
results	O
show	O
that	O
the	O
attack	O
achieves	O
over	O
90%	O
success	O
rate	O
across	O
different	O
object	O
types	O
and	O
MSF.	O
Our	O
attack	O
is	O
also	O
found	O
stealthy,	O
robust	O
to	O
victim	O
positions,	O
transferable	O
across	O
MSF	O
algorithms,	O
and	O
physical-world	O
realizable	O
after	O
being	O
3D-printed	O
and	O
captured	O
by	O
LiDAR	O
and	O
camera	O
devices.	O
To	O
concretely	O
assess	O
the	O
end-to-end	O
safety	O
impact,	O
we	O
further	O
perform	O
simulation	O
evaluation	O
and	O
show	O
that	O
it	O
can	O
cause	O
a	O
100%	O
vehicle	O
collision	O
rate	O
for	O
an	O
industry-grade	O
AD	O
system.	O

Ultrasound	O
(US)	O
is	O
a	O
non-invasive	O
yet	O
effective	O
medical	O
diagnostic	O
imaging	O
technique	O
for	O
the	O
COVID-19	O
global	O
pandemic.	O
However,	O
due	O
to	O
complex	O
feature	O
behaviors	O
and	O
expensive	O
annotations	O
of	O
US	O
images,	O
it	O
is	O
difficult	O
to	O
apply	O
Artificial	O
Intelligence	O
(AI)	O
assisting	O
approaches	O
for	O
lung's	O
multi-symptom	O
(multi-label)	O
classification.	O
To	O
overcome	O
these	O
difficulties,	O
we	O
propose	O
a	O
novel	O
semi-supervised	O
Two-Stream	O
Active	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(TSAL)	O
method	O
to	O
model	O
complicated	O
features	O
and	O
reduce	O
labeling	O
costs	O
in	O
an	O
iterative	O
procedure.	O
The	O
core	O
component	O
of	O
TSAL	O
is	O
the	O
multi-label	O
learning	O
mechanism,	O
in	O
which	O
label	O
correlations	O
information	O
is	O
used	O
to	O
design	O
multi-label	O
margin	O
(MLM)	O
strategy	O
and	O
confidence	O
validation	O
for	O
automatically	O
selecting	O
informative	O
samples	O
and	O
confident	O
labels.	O
On	O
this	O
basis,	O
a	O
multi-symptom	O
multi-label	O
(MSML)	O
classification	O
network	O
is	O
proposed	O
to	O
learn	O
discriminative	O
features	O
of	O
lung	O
symptoms,	O
and	O
a	O
human-machine	O
interaction	O
is	O
exploited	O
to	O
confirm	O
the	O
final	O
annotations	O
that	O
are	O
used	O
to	O
fine-tune	O
MSML	O
with	O
progressively	O
labeled	O
data.	O
Moreover,	O
a	O
novel	O
lung	O
US	O
dataset	O
named	O
COVID19-LUSMS	O
is	O
built,	O
currently	O
containing	O
71	O
clinical	O
patients	O
with	O
6,836	O
images	O
sampled	O
from	O
678	O
videos.	O
Experimental	O
evaluations	O
show	O
that	O
TSAL	O
using	O
only	O
20%	O
data	O
can	O
achieve	O
superior	O
performance	O
to	O
the	O
baseline	O
and	O
the	O
state-of-the-art.	O
Qualitatively,	O
visualization	O
of	O
both	O
attention	O
map	O
and	O
sample	O
distribution	O
confirms	O
the	O
good	O
consistency	O
with	O
the	O
clinic	O
knowledge.	O

Envisioning	O
a	O
new	O
imaginative	O
idea	O
together	O
is	O
a	O
popular	O
human	O
need.	O
Imagining	O
together	O
as	O
a	O
team	O
can	O
often	O
lead	O
to	O
breakthrough	O
ideas,	O
but	O
the	O
collaboration	O
effort	O
can	O
also	O
be	O
challenging,	O
especially	O
when	O
the	O
team	O
members	O
are	O
separated	O
by	O
time	O
and	O
space.	O
What	O
if	O
there	O
is	O
a	O
AI	O
that	O
can	O
assist	O
the	O
team	O
to	O
collaboratively	O
envision	O
new	O
ideas?.	O
Is	O
it	O
possible	O
to	O
develop	O
a	O
working	O
model	O
of	O
such	O
an	O
AI?	O
This	O
paper	O
aims	O
to	O
design	O
such	O
an	O
intelligence.	O
This	O
paper	O
proposes	O
a	O
approach	O
to	O
design	O
a	O
creative	O
and	O
collaborative	O
intelligence	O
by	O
employing	O
a	O
form	O
of	O
distributed	O
machine	O
learning	O
approach	O
called	O
Federated	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
along	O
with	O
fusion	O
on	O
Generative	O
Adversarial	O
Networks,	O
GAN.	O
This	O
collaborative	O
creative	O
AI	O
presents	O
a	O
new	O
paradigm	O
in	O
AI,	O
one	O
that	O
lets	O
a	O
team	O
of	O
two	O
or	O
more	O
to	O
come	O
together	O
to	O
imagine	O
and	O
envision	O
ideas	O
that	O
synergies	O
well	O
with	O
interests	O
of	O
all	O
members	O
of	O
the	O
team.	O
In	O
short,	O
this	O
paper	O
explores	O
the	O
design	O
of	O
a	O
novel	O
type	O
of	O
AI	O
paradigm,	O
called	O
Federated	O
AI	O
Imagination,	O
one	O
that	O
lets	O
geographically	O
distributed	O
teams	O
to	O
collaboratively	O
imagine.	O

Latest	O
insights	O
from	O
biology	O
show	O
that	O
intelligence	O
does	O
not	O
only	O
emerge	O
from	O
the	O
connections	O
between	O
the	O
neurons,	O
but	O
that	O
individual	O
neurons	O
shoulder	O
more	O
computational	O
responsibility.	O
Current	O
Neural	O
Network	O
architecture	O
design	O
and	O
search	O
are	O
biased	O
on	O
fixed	O
activation	O
functions.	O
Using	O
more	O
advanced	O
learnable	O
activation	O
functions	O
provide	O
Neural	O
Networks	O
with	O
higher	O
learning	O
capacity.	O
However,	O
general	O
guidance	O
for	O
building	O
such	O
networks	O
is	O
still	O
missing.	O
In	O
this	O
work,	O
we	O
first	O
explain	O
why	O
rationals	O
offer	O
an	O
optimal	O
choice	O
for	O
activation	O
functions.	O
We	O
then	O
show	O
that	O
they	O
are	O
closed	O
under	O
residual	O
connections,	O
and	O
inspired	O
by	O
recurrence	O
for	O
residual	O
networks	O
we	O
derive	O
a	O
self-regularized	O
version	O
of	O
Rationals:	O
Recurrent	O
Rationals.	O
We	O
demonstrate	O
that	O
(Recurrent)	O
Rational	O
Networks	O
lead	O
to	O
high	O
performance	O
improvements	O
on	O
Image	B-RESEARCH_PROBLEM
Classification	E-RESEARCH_PROBLEM
and	O
Deep	O
Reinforcement	O
Learning.	O

Quantization	S-RESEARCH_PROBLEM
techniques	O
can	O
reduce	O
the	O
size	O
of	O
Deep	O
Neural	O
Networks	O
and	O
improve	O
inference	O
latency	O
and	O
throughput	O
by	O
taking	O
advantage	O
of	O
high	O
throughput	O
integer	O
instructions.	O
In	O
this	O
paper	O
we	O
review	O
the	O
mathematical	O
aspects	O
of	O
quantization	O
parameters	O
and	O
evaluate	O
their	O
choices	O
on	O
a	O
wide	O
range	O
of	O
neural	O
network	O
models	O
for	O
different	O
application	O
domains,	O
including	O
vision,	O
speech,	O
and	O
language.	O
We	O
focus	O
on	O
quantization	O
techniques	O
that	O
are	O
amenable	O
to	O
acceleration	O
by	O
processors	O
with	O
high-throughput	O
integer	O
math	O
pipelines.	O
We	O
also	O
present	O
a	O
workflow	O
for	O
8-bit	O
quantization	O
that	O
is	O
able	O
to	O
maintain	O
accuracy	O
within	O
1%	O
of	O
the	O
floating-point	O
baseline	O
on	O
all	O
networks	O
studied,	O
including	O
models	O
that	O
are	O
more	O
difficult	O
to	O
quantize,	O
such	O
as	O
MobileNets	O
and	O
BERT-large.	O

Causal	O
discovery,	O
i.e.,	O
inferring	O
underlying	O
cause-effect	O
relationships	O
from	O
observations	O
of	O
a	O
scene	O
or	O
system,	O
is	O
an	O
inherent	O
mechanism	O
in	O
human	O
cognition,	O
but	O
has	O
been	O
shown	O
to	O
be	O
highly	O
challenging	O
to	O
automate.	O
The	O
majority	O
of	O
approaches	O
in	O
the	O
literature	O
aiming	O
for	O
this	O
task	O
consider	O
constrained	O
scenarios	O
with	O
fully	O
observed	O
variables	O
or	O
data	O
from	O
stationary	O
time-series.	O
In	O
this	O
work	O
we	O
aim	O
for	O
causal	O
discovery	O
in	O
a	O
more	O
general	O
class	O
of	O
scenarios,	O
scenes	O
with	O
non-stationary	O
behavior	O
over	O
time.	O
For	O
our	O
purposes	O
we	O
here	O
regard	O
a	O
scene	O
as	O
a	O
composition	O
objects	O
interacting	O
with	O
each	O
other	O
over	O
time.	O
Non-stationarity	O
is	O
modeled	O
as	O
stationarity	O
conditioned	O
on	O
an	O
underlying	O
variable,	O
a	O
state,	O
which	O
can	O
be	O
of	O
varying	O
dimension,	O
more	O
or	O
less	O
hidden	O
given	O
observations	O
of	O
the	O
scene,	O
and	O
also	O
depend	O
more	O
or	O
less	O
directly	O
on	O
these	O
observations.	O
We	O
propose	O
a	O
probabilistic	O
deep	O
learning	O
approach	O
called	O
State-Dependent	O
Causal	B-RESEARCH_PROBLEM
Inference	E-RESEARCH_PROBLEM
(SDCI)	O
for	O
causal	O
discovery	O
in	O
such	O
conditionally	O
stationary	O
time-series	O
data.	O
Results	O
in	O
two	O
different	O
synthetic	O
scenarios	O
show	O
that	O
this	O
method	O
is	O
able	O
to	O
recover	O
the	O
underlying	O
causal	O
dependencies	O
with	O
high	O
accuracy	O
even	O
in	O
cases	O
with	O
hidden	O
states.	O

In	O
various	O
cases	O
of	O
decision	O
analysis	O
we	O
use	O
two	O
popular	O
methods:	O
Analytical	O
Hierarchical	O
Process	O
(AHP)	O
and	O
Fuzzy	O
based	O
AHP	O
or	O
Fuzzy	O
AHP.	O
Both	O
the	O
methods	O
deal	O
with	O
stochastic	O
data	O
and	O
can	O
determine	O
decision	O
result	O
through	O
Multi	O
Criteria	O
Decision	B-RESEARCH_PROBLEM
Making	E-RESEARCH_PROBLEM
(MCDM)	O
process.	O
Obviously	O
resulting	O
values	O
of	O
the	O
two	O
methods	O
are	O
not	O
same	O
though	O
same	O
set	O
of	O
data	O
is	O
fed	O
into	O
them.	O
In	O
this	O
research	O
work,	O
we	O
have	O
tried	O
to	O
observe	O
similarities	O
and	O
dissimilarities	O
between	O
two	O
methods	O
outputs.	O
Almost	O
same	O
trend	O
or	O
fluctuations	O
in	O
outputs	O
have	O
been	O
seen	O
for	O
both	O
methods	O
for	O
same	O
set	O
of	O
input	O
data	O
which	O
are	O
not	O
consistent.	O
Both	O
method	O
outputs	O
ups	O
and	O
down	O
fluctuations	O
are	O
same	O
for	O
fifty	O
percent	O
cases.	O

Deep	O
Gaussian	B-RESEARCH_PROBLEM
Processes	E-RESEARCH_PROBLEM
(DGPs)	O
were	O
proposed	O
as	O
an	O
expressive	O
Bayesian	O
model	O
capable	O
of	O
a	O
mathematically	O
grounded	O
estimation	O
of	O
uncertainty.	O
The	O
expressivity	O
of	O
DPGs	O
results	O
from	O
not	O
only	O
the	O
compositional	O
character	O
but	O
the	O
distribution	O
propagation	O
within	O
the	O
hierarchy.	O
Recently,	O
[1]	O
pointed	O
out	O
that	O
the	O
hierarchical	O
structure	O
of	O
DGP	O
well	O
suited	O
modeling	O
the	O
multi-fidelity	O
regression,	O
in	O
which	O
one	O
is	O
provided	O
sparse	O
observations	O
with	O
high	O
precision	O
and	O
plenty	O
of	O
low	O
fidelity	O
observations.	O
We	O
propose	O
the	O
conditional	O
DGP	O
model	O
in	O
which	O
the	O
latent	O
GPs	O
are	O
directly	O
supported	O
by	O
the	O
fixed	O
lower	O
fidelity	O
data.	O
Then	O
the	O
moment	O
matching	O
method	O
in	O
[2]	O
is	O
applied	O
to	O
approximate	O
the	O
marginal	O
prior	O
of	O
conditional	O
DGP	O
with	O
a	O
GP.	O
The	O
obtained	O
effective	O
kernels	O
are	O
implicit	O
functions	O
of	O
the	O
lower-fidelity	O
data,	O
manifesting	O
the	O
expressivity	O
contributed	O
by	O
distribution	O
propagation	O
within	O
the	O
hierarchy.	O
The	O
hyperparameters	O
are	O
learned	O
via	O
optimizing	O
the	O
approximate	O
marginal	O
likelihood.	O
Experiments	O
with	O
synthetic	O
and	O
high	O
dimensional	O
data	O
show	O
comparable	O
performance	O
against	O
other	O
multi-fidelity	O
regression	O
methods,	O
variational	O
inference,	O
and	O
multi-output	O
GP.	O
We	O
conclude	O
that,	O
with	O
the	O
low	O
fidelity	O
data	O
and	O
the	O
hierarchical	O
DGP	O
structure,	O
the	O
effective	O
kernel	O
encodes	O
the	O
inductive	O
bias	O
for	O
true	O
function	O
allowing	O
the	O
compositional	O
freedom	O
discussed	O
in	O
[3,4].	O

Translation	S-RESEARCH_PROBLEM
is	O
a	O
central	O
biological	O
process	O
by	O
which	O
proteins	O
are	O
synthesizedfrom	O
genetic	O
information	O
contained	O
within	O
mRNAs.	O
Here	O
we	O
study	O
the	O
kinetics	O
oftranslation	O
at	O
molecular	O
level	O
through	O
a	O
stochastic	O
simulation	O
model.	O
The	O
modelexplicitly	O
include	O
RNA	O
sequences,	O
ribosome	O
dynamics,	O
tRNA	O
pool	O
and	O
biochemicalreactions	O
in	O
the	O
translation	O
elongation.	O
The	O
results	O
show	O
that	O
the	O
translationefficiency	O
is	O
mainly	O
limited	O
by	O
the	O
available	O
ribosome	O
number,	O
translationinitiation	O
and	O
the	O
translation	O
elongation	O
time.	O
The	O
elongation	O
time	O
islog-normal	O
distribution	O
with	O
mean	O
and	O
variance	O
determined	O
by	O
both	O
the	O
codonsaturation	O
and	O
the	O
process	O
of	O
aa-tRNA	O
selection	O
at	O
each	O
codon	O
binding.Moreover,	O
our	O
simulations	O
show	O
that	O
the	O
translation	O
accuracy	O
exponentiallydecreases	O
with	O
the	O
sequence	O
length.	O
These	O
results	O
suggest	O
that	O
aa-tRNAcompetition	O
is	O
crucial	O
for	O
both	O
translation	O
elongation,	O
translation	O
efficiencyand	O
the	O
accuracy,	O
which	O
in	O
turn	O
determined	O
the	O
effective	O
protein	O
productionrate	O
of	O
correct	O
proteins.	O
Our	O
results	O
improve	O
the	O
dynamical	O
equation	O
of	O
proteinproduction	O
with	O
a	O
delay	O
differential	O
equation	O
which	O
is	O
dependent	O
on	O
sequenceinformations	O
through	O
both	O
the	O
effective	O
production	O
rate	O
and	O
the	O
distribution	O
ofelongation	O
time.	O

Image	O
classification	O
has	O
always	O
been	O
a	O
hot	O
and	O
challenging	O
task.	O
This	O
paper	O
is	O
a	O
brief	O
report	O
to	O
our	O
submission	O
to	O
the	O
VIPriors	O
Image	B-RESEARCH_PROBLEM
Classification	E-RESEARCH_PROBLEM
Challenge.	O
In	O
this	O
challenge,	O
the	O
difficulty	O
is	O
how	O
to	O
train	O
the	O
model	O
from	O
scratch	O
without	O
any	O
pretrained	O
weight.	O
In	O
our	O
method,	O
several	O
strong	O
backbones	O
and	O
multiple	O
loss	O
functions	O
are	O
used	O
to	O
learn	O
more	O
representative	O
features.	O
To	O
improve	O
the	O
models'	O
generalization	O
and	O
robustness,	O
efficient	O
image	O
augmentation	O
strategies	O
are	O
utilized,	O
like	O
autoaugment	O
and	O
cutmix.	O
Finally,	O
ensemble	O
learning	O
is	O
used	O
to	O
increase	O
the	O
performance	O
of	O
the	O
models.	O
The	O
final	O
Top-1	O
accuracy	O
of	O
our	O
team	O
DeepBlueAI	O
is	O
0.7015,	O
ranking	O
second	O
in	O
the	O
leaderboard.	O

Weakly	B-RESEARCH_PROBLEM
Supervised	I-RESEARCH_PROBLEM
Object	I-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
(WSOD)	O
has	O
emerged	O
as	O
an	O
effective	O
tool	O
to	O
train	O
object	O
detectors	O
using	O
only	O
the	O
image-level	O
category	O
labels.	O
However,	O
without	O
object-level	O
labels,	O
WSOD	O
detectors	O
are	O
prone	O
to	O
detect	O
bounding	O
boxes	O
on	O
salient	O
objects,	O
clustered	O
objects	O
and	O
discriminative	O
object	O
parts.	O
Moreover,	O
the	O
image-level	O
category	O
labels	O
do	O
not	O
enforce	O
consistent	O
object	O
detection	O
across	O
different	O
transformations	O
of	O
the	O
same	O
images.	O
To	O
address	O
the	O
above	O
issues,	O
we	O
propose	O
a	O
Comprehensive	O
Attention	O
Self-Distillation	O
(CASD)	O
training	O
approach	O
for	O
WSOD.	O
To	O
balance	O
feature	O
learning	O
among	O
all	O
object	O
instances,	O
CASD	O
computes	O
the	O
comprehensive	O
attention	O
aggregated	O
from	O
multiple	O
transformations	O
and	O
feature	O
layers	O
of	O
the	O
same	O
images.	O
To	O
enforce	O
consistent	O
spatial	O
supervision	O
on	O
objects,	O
CASD	O
conducts	O
self-distillation	O
on	O
the	O
WSOD	O
networks,	O
such	O
that	O
the	O
comprehensive	O
attention	O
is	O
approximated	O
simultaneously	O
by	O
multiple	O
transformations	O
and	O
feature	O
layers	O
of	O
the	O
same	O
images.	O
CASD	O
produces	O
new	O
state-of-the-art	O
WSOD	O
results	O
on	O
standard	O
benchmarks	O
such	O
as	O
PASCAL	O
VOC	O
2007/2012	O
and	O
MS-COCO.	O

This	O
paper	O
describes	O
SalamNET,	O
an	O
Arabic	O
offensive	O
language	O
detection	O
system	O
that	O
has	O
been	O
submitted	O
to	O
SemEval	O
2020	O
shared	O
task	O
12:	O
Multilingual	O
Offensive	O
Language	B-RESEARCH_PROBLEM
Identification	E-RESEARCH_PROBLEM
in	O
Social	O
Media.	O
Our	O
approach	O
focuses	O
on	O
applying	O
multiple	O
deep	O
learning	O
models	O
and	O
conducting	O
in	O
depth	O
error	O
analysis	O
of	O
results	O
to	O
provide	O
system	O
implications	O
for	O
future	O
development	O
considerations.	O
To	O
pursue	O
our	O
goal,	O
a	O
Recurrent	O
Neural	O
Network	O
(RNN),	O
a	O
Gated	O
Recurrent	O
Unit	O
(GRU),	O
and	O
Long-Short	O
Term	O
Memory	O
(LSTM)	O
models	O
with	O
different	O
design	O
architectures	O
have	O
been	O
developed	O
and	O
evaluated.	O
The	O
SalamNET,	O
a	O
Bi-directional	O
Gated	O
Recurrent	O
Unit	O
(Bi-GRU)	O
based	O
model,	O
reports	O
a	O
macro-F1	O
score	O
of	O
0.83.	O

Deep	O
Convolutional	O
Neural	O
Network	O
(CNN)	O
is	O
a	O
special	O
type	O
of	O
Neural	O
Networks,	O
which	O
has	O
shown	O
exemplary	O
performance	O
on	O
several	O
competitions	O
related	O
to	O
Computer	O
Vision	O
and	O
Image	O
Processing.	O
Some	O
of	O
the	O
exciting	O
application	O
areas	O
of	O
CNN	O
include	O
Image	B-RESEARCH_PROBLEM
Classification	E-RESEARCH_PROBLEM
and	O
Segmentation,	O
Object	O
Detection,	O
Video	O
Processing,	O
Natural	O
Language	O
Processing,	O
and	O
Speech	O
Recognition.	O
The	O
powerful	O
learning	O
ability	O
of	O
deep	O
CNN	O
is	O
primarily	O
due	O
to	O
the	O
use	O
of	O
multiple	O
feature	O
extraction	O
stages	O
that	O
can	O
automatically	O
learn	O
representations	O
from	O
the	O
data.	O
The	O
availability	O
of	O
a	O
large	O
amount	O
of	O
data	O
and	O
improvement	O
in	O
the	O
hardware	O
technology	O
has	O
accelerated	O
the	O
research	O
in	O
CNNs,	O
and	O
recently	O
interesting	O
deep	O
CNN	O
architectures	O
have	O
been	O
reported.	O
Several	O
inspiring	O
ideas	O
to	O
bring	O
advancements	O
in	O
CNNs	O
have	O
been	O
explored,	O
such	O
as	O
the	O
use	O
of	O
different	O
activation	O
and	O
loss	O
functions,	O
parameter	O
optimization,	O
regularization,	O
and	O
architectural	O
innovations.	O
However,	O
the	O
significant	O
improvement	O
in	O
the	O
representational	O
capacity	O
of	O
the	O
deep	O
CNN	O
is	O
achieved	O
through	O
architectural	O
innovations.	O
Notably,	O
the	O
ideas	O
of	O
exploiting	O
spatial	O
and	O
channel	O
information,	O
depth	O
and	O
width	O
of	O
architecture,	O
and	O
multi-path	O
information	O
processing	O
have	O
gained	O
substantial	O
attention.	O
Similarly,	O
the	O
idea	O
of	O
using	O
a	O
block	O
of	O
layers	O
as	O
a	O
structural	O
unit	O
is	O
also	O
gaining	O
popularity.	O
This	O
survey	O
thus	O
focuses	O
on	O
the	O
intrinsic	O
taxonomy	O
present	O
in	O
the	O
recently	O
reported	O
deep	O
CNN	O
architectures	O
and,	O
consequently,	O
classifies	O
the	O
recent	O
innovations	O
in	O
CNN	O
architectures	O
into	O
seven	O
different	O
categories.	O
These	O
seven	O
categories	O
are	O
based	O
on	O
spatial	O
exploitation,	O
depth,	O
multi-path,	O
width,	O
feature-map	O
exploitation,	O
channel	O
boosting,	O
and	O
attention.	O
Additionally,	O
the	O
elementary	O
understanding	O
of	O
CNN	O
components,	O
current	O
challenges,	O
and	O
applications	O
of	O
CNN	O
are	O
also	O
provided.	O

Neural	O
network	O
models	O
are	O
resource	O
hungry.	O
It	O
is	O
difficult	O
to	O
deploy	O
such	O
deep	O
networks	O
on	O
devices	O
with	O
limited	O
resources,	O
like	O
smart	O
wearables,	O
cellphones,	O
drones,	O
and	O
autonomous	O
vehicles.	O
Low	O
bit	O
quantization	O
such	O
as	O
binary	O
and	O
ternary	O
quantization	O
is	O
a	O
common	O
approach	O
to	O
alleviate	O
this	O
resource	O
requirements.	O
Ternary	O
quantization	O
provides	O
a	O
more	O
flexible	O
model	O
and	O
outperforms	O
binary	O
quantization	O
in	O
terms	O
of	O
accuracy,	O
however	O
doubles	O
the	O
memory	O
footprint	O
and	O
increases	O
the	O
computational	O
cost.	O
Contrary	O
to	O
these	O
approaches,	O
mixed	O
quantized	O
models	O
allow	O
a	O
trade-off	O
between	O
accuracy	O
and	O
memory	O
footprint.	O
In	O
such	O
models,	O
quantization	O
depth	O
is	O
often	O
chosen	O
manually,	O
or	O
is	O
tuned	O
using	O
a	O
separate	O
optimization	O
routine.	O
The	O
latter	O
requires	O
training	O
a	O
quantized	O
network	O
multiple	O
times.	O
Here,	O
we	O
propose	O
an	O
adaptive	O
combination	O
of	O
binary	O
and	O
ternary	O
quantization,	O
namely	O
Smart	O
Quantization	S-RESEARCH_PROBLEM
(SQ),	O
in	O
which	O
the	O
quantization	O
depth	O
is	O
modified	O
directly	O
via	O
a	O
regularization	O
function,	O
so	O
that	O
the	O
model	O
is	O
trained	O
only	O
once.	O
Our	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
method	O
adapts	O
quantization	O
depth	O
successfully	O
while	O
keeping	O
the	O
model	O
accuracy	O
high	O
on	O
MNIST	O
and	O
CIFAR10	O
benchmarks.	O

We	O
review	O
three	O
recently-proposed	O
classifier	O
quality	O
metrics	O
and	O
consider	O
their	O
suitability	O
for	O
large-scale	O
classification	O
challenges	O
such	O
as	O
applying	O
convolutional	O
neural	O
networks	O
to	O
the	O
1000-class	O
ImageNet	O
dataset.	O
These	O
metrics,	O
referred	O
to	O
as	O
the	O
"geometric	O
accuracy,"	O
"decisiveness,"	O
and	O
"robustness,"	O
are	O
based	O
on	O
the	O
generalized	O
mean	O
($\rho$	O
equals	O
0,	O
1,	O
and	O
-2/3,	O
respectively)	O
of	O
the	O
classifier's	O
self-reported	O
and	O
measured	O
probabilities	O
of	O
correct	O
classification.	O
We	O
also	O
propose	O
some	O
minor	O
clarifications	O
to	O
standardize	O
the	O
metric	O
definitions.	O
With	O
these	O
updates,	O
we	O
show	O
some	O
examples	O
of	O
calculating	O
the	O
metrics	O
using	O
deep	O
convolutional	O
neural	O
networks	O
(AlexNet	O
and	O
DenseNet)	O
acting	O
on	O
large	O
datasets	O
(the	O
German	O
Traffic	B-RESEARCH_PROBLEM
Sign	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
Benchmark	O
and	O
ImageNet).	O

High-level	O
synthesis	O
(HLS)	O
shortens	O
the	O
development	O
time	O
of	O
hardware	O
designs	O
and	O
enables	O
faster	O
design	O
space	O
exploration	O
at	O
a	O
higher	O
abstraction	O
level.	O
Optimization	O
of	O
complex	O
applications	O
in	O
HLS	O
is	O
challenging	O
due	O
to	O
the	O
effects	O
of	O
implementation	O
issues	O
such	O
as	O
routing	O
congestion.	O
Routing	O
congestion	O
estimation	O
is	O
absent	O
or	O
inaccurate	O
in	O
existing	O
HLS	O
design	O
methods	O
and	O
tools.	O
Early	O
and	O
accurate	O
congestion	O
estimation	O
is	O
of	O
great	O
benefit	O
to	O
guide	O
the	O
optimization	O
in	O
HLS	O
and	O
improve	O
the	O
efficiency	O
of	O
implementation.	O
However,	O
routability,	O
a	O
serious	O
concern	O
in	O
FPGA	O
designs,	O
has	O
been	O
difficult	O
to	O
evaluate	O
in	O
HLS	O
without	O
analyzing	O
post-implementation	O
details	O
after	O
Place	O
and	O
Route.	O
To	O
this	O
end,	O
we	O
propose	O
a	O
novel	O
method	O
to	O
predict	O
routing	O
congestion	O
in	O
HLS	O
using	O
machine	O
learning	O
and	O
map	O
the	O
expected	O
congested	O
regions	O
in	O
the	O
design	O
to	O
the	O
relevant	O
high-level	O
source	O
code.	O
This	O
is	O
greatly	O
beneficial	O
in	O
early	O
identification	O
of	O
routability	O
oriented	O
bottlenecks	O
in	O
the	O
high-level	O
source	O
code	O
without	O
running	O
time-consuming	O
register-transfer	O
level	O
(RTL)	O
implementation	O
flow.	O
Experiments	O
demonstrate	O
that	O
our	O
approach	O
accurately	O
estimates	O
vertical	O
and	O
horizontal	O
routing	O
congestion	O
with	O
errors	O
of	O
6.71%	O
and	O
10.05%	O
respectively.	O
By	O
presenting	O
Face	B-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
application	O
as	O
a	O
case	O
study,	O
we	O
show	O
that	O
by	O
discovering	O
the	O
bottlenecks	O
in	O
high-level	O
source	O
code,	O
routing	O
congestion	O
can	O
be	O
easily	O
and	O
quickly	O
resolved	O
compared	O
to	O
the	O
efforts	O
involved	O
in	O
RTL	O
implementation	O
and	O
design	O
feedback.	O

In	O
this	O
work,	O
we	O
address	O
the	O
problem	O
of	O
Named	B-RESEARCH_PROBLEM
Entity	I-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(NER)	O
in	O
code-switched	O
tweets	O
as	O
a	O
part	O
of	O
the	O
Workshop	O
on	O
Computational	O
Approaches	O
to	O
Linguistic	O
Code-switching	O
(CALCS)	O
at	O
ACL{'}18.	O
Code-switching	O
is	O
the	O
phenomenon	O
where	O
a	O
speaker	O
switches	O
between	O
two	O
languages	O
or	O
variants	O
of	O
the	O
same	O
language	O
within	O
or	O
across	O
utterances,	O
known	O
as	O
intra-sentential	O
or	O
inter-sentential	O
code-switching,	O
respectively.	O
Processing	O
such	O
data	O
is	O
challenging	O
using	O
state	O
of	O
the	O
art	O
methods	O
since	O
such	O
technology	O
is	O
generally	O
geared	O
towards	O
processing	O
monolingual	O
text.	O
In	O
this	O
paper	O
we	O
explored	O
ways	O
to	O
use	O
language	O
identification	O
and	O
translation	O
to	O
recognize	O
named	O
entities	O
in	O
such	O
data,	O
however,	O
utilizing	O
simple	O
features	O
(sans	O
multi-lingual	O
features)	O
with	O
Conditional	O
Random	O
Field	O
(CRF)	O
classifier	O
achieved	O
the	O
best	O
results.	O
Our	O
experiments	O
were	O
mainly	O
aimed	O
at	O
the	O
(ENG-SPA)	O
English-Spanish	O
dataset	O
but	O
we	O
submitted	O
a	O
language-independent	O
version	O
of	O
our	O
system	O
to	O
the	O
(MSA-EGY)	O
Arabic-Egyptian	O
dataset	O
as	O
well	O
and	O
achieved	O
good	O
results.	O

Artificial	O
Intelligence	O
agents	O
are	O
required	O
to	O
learn	O
from	O
their	O
surroundings	O
and	O
to	O
reason	O
about	O
the	O
knowledge	O
that	O
has	O
been	O
learned	O
in	O
order	O
to	O
make	O
decisions.	O
While	O
state-of-the-art	O
learning	O
from	O
data	O
typically	O
uses	O
sub-symbolic	O
distributed	O
representations,	O
reasoning	O
is	O
normally	O
useful	O
at	O
a	O
higher	O
level	O
of	O
abstraction	O
with	O
the	O
use	O
of	O
a	O
first-order	O
logic	O
language	O
for	O
knowledge	O
representation.	O
As	O
a	O
result,	O
attempts	O
at	O
combining	O
symbolic	O
AI	O
and	O
neural	O
computation	O
into	O
neural-symbolic	O
systems	O
have	O
been	O
on	O
the	O
increase.	O
In	O
this	O
paper,	O
we	O
present	O
Logic	O
Tensor	B-RESEARCH_PROBLEM
Networks	E-RESEARCH_PROBLEM
(LTN),	O
a	O
neurosymbolic	O
formalism	O
and	O
computational	O
model	O
that	O
supports	O
learning	O
and	O
reasoning	O
through	O
the	O
introduction	O
of	O
a	O
many-valued,	O
end-to-end	O
differentiable	O
first-order	O
logic	O
called	O
Real	O
Logic	O
as	O
a	O
representation	O
language	O
for	O
deep	O
learning.	O
We	O
show	O
that	O
LTN	O
provides	O
a	O
uniform	O
language	O
for	O
the	O
specification	O
and	O
the	O
computation	O
of	O
several	O
AI	O
tasks	O
such	O
as	O
data	O
clustering,	O
multi-label	O
classification,	O
relational	O
learning,	O
query	O
answering,	O
semi-supervised	O
learning,	O
regression	O
and	O
embedding	O
learning.	O
We	O
implement	O
and	O
illustrate	O
each	O
of	O
the	O
above	O
tasks	O
with	O
a	O
number	O
of	O
simple	O
explanatory	O
examples	O
using	O
TensorFlow	O
2.	O
Keywords:	O
Neurosymbolic	O
AI,	O
Deep	O
Learning	O
and	O
Reasoning,	O
Many-valued	O
Logic.	O

In	O
Machine	O
Learning	O
scenarios,	O
privacy	O
is	O
a	O
crucial	O
concern	O
when	O
models	O
have	O
to	O
be	O
trained	O
with	O
private	O
data	O
coming	O
from	O
users	O
of	O
a	O
service,	O
such	O
as	O
a	O
recommender	O
system,	O
a	O
location-based	O
mobile	O
service,	O
a	O
mobile	O
phone	O
text	O
messaging	O
service	O
providing	O
next	O
word	O
prediction,	O
or	O
a	O
face	O
image	O
classification	O
system.	O
The	O
main	O
issue	O
is	O
that,	O
often,	O
data	O
are	O
collected,	O
transferred,	O
and	O
processed	O
by	O
third	O
parties.	O
These	O
transactions	O
violate	O
new	O
regulations,	O
such	O
as	O
GDPR.	O
Furthermore,	O
users	O
usually	O
are	O
not	O
willing	O
to	O
share	O
private	O
data	O
such	O
as	O
their	O
visited	O
locations,	O
the	O
text	O
messages	O
they	O
wrote,	O
or	O
the	O
photo	O
they	O
took	O
with	O
a	O
third	O
party.	O
On	O
the	O
other	O
hand,	O
users	O
appreciate	O
services	O
that	O
work	O
based	O
on	O
their	O
behaviors	O
and	O
preferences.	O
In	O
order	O
to	O
address	O
these	O
issues,	O
Federated	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(FL)	O
has	O
been	O
recently	O
proposed	O
as	O
a	O
means	O
to	O
build	O
ML	O
models	O
based	O
on	O
private	O
datasets	O
distributed	O
over	O
a	O
large	O
number	O
of	O
clients,	O
while	O
preventing	O
data	O
leakage.	O
A	O
federation	O
of	O
users	O
is	O
asked	O
to	O
train	O
a	O
same	O
global	O
model	O
on	O
their	O
private	O
data,	O
while	O
a	O
central	O
coordinating	O
server	O
receives	O
locally	O
computed	O
updates	O
by	O
clients	O
and	O
aggregate	O
them	O
to	O
obtain	O
a	O
better	O
global	O
model,	O
without	O
the	O
need	O
to	O
use	O
clients'	O
actual	O
data.	O
In	O
this	O
work,	O
we	O
extend	O
the	O
FL	O
approach	O
by	O
pushing	O
forward	O
the	O
state-of-the-art	O
approaches	O
in	O
the	O
aggregation	O
step	O
of	O
FL,	O
which	O
we	O
deem	O
crucial	O
for	O
building	O
a	O
high-quality	O
global	O
model.	O
Specifically,	O
we	O
propose	O
an	O
approach	O
that	O
takes	O
into	O
account	O
a	O
suite	O
of	O
client-specific	O
criteria	O
that	O
constitute	O
the	O
basis	O
for	O
assigning	O
a	O
score	O
to	O
each	O
client	O
based	O
on	O
a	O
priority	O
of	O
criteria	O
defined	O
by	O
the	O
service	O
provider.	O
Extensive	O
experiments	O
on	O
two	O
publicly	O
available	O
datasets	O
indicate	O
the	O
merits	O
of	O
the	O
proposed	O
approach	O
compared	O
to	O
standard	O
FL	O
baseline.	O

This	O
paper	O
studies	O
how	O
to	O
apply	O
differential	O
privacy	O
to	O
constrained	O
optimization	O
problems	O
whose	O
inputs	O
are	O
sensitive.	O
This	O
task	O
raises	O
significant	O
challenges	O
since	O
random	O
perturbations	O
of	O
the	O
input	O
data	O
often	O
render	O
the	O
constrained	O
optimization	O
problem	O
infeasible	O
or	O
change	O
significantly	O
the	O
nature	O
of	O
its	O
optimal	O
solutions.	O
To	O
address	O
this	O
difficulty,	O
this	O
paper	O
proposes	O
a	O
bilevel	B-RESEARCH_PROBLEM
optimization	E-RESEARCH_PROBLEM
model	O
that	O
can	O
be	O
used	O
as	O
a	O
post-processing	O
step:	O
It	O
redistributes	O
the	O
noise	O
introduced	O
by	O
a	O
differentially	O
private	O
mechanism	O
optimally	O
while	O
restoring	O
feasibility	O
and	O
near-optimality.	O
The	O
paper	O
shows	O
that,	O
under	O
a	O
natural	O
assumption,	O
this	O
bilevel	O
model	O
can	O
be	O
solved	O
efficiently	O
for	O
real-life	O
large-scale	O
nonlinear	O
nonconvex	O
optimization	O
problems	O
with	O
sensitive	O
customer	O
data.	O
The	O
experimental	O
results	O
demonstrate	O
the	O
accuracy	O
of	O
the	O
privacy-preserving	O
mechanism	O
and	O
showcases	O
significant	O
benefits	O
compared	O
to	O
standard	O
approaches.	O

Human	O
Activity	B-RESEARCH_PROBLEM
Recognition	E-RESEARCH_PROBLEM
(HAR),	O
based	O
on	O
machine	O
and	O
deep	O
learning	O
algorithms	O
is	O
considered	O
one	O
of	O
the	O
most	O
promising	O
technologies	O
to	O
monitor	O
professional	O
and	O
daily	O
life	O
activities	O
for	O
different	O
categories	O
of	O
people	O
(e.g.,	O
athletes,	O
elderly,	O
kids,	O
employers)	O
in	O
order	O
to	O
provide	O
a	O
variety	O
of	O
services	O
related,	O
for	O
example	O
to	O
well-being,	O
empowering	O
of	O
technical	O
performances,	O
prevention	O
of	O
risky	O
situation,	O
and	O
educational	O
purposes.	O
However,	O
the	O
analysis	O
of	O
the	O
effectiveness	O
and	O
the	O
efficiency	O
of	O
HAR	O
methodologies	O
suffers	O
from	O
the	O
lack	O
of	O
a	O
standard	O
workflow,	O
which	O
might	O
represent	O
the	O
baseline	O
for	O
the	O
estimation	O
of	O
the	O
quality	O
of	O
the	O
developed	O
pattern	O
recognition	O
models.	O
This	O
makes	O
the	O
comparison	O
among	O
different	O
approaches	O
a	O
challenging	O
task.	O
In	O
addition,	O
researchers	O
can	O
make	O
mistakes	O
that,	O
when	O
not	O
detected,	O
definitely	O
affect	O
the	O
achieved	O
results.	O
To	O
mitigate	O
such	O
issues,	O
this	O
paper	O
proposes	O
an	O
open-source	O
automatic	O
and	O
highly	O
configurable	O
framework,	O
named	O
B-HAR,	O
for	O
the	O
definition,	O
standardization,	O
and	O
development	O
of	O
a	O
baseline	O
framework	O
in	O
order	O
to	O
evaluate	O
and	O
compare	O
HAR	O
methodologies.	O
It	O
implements	O
the	O
most	O
popular	O
data	O
processing	O
methods	O
for	O
data	O
preparation	O
and	O
the	O
most	O
commonly	O
used	O
machine	O
and	O
deep	O
learning	O
pattern	O
recognition	O
models.	O

Efficient	O
similarity	O
retrieval	O
from	O
large-scale	O
multimodal	O
database	O
ispervasive	O
in	O
modern	O
search	O
engines	O
and	O
social	O
networks.	O
To	O
support	O
queriesacross	O
content	O
modalities,	O
the	O
system	O
should	O
enable	O
cross-modal	O
correlation	O
andcomputation-efficient	O
indexing.	O
While	O
hashing	O
methods	O
have	O
shown	O
greatpotential	O
in	O
achieving	O
this	O
goal,	O
current	O
attempts	O
generally	O
fail	O
to	O
learnisomorphic	O
hash	O
codes	O
in	O
a	O
seamless	O
scheme,	O
that	O
is,	O
they	O
embed	O
multiplemodalities	O
in	O
a	O
continuous	O
isomorphic	O
space	O
and	O
separately	O
threshold	O
embeddingsinto	O
binary	O
codes,	O
which	O
incurs	O
substantial	O
loss	O
of	O
retrieval	O
accuracy.	O
In	O
thispaper,	O
we	O
approach	O
seamless	O
multimodal	O
hashing	O
by	O
proposing	O
a	O
novel	O
CompositeCorrelation	O
Quantization	S-RESEARCH_PROBLEM
(CCQ)	O
model.	O
Specifically,	O
CCQ	O
jointly	O
findscorrelation-maximal	O
mappings	O
that	O
transform	O
different	O
modalities	O
intoisomorphic	O
latent	O
space,	O
and	O
learns	O
composite	O
quantizers	O
that	O
convert	O
theisomorphic	O
latent	O
features	O
into	O
compact	O
binary	O
codes.	O
An	O
optimization	O
frameworkis	O
devised	O
to	O
preserve	O
both	O
intra-modal	O
similarity	O
and	O
inter-modal	O
correlationthrough	O
minimizing	O
both	O
reconstruction	O
and	O
quantization	O
errors,	O
which	O
can	O
betrained	O
from	O
both	O
paired	O
and	O
partially	O
paired	O
data	O
in	O
linear	O
time.	O
Acomprehensive	O
set	O
of	O
experiments	O
clearly	O
show	O
the	O
superior	O
effectiveness	O
andefficiency	O
of	O
CCQ	O
against	O
the	O
state	O
of	O
the	O
art	O
hashing	O
methods	O
for	O
bothunimodal	O
and	O
cross-modal	O
retrieval.	O

Automated	B-RESEARCH_PROBLEM
Theorem	I-RESEARCH_PROBLEM
Proving	E-RESEARCH_PROBLEM
(ATP)	O
is	O
an	O
established	O
branch	O
of	O
ArtificialIntelligence.	O
The	O
purpose	O
of	O
ATP	O
is	O
to	O
design	O
a	O
system	O
which	O
can	O
automaticallyfigure	O
out	O
an	O
algorithm	O
either	O
to	O
prove	O
or	O
disprove	O
a	O
mathematical	O
claim,	O
onthe	O
basis	O
of	O
a	O
set	O
of	O
given	O
premises,	O
using	O
a	O
set	O
of	O
fundamental	O
postulates	O
andfollowing	O
the	O
method	O
of	O
logical	O
inference.	O
In	O
this	O
paper,	O
we	O
propose	O
GraATP,	O
ageneralized	O
framework	O
for	O
automated	O
theorem	O
proving	O
in	O
plane	O
geometry.	O
Ourproposed	O
method	O
translates	O
the	O
geometric	O
entities	O
into	O
nodes	O
of	O
a	O
graph	O
and	O
therelations	O
between	O
them	O
as	O
edges	O
of	O
that	O
graph.	O
The	O
automated	O
system	O
searchesfor	O
different	O
ways	O
to	O
reach	O
the	O
conclusion	O
for	O
a	O
claim	O
via	O
graph	O
traversal	O
bywhich	O
the	O
validity	O
of	O
the	O
geometric	O
theorem	O
is	O
examined.	O

Image	B-RESEARCH_PROBLEM
Super-Resolution	E-RESEARCH_PROBLEM
(SR)	O
provides	O
a	O
promising	O
technique	O
to	O
enhance	O
the	O
image	O
quality	O
of	O
low-resolution	O
optical	O
sensors,	O
facilitating	O
better-performing	O
target	O
detection	O
and	O
autonomous	O
navigation	O
in	O
a	O
wide	O
range	O
of	O
robotics	O
applications.	O
It	O
is	O
noted	O
that	O
the	O
state-of-the-art	O
SR	O
methods	O
are	O
typically	O
trained	O
and	O
tested	O
using	O
single-channel	O
inputs,	O
neglecting	O
the	O
fact	O
that	O
the	O
cost	O
of	O
capturing	O
high-resolution	O
images	O
in	O
different	O
spectral	O
domains	O
varies	O
significantly.	O
In	O
this	O
paper,	O
we	O
attempt	O
to	O
leverage	O
complementary	O
information	O
from	O
a	O
low-cost	O
channel	O
(visible/depth)	O
to	O
boost	O
image	O
quality	O
of	O
an	O
expensive	O
channel	O
(thermal)	O
using	O
fewer	O
parameters.	O
To	O
this	O
end,	O
we	O
first	O
present	O
an	O
effective	O
method	O
to	O
virtually	O
generate	O
pixel-wise	O
aligned	O
visible	O
and	O
thermal	O
images	O
based	O
on	O
real-time	O
3D	O
reconstruction	O
of	O
multi-modal	O
data	O
captured	O
at	O
various	O
viewpoints.	O
Then,	O
we	O
design	O
a	O
feature-level	O
multispectral	O
fusion	O
residual	O
network	O
model	O
to	O
perform	O
high-accuracy	O
SR	O
of	O
thermal	O
images	O
by	O
adaptively	O
integrating	O
co-occurrence	O
features	O
presented	O
in	O
multispectral	O
images.	O
Experimental	O
results	O
demonstrate	O
that	O
this	O
new	O
approach	O
can	O
effectively	O
alleviate	O
the	O
ill-posed	O
inverse	O
problem	O
of	O
image	O
SR	O
by	O
taking	O
into	O
account	O
complementary	O
information	O
from	O
an	O
additional	O
low-cost	O
channel,	O
significantly	O
outperforming	O
state-of-the-art	O
SR	O
approaches	O
in	O
terms	O
of	O
both	O
accuracy	O
and	O
efficiency.	O

Differentiable	O
ARchiTecture	O
Search	O
(DARTS)	O
is	O
one	O
of	O
the	O
most	O
trending	O
Neural	B-RESEARCH_PROBLEM
Architecture	I-RESEARCH_PROBLEM
Search	E-RESEARCH_PROBLEM
(NAS)	O
methods,	O
drastically	O
reducing	O
search	O
cost	O
by	O
resorting	O
to	O
Stochastic	O
Gradient	O
Descent	O
(SGD)	O
and	O
weight-sharing.	O
However,	O
it	O
also	O
greatly	O
reduces	O
the	O
search	O
space,	O
thus	O
excluding	O
potential	O
promising	O
architectures	O
from	O
being	O
discovered.	O
In	O
this	O
paper,	O
we	O
propose	O
D-DARTS,	O
a	O
novel	O
solution	O
that	O
addresses	O
this	O
problem	O
by	O
nesting	O
several	O
neural	O
networks	O
at	O
cell-level	O
instead	O
of	O
using	O
weight-sharing	O
to	O
produce	O
more	O
diversified	O
and	O
specialized	O
architectures.	O
Moreover,	O
we	O
introduce	O
a	O
novel	O
algorithm	O
which	O
can	O
derive	O
deeper	O
architectures	O
from	O
a	O
few	O
trained	O
cells,	O
increasing	O
performance	O
and	O
saving	O
computation	O
time.	O
Our	O
solution	O
is	O
able	O
to	O
provide	O
state-of-the-art	O
results	O
on	O
CIFAR-10,	O
CIFAR-100	O
and	O
ImageNet	O
while	O
using	O
significantly	O
less	O
parameters	O
than	O
previous	O
baselines,	O
resulting	O
in	O
more	O
hardware-efficient	O
neural	O
networks.	O

We	O
consider	O
the	O
task	O
of	O
incorporating	O
real-world	O
commonsense	O
knowledge	O
into	O
deep	O
Natural	B-RESEARCH_PROBLEM
Language	I-RESEARCH_PROBLEM
Inference	E-RESEARCH_PROBLEM
(NLI)	O
models.	O
Existing	O
external	O
knowledge	O
incorporation	O
methods	O
are	O
limited	O
to	O
lexical	O
level	O
knowledge	O
and	O
lack	O
generalization	O
across	O
NLI	O
models,	O
datasets,	O
and	O
commonsense	O
knowledge	O
sources.	O
To	O
address	O
these	O
issues,	O
we	O
propose	O
a	O
novel	O
NLI	O
model-independent	O
neural	O
framework,	O
BiCAM.	O
BiCAM	O
incorporates	O
real-world	O
commonsense	O
knowledge	O
into	O
NLI	O
models.	O
Combined	O
with	O
convolutional	O
feature	O
detectors	O
and	O
bilinear	O
feature	O
fusion,	O
BiCAM	O
provides	O
a	O
conceptually	O
simple	O
mechanism	O
that	O
generalizes	O
well.	O
Quantitative	O
evaluations	O
with	O
two	O
state-of-the-art	O
NLI	O
baselines	O
on	O
SNLI	O
and	O
SciTail	O
datasets	O
in	O
conjunction	O
with	O
ConceptNet	O
and	O
Aristo	O
Tuple	O
KGs	O
show	O
that	O
BiCAM	O
considerably	O
improves	O
the	O
accuracy	O
the	O
incorporated	O
NLI	O
baselines.	O
For	O
example,	O
our	O
BiECAM	O
model,	O
an	O
instance	O
of	O
BiCAM,	O
on	O
the	O
challenging	O
SciTail	O
dataset,	O
improves	O
the	O
accuracy	O
of	O
incorporated	O
baselines	O
by	O
7.0%	O
with	O
ConceptNet,	O
and	O
8.0%	O
with	O
Aristo	O
Tuple	O
KG.	O

This	O
paper	O
describes	O
the	O
POSTECH{'}s	O
submission	O
to	O
the	O
WMT	O
2018	O
shared	O
task	O
on	O
Automatic	B-RESEARCH_PROBLEM
Post-Editing	E-RESEARCH_PROBLEM
(APE).	O
We	O
propose	O
a	O
new	O
neural	O
end-to-end	O
post-editing	O
model	O
based	O
on	O
the	O
transformer	O
network.	O
We	O
modified	O
the	O
encoder-decoder	O
attention	O
to	O
reflect	O
the	O
relation	O
between	O
the	O
machine	O
translation	O
output,	O
the	O
source	O
and	O
the	O
post-edited	O
translation	O
in	O
APE	O
problem.	O
Experiments	O
on	O
WMT17	O
English-German	O
APE	O
data	O
set	O
show	O
an	O
improvement	O
in	O
both	O
TER	O
and	O
BLEU	O
score	O
over	O
the	O
best	O
result	O
of	O
WMT17	O
APE	O
shared	O
task.	O
Our	O
primary	O
submission	O
achieves	O
-4.52	O
TER	O
and	O
+6.81	O
BLEU	O
score	O
on	O
PBSMT	O
task	O
and	O
-0.13	O
TER	O
and	O
+0.40	O
BLEU	O
score	O
for	O
NMT	O
task	O
compare	O
to	O
the	O
baseline.	O

The	O
multi-scale	O
defect	O
detection	O
for	O
photovoltaic	O
(PV)	O
cell	O
electroluminescence	O
(EL)	O
images	O
is	O
a	O
challenging	O
task,	O
due	O
to	O
the	O
feature	O
vanishing	O
as	O
network	O
deepens.	O
To	O
address	O
this	O
problem,	O
an	O
attention-based	O
top-down	O
and	O
bottom-up	O
architecture	O
is	O
developed	O
to	O
accomplish	O
multi-scale	O
feature	O
fusion.	O
This	O
architecture,	O
called	O
Bidirectional	O
Attention	O
Feature	O
Pyramid	O
Network	O
(BAFPN),	O
can	O
make	O
all	O
layers	O
of	O
the	O
pyramid	O
share	O
similar	O
semantic	O
features.	O
In	O
BAFPN,	O
cosine	O
similarity	O
is	O
employed	O
to	O
measure	O
the	O
importance	O
of	O
each	O
pixel	O
in	O
the	O
fused	O
features.	O
Furthermore,	O
a	O
novel	O
object	O
detector	O
is	O
proposed,	O
called	O
BAF-Detector,	O
which	O
embeds	O
BAFPN	O
into	O
Region	B-RESEARCH_PROBLEM
Proposal	E-RESEARCH_PROBLEM
Network	O
(RPN)	O
in	O
Faster	O
RCNN+FPN.	O
BAFPN	O
improves	O
the	O
robustness	O
of	O
the	O
network	O
to	O
scales,	O
thus	O
the	O
proposed	O
detector	O
achieves	O
a	O
good	O
performance	O
in	O
multi-scale	O
defects	O
detection	O
task.	O
Finally,	O
the	O
experimental	O
results	O
on	O
a	O
large-scale	O
EL	O
dataset	O
including	O
3629	O
images,	O
2129	O
of	O
which	O
are	O
defective,	O
show	O
that	O
the	O
proposed	O
method	O
achieves	O
98.70%	O
(F-measure),	O
88.07%	O
(mAP),	O
and	O
73.29%	O
(IoU)	O
in	O
terms	O
of	O
multi-scale	O
defects	O
classification	O
and	O
detection	O
results	O
in	O
raw	O
PV	O
cell	O
EL	O
images.	O

Visual	B-RESEARCH_PROBLEM
Question	I-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
(VQA)	O
models	O
have	O
achieved	O
significant	O
success	O
in	O
recent	O
times.	O
Despite	O
the	O
success	O
of	O
VQA	O
models,	O
they	O
are	O
mostly	O
black-box	O
models	O
providing	O
no	O
reasoning	O
about	O
the	O
predicted	O
answer,	O
thus	O
raising	O
questions	O
for	O
their	O
applicability	O
in	O
safety-critical	O
such	O
as	O
autonomous	O
systems	O
and	O
cyber-security.	O
Current	O
state	O
of	O
the	O
art	O
fail	O
to	O
better	O
complex	O
questions	O
and	O
thus	O
are	O
unable	O
to	O
exploit	O
compositionality.	O
To	O
minimize	O
the	O
black-box	O
effect	O
of	O
these	O
models	O
and	O
also	O
to	O
make	O
them	O
better	O
exploit	O
compositionality,	O
we	O
propose	O
a	O
Dynamic	O
Neural	O
Network	O
(DMN),	O
which	O
can	O
understand	O
a	O
particular	O
question	O
and	O
then	O
dynamically	O
assemble	O
various	O
relatively	O
shallow	O
deep	O
learning	O
modules	O
from	O
a	O
pool	O
of	O
modules	O
to	O
form	O
a	O
network.	O
We	O
incorporate	O
compositional	O
temporal	O
attention	O
to	O
these	O
deep	O
learning	O
based	O
modules	O
to	O
increase	O
compositionality	O
exploitation.	O
This	O
results	O
in	O
achieving	O
better	O
understanding	O
of	O
complex	O
questions	O
and	O
also	O
provides	O
reasoning	O
as	O
to	O
why	O
the	O
module	O
predicts	O
a	O
particular	O
answer.	O
Experimental	O
analysis	O
on	O
the	O
two	O
benchmark	O
datasets,	O
VQA2.0	O
and	O
CLEVR,	O
depicts	O
that	O
our	O
model	O
outperforms	O
the	O
previous	O
approaches	O
for	O
Visual	B-RESEARCH_PROBLEM
Question	I-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
task	O
as	O
well	O
as	O
provides	O
better	O
reasoning,	O
thus	O
making	O
it	O
reliable	O
for	O
mission	O
critical	O
applications	O
like	O
safety	O
and	O
security.	O

Circular	O
cone-beam	O
(CCB)	O
Computed	B-RESEARCH_PROBLEM
Tomography	I-RESEARCH_PROBLEM
(CT)	E-RESEARCH_PROBLEM
has	O
become	O
an	O
integral	O
part	O
of	O
industrial	O
quality	O
control,	O
materials	O
science	O
and	O
medical	O
imaging.	O
The	O
need	O
to	O
acquire	O
and	O
process	O
each	O
scan	O
in	O
a	O
short	O
time	O
naturally	O
leads	O
to	O
trade-offs	O
between	O
speed	O
and	O
reconstruction	O
quality,	O
creating	O
a	O
need	O
for	O
fast	O
reconstruction	O
algorithms	O
capable	O
of	O
creating	O
accurate	O
reconstructions	O
from	O
limited	O
data.	O
In	O
this	O
paper	O
we	O
introduce	O
the	O
Neural	O
Network	O
Feldkamp-Davis-Kress	O
(NN-FDK)	O
algorithm.	O
This	O
algorithm	O
adds	O
a	O
machine	O
learning	O
component	O
to	O
the	O
FDK	O
algorithm	O
to	O
improve	O
its	O
reconstruction	O
accuracy	O
while	O
maintaining	O
its	O
computational	O
efficiency.	O
Moreover,	O
the	O
NN-FDK	O
algorithm	O
is	O
designed	O
such	O
that	O
it	O
has	O
low	O
training	O
data	O
requirements	O
and	O
is	O
fast	O
to	O
train.	O
This	O
ensures	O
that	O
the	O
proposed	O
algorithm	O
can	O
be	O
used	O
to	O
improve	O
image	O
quality	O
in	O
high	O
throughput	O
CT	O
scanning	O
settings,	O
where	O
FDK	O
is	O
currently	O
used	O
to	O
keep	O
pace	O
with	O
the	O
acquisition	O
speed	O
using	O
readily	O
available	O
computational	O
resources.	O
We	O
compare	O
the	O
NN-FDK	O
algorithm	O
to	O
two	O
standard	O
CT	O
reconstruction	O
algorithms	O
and	O
to	O
two	O
popular	O
deep	O
neural	O
networks	O
trained	O
to	O
remove	O
reconstruction	O
artifacts	O
from	O
the	O
2D	O
slices	O
of	O
an	O
FDK	O
reconstruction.	O
We	O
show	O
that	O
the	O
NN-FDK	O
reconstruction	O
algorithm	O
is	O
substantially	O
faster	O
in	O
computing	O
a	O
reconstruction	O
than	O
all	O
the	O
tested	O
alternative	O
methods	O
except	O
for	O
the	O
standard	O
FDK	O
algorithm	O
and	O
we	O
show	O
it	O
can	O
compute	O
accurate	O
CCB	O
CT	O
reconstructions	O
in	O
cases	O
of	O
high	O
noise,	O
a	O
low	O
number	O
of	O
projection	O
angles	O
or	O
large	O
cone	O
angles.	O
Moreover,	O
we	O
show	O
that	O
the	O
training	O
time	O
of	O
an	O
NN-FDK	O
network	O
is	O
orders	O
of	O
magnitude	O
lower	O
than	O
the	O
considered	O
deep	O
neural	O
networks,	O
with	O
only	O
a	O
slight	O
reduction	O
in	O
reconstruction	O
accuracy.	O

Despite	O
the	O
significant	O
progress	O
achieved	O
in	O
image	O
de-raining	O
by	O
training	O
an	O
encoder-decoder	O
network	O
within	O
the	O
image-to-image	O
translation	O
formulation,	O
blurry	O
results	O
with	O
missing	O
details	O
indicate	O
the	O
deficiency	O
of	O
the	O
existing	O
models.	O
By	O
interpreting	O
the	O
de-raining	O
encoder-decoder	O
network	O
as	O
a	O
conditional	O
generator,	O
within	O
which	O
the	O
decoder	O
acts	O
as	O
a	O
generator	O
conditioned	O
on	O
the	O
embedding	O
learned	O
by	O
the	O
encoder,	O
the	O
unsatisfactory	O
output	O
can	O
be	O
attributed	O
to	O
the	O
low-quality	O
embedding	O
learned	O
by	O
the	O
encoder.	O
In	O
this	O
paper,	O
we	O
hypothesize	O
that	O
there	O
exists	O
an	O
inherent	O
mapping	O
between	O
the	O
low-quality	O
embedding	O
to	O
a	O
latent	O
optimal	O
one,	O
with	O
which	O
the	O
generator	O
(decoder)	O
can	O
produce	O
much	O
better	O
results.	O
To	O
improve	O
the	O
de-raining	O
results	O
significantly	O
over	O
existing	O
models,	O
we	O
propose	O
to	O
learn	O
this	O
mapping	O
by	O
formulating	O
a	O
residual	O
learning	O
branch,	O
that	O
is	O
capable	O
of	O
adaptively	O
adding	O
residuals	O
to	O
the	O
original	O
low-quality	O
embedding	O
in	O
a	O
representation	O
entanglement	O
manner.	O
Using	O
an	O
embedding	O
learned	O
this	O
way,	O
the	O
decoder	O
is	O
able	O
to	O
generate	O
much	O
more	O
satisfactory	O
de-raining	O
results	O
with	O
better	O
detail	O
recovery	O
and	O
rain	O
artefacts	O
removal,	O
providing	O
new	O
state-of-the-art	O
results	O
on	O
four	O
benchmark	O
datasets	O
with	O
considerable	O
improvement	O
(i.e.,	O
on	O
the	O
challenging	O
Rain100H	O
data,	O
an	O
improvement	O
of	O
4.19dB	O
on	O
PSNR	O
and	O
5%	O
on	O
SSIM	S-RESEARCH_PROBLEM
is	O
obtained).	O
The	O
entanglement	O
can	O
be	O
easily	O
adopted	O
into	O
any	O
encoder-decoder	O
based	O
image	O
restoration	O
networks.	O
Besides,	O
we	O
propose	O
a	O
series	O
of	O
evaluation	O
metrics	O
to	O
investigate	O
the	O
specific	O
contribution	O
of	O
the	O
proposed	O
entangled	O
representation	O
learning	O
mechanism.	O
Codes	O
are	O
available	O
at	O
.	O

Training	O
semantic	O
segmentation	O
models	O
requires	O
a	O
large	O
amount	O
of	O
finely	O
annotated	O
data,	O
making	O
it	O
hard	O
to	O
quickly	O
adapt	O
to	O
novel	O
classes	O
not	O
satisfying	O
this	O
condition.	O
Few-Shot	O
Segmentation	O
(FS-Seg)	O
tackles	O
this	O
problem	O
with	O
many	O
constraints.	O
In	O
this	O
paper,	O
we	O
introduce	O
a	O
new	O
benchmark,	O
called	O
Generalized	O
Few-Shot	B-RESEARCH_PROBLEM
Semantic	I-RESEARCH_PROBLEM
Segmentation	E-RESEARCH_PROBLEM
(GFS-Seg),	O
to	O
analyze	O
the	O
generalization	O
ability	O
of	O
segmentation	O
models	O
to	O
simultaneously	O
recognize	O
novel	O
categories	O
with	O
very	O
few	O
examples	O
as	O
well	O
as	O
base	O
categories	O
with	O
sufficient	O
examples.	O
Previous	O
state-of-the-art	O
FS-Seg	O
methods	O
fall	O
short	O
in	O
GFS-Seg	O
and	O
the	O
performance	O
discrepancy	O
mainly	O
comes	O
from	O
the	O
constrained	O
training	O
setting	O
of	O
FS-Seg.	O
To	O
make	O
GFS-Seg	O
tractable,	O
we	O
set	O
up	O
a	O
GFS-Seg	O
baseline	O
that	O
achieves	O
decent	O
performance	O
without	O
structural	O
change	O
on	O
the	O
original	O
model.	O
Then,	O
as	O
context	O
is	O
the	O
key	O
for	O
boosting	O
performance	O
on	O
semantic	O
segmentation,	O
we	O
propose	O
the	O
Context-Aware	O
Prototype	O
Learning	O
(CAPL)	O
that	O
significantly	O
improves	O
performance	O
by	O
leveraging	O
the	O
contextual	O
information	O
to	O
update	O
class	O
prototypes	O
with	O
aligned	O
features.	O
Extensive	O
experiments	O
on	O
Pascal-VOC	O
and	O
COCO	O
manifest	O
the	O
effectiveness	O
of	O
CAPL,	O
and	O
CAPL	O
also	O
generalizes	O
well	O
to	O
FS-Seg.	O

The	O
standard	O
ML	O
methodology	O
assumes	O
that	O
the	O
test	O
samples	O
are	O
derived	O
from	O
a	O
set	O
of	O
pre-observed	O
classes	O
used	O
in	O
the	O
training	O
phase.	O
Where	O
the	O
model	O
extracts	O
and	O
learns	O
useful	O
patterns	O
to	O
detect	O
new	O
data	O
samples	O
belonging	O
to	O
the	O
same	O
data	O
classes.	O
However,	O
in	O
certain	O
applications	O
such	O
as	O
Network	B-RESEARCH_PROBLEM
Intrusion	I-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
Systems,	O
it	O
is	O
challenging	O
to	O
obtain	O
data	O
samples	O
for	O
all	O
attack	O
classes	O
that	O
the	O
model	O
will	O
most	O
likely	O
observe	O
in	O
production.	O
ML-based	O
NIDSs	O
face	O
new	O
attack	O
traffic	O
known	O
as	O
zero-day	O
attacks,	O
that	O
are	O
not	O
used	O
in	O
the	O
training	O
of	O
the	O
learning	O
models	O
due	O
to	O
their	O
non-existence	O
at	O
the	O
time.	O
In	O
this	O
paper,	O
a	O
zero-shot	O
learning	O
methodology	O
has	O
been	O
proposed	O
to	O
evaluate	O
the	O
ML	O
model	O
performance	O
in	O
the	O
detection	O
of	O
zero-day	O
attack	O
scenarios.	O
In	O
the	O
attribute	O
learning	O
stage,	O
the	O
ML	O
models	O
map	O
the	O
network	O
data	O
features	O
to	O
distinguish	O
semantic	O
attributes	O
from	O
known	O
attack	O
(seen)	O
classes.	O
In	O
the	O
inference	O
stage,	O
the	O
models	O
are	O
evaluated	O
in	O
the	O
detection	O
of	O
zero-day	O
attack	O
(unseen)	O
classes	O
by	O
constructing	O
the	O
relationships	O
between	O
known	O
attacks	O
and	O
zero-day	O
attacks.	O
A	O
new	O
metric	O
is	O
defined	O
as	O
Zero-day	O
Detection	O
Rate,	O
which	O
measures	O
the	O
effectiveness	O
of	O
the	O
learning	O
model	O
in	O
the	O
inference	O
stage.	O
The	O
results	O
demonstrate	O
that	O
while	O
the	O
majority	O
of	O
the	O
attack	O
classes	O
do	O
not	O
represent	O
significant	O
risks	O
to	O
organisations	O
adopting	O
an	O
ML-based	O
NIDS	O
in	O
a	O
zero-day	O
attack	O
scenario.	O
However,	O
for	O
certain	O
attack	O
groups	O
identified	O
in	O
this	O
paper,	O
such	O
systems	O
are	O
not	O
effective	O
in	O
applying	O
the	O
learnt	O
attributes	O
of	O
attack	O
behaviour	O
to	O
detect	O
them	O
as	O
malicious.	O
Further	O
Analysis	O
was	O
conducted	O
using	O
the	O
Wasserstein	O
Distance	O
technique	O
to	O
measure	O
how	O
different	O
such	O
attacks	O
are	O
from	O
other	O
attack	O
types	O
used	O
in	O
the	O
training	O
of	O
the	O
ML	O
model.	O
The	O
results	O
demonstrate	O
that	O
sophisticated	O
attacks	O
with	O
a	O
low	O
zero-day	O
detection	O
rate	O
have	O
a	O
significantly	O
distinct	O
feature	O
distribution	O
compared	O
to	O
the	O
other	O
attack	O
classes.	O

We	O
ascertain	O
and	O
compare	O
the	O
performances	O
of	O
AutoML	S-RESEARCH_PROBLEM
tools	O
on	O
large,	O
highly	O
imbalanced	O
healthcare	O
datasets.	O
We	O
generated	O
a	O
large	O
dataset	O
using	O
historical	O
administrative	O
claims	O
including	O
demographic	O
information	O
and	O
flags	O
for	O
disease	O
codes	O
in	O
four	O
different	O
time	O
windows	O
prior	O
to	O
2019.	O
We	O
then	O
trained	O
three	O
AutoML	S-RESEARCH_PROBLEM
tools	O
on	O
this	O
dataset	O
to	O
predict	O
six	O
different	O
disease	O
outcomes	O
in	O
2019	O
and	O
evaluated	O
model	O
performances	O
on	O
several	O
metrics.	O
The	O
AutoML	S-RESEARCH_PROBLEM
tools	O
showed	O
improvement	O
from	O
the	O
baseline	O
random	O
forest	O
model	O
but	O
did	O
not	O
differ	O
significantly	O
from	O
each	O
other.	O
All	O
models	O
recorded	O
low	O
area	O
under	O
the	O
precision-recall	O
curve	O
and	O
failed	O
to	O
predict	O
true	O
positives	O
while	O
keeping	O
the	O
true	O
negative	O
rate	O
high.	O
Model	O
performance	O
was	O
not	O
directly	O
related	O
to	O
prevalence.	O
We	O
provide	O
a	O
specific	O
use-case	O
to	O
illustrate	O
how	O
to	O
select	O
a	O
threshold	O
that	O
gives	O
the	O
best	O
balance	O
between	O
true	O
and	O
false	O
positive	O
rates,	O
as	O
this	O
is	O
an	O
important	O
consideration	O
in	O
medical	O
applications.	O
Healthcare	O
datasets	O
present	O
several	O
challenges	O
for	O
AutoML	S-RESEARCH_PROBLEM
tools,	O
including	O
large	O
sample	O
size,	O
high	O
imbalance,	O
and	O
limitations	O
in	O
the	O
available	O
features	O
types.	O
Improvements	O
in	O
scalability,	O
combinations	O
of	O
imbalance-learning	O
resampling	O
and	O
ensemble	O
approaches,	O
and	O
curated	O
feature	O
selection	O
are	O
possible	O
next	O
steps	O
to	O
achieve	O
better	O
performance.	O
Among	O
the	O
three	O
explored,	O
no	O
AutoML	S-RESEARCH_PROBLEM
tool	O
consistently	O
outperforms	O
the	O
rest	O
in	O
terms	O
of	O
predictive	O
performance.	O
The	O
performances	O
of	O
the	O
models	O
in	O
this	O
study	O
suggest	O
that	O
there	O
may	O
be	O
room	O
for	O
improvement	O
in	O
handling	O
medical	O
claims	O
data.	O
Finally,	O
selection	O
of	O
the	O
optimal	O
prediction	O
threshold	O
should	O
be	O
guided	O
by	O
the	O
specific	O
practical	O
application.	O

Pathological	O
slowing	O
in	O
the	O
electroencephalogram	O
(EEG	S-RESEARCH_PROBLEM
)	O
is	O
widely	O
investigated	O
for	O
the	O
diagnosis	O
of	O
neurological	O
disorders.	O
Currently,	O
the	O
gold	O
standard	O
for	O
slowing	O
detection	O
is	O
the	O
visual	O
inspection	O
of	O
the	O
EEG	S-RESEARCH_PROBLEM
by	O
experts,	O
which	O
is	O
time-consuming	O
and	O
subjective.	O
To	O
address	O
those	O
issues,	O
we	O
propose	O
three	O
automated	O
approaches	O
to	O
detect	O
slowing	O
in	O
EEG	S-RESEARCH_PROBLEM
:	O
Threshold-based	O
Detecting	O
System	O
(TDS),	O
Shallow	O
Learning-based	O
Detecting	O
System	O
(SLDS),	O
and	O
Deep	O
Learning-based	O
Detecting	O
System	O
(DLDS).	O
These	O
systems	O
are	O
evaluated	O
on	O
channel-,	O
segment-	O
and	O
EEG	S-RESEARCH_PROBLEM
-level.	O
The	O
TDS,	O
SLDS,	O
and	O
DLDS	O
performs	O
prediction	O
via	O
detecting	O
slowing	O
at	O
individual	O
channels,	O
and	O
those	O
detections	O
are	O
arranged	O
in	O
histograms	O
for	O
detection	O
of	O
slowing	O
at	O
the	O
segment-	O
and	O
EEG	S-RESEARCH_PROBLEM
-level.	O
We	O
evaluate	O
the	O
systems	O
through	O
Leave-One-Subject-Out	O
(LOSO)	O
cross-validation	O
(CV)	O
and	O
Leave-One-Institution-Out	O
(LOIO)	O
CV	O
on	O
four	O
datasets	O
from	O
the	O
US,	O
Singapore,	O
and	O
India.	O
The	O
DLDS	O
achieved	O
the	O
best	O
overall	O
results:	O
LOIO	O
CV	O
mean	O
balanced	O
accuracy	O
(BAC)	O
of	O
71.9%,	O
75.5%,	O
and	O
82.0%	O
at	O
channel-,	O
segment-	O
and	O
EEG	S-RESEARCH_PROBLEM
-level,	O
and	O
LOSO	O
CV	O
mean	O
BAC	O
of	O
73.6%,	O
77.2%,	O
and	O
81.8%	O
at	O
channel-,	O
segment-,	O
and	O
EEG	S-RESEARCH_PROBLEM
-level.	O
The	O
channel-	O
and	O
segment-level	O
performance	O
is	O
comparable	O
to	O
the	O
intra-rater	O
agreement	O
(IRA)	O
of	O
an	O
expert	O
of	O
72.4%	O
and	O
82%.	O
The	O
DLDS	O
can	O
process	O
a	O
30-minutes	O
EEG	S-RESEARCH_PROBLEM
in	O
4	O
seconds	O
and	O
can	O
be	O
deployed	O
to	O
assist	O
clinicians	O
in	O
interpreting	O
EEG	S-RESEARCH_PROBLEM
s.	O

In	O
this	O
paper	O
we	O
present	O
the	O
dataset	O
of	O
Himachali	O
low	O
resource	O
endangered	O
language,	O
Kangri	O
(ISO	O
639-3xnr)	O
listed	O
in	O
the	O
United	O
Nations	O
Educational,	O
Scientific	O
and	O
Cultural	O
Organization	O
(UNESCO).	O
The	O
compilation	O
of	O
kangri	O
corpus	O
has	O
been	O
a	O
challenging	O
task	O
due	O
to	O
the	O
non-availability	O
of	O
the	O
digitalized	O
resources.	O
The	O
corpus	O
contains	O
1,81,552	O
Monolingual	O
and	O
27,362	O
Hindi-Kangri	O
Parallel	O
corpora.	O
We	O
shared	O
pre-trained	O
kangri	O
word	O
embeddings.	O
We	O
also	O
reported	O
the	O
Bilingual	O
Evaluation	O
Understudy	O
(BLEU)	O
score	O
and	O
Metric	O
for	O
Evaluation	O
of	O
Translation	O
with	O
Explicit	O
ORdering	O
(METEOR)	O
score	O
of	O
Statistical	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(SMT)	O
and	O
Neural	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(NMT)	O
results	O
for	O
the	O
corpus.	O
The	O
corpus	O
is	O
freely	O
available	O
for	O
non-commercial	O
usages	O
and	O
research.	O
To	O
the	O
best	O
of	O
our	O
knowledge,	O
this	O
is	O
the	O
first	O
Himachali	O
low	O
resource	O
endangered	O
language	O
corpus.	O
The	O
resources	O
are	O
available	O
at	O
(https://github.com/chauhanshweta/Kangri_corpus)	O

The	O
Pre-training	O
for	O
Video	B-RESEARCH_PROBLEM
Captioning	E-RESEARCH_PROBLEM
Challenge	O
2020	O
Summary:	O
results	O
and	O
challenge	O
participants'	O
technical	O
reports.	O

Manual	O
count	O
of	O
mitotic	O
figures,	O
which	O
is	O
determined	O
in	O
the	O
tumor	O
region	O
with	O
the	O
highest	O
mitotic	O
activity,	O
is	O
a	O
key	O
parameter	O
of	O
most	O
tumor	O
grading	O
schemes.	O
It	O
can	O
be,	O
however,	O
strongly	O
dependent	O
on	O
the	O
area	O
selection	O
due	O
to	O
uneven	O
mitotic	O
figure	O
distribution	O
in	O
the	O
tumor	O
section.We	O
aimed	O
to	O
assess	O
the	O
question,	O
how	O
significantly	O
the	O
area	O
selection	O
could	O
impact	O
the	O
mitotic	O
count,	O
which	O
has	O
a	O
known	O
high	O
inter-rater	O
disagreement.	O
On	O
a	O
data	O
set	O
of	O
32	O
whole	B-RESEARCH_PROBLEM
slide	I-RESEARCH_PROBLEM
images	E-RESEARCH_PROBLEM
of	O
H&E-stained	O
canine	O
cutaneous	O
mast	O
cell	O
tumor,	O
fully	O
annotated	O
for	O
mitotic	O
figures,	O
we	O
asked	O
eight	O
veterinary	O
pathologists	O
(five	O
board-certified,	O
three	O
in	O
training)	O
to	O
select	O
a	O
field	O
of	O
interest	O
for	O
the	O
mitotic	O
count.	O
To	O
assess	O
the	O
potential	O
difference	O
on	O
the	O
mitotic	O
count,	O
we	O
compared	O
the	O
mitotic	O
count	O
of	O
the	O
selected	O
regions	O
to	O
the	O
overall	O
distribution	O
on	O
the	O
slide.Additionally,	O
we	O
evaluated	O
three	O
deep	O
learning-based	O
methods	O
for	O
the	O
assessment	O
of	O
highest	O
mitotic	O
density:	O
In	O
one	O
approach,	O
the	O
model	O
would	O
directly	O
try	O
to	O
predict	O
the	O
mitotic	O
count	O
for	O
the	O
presented	O
image	O
patches	O
as	O
a	O
regression	O
task.	O
The	O
second	O
method	O
aims	O
at	O
deriving	O
a	O
segmentation	O
mask	O
for	O
mitotic	O
figures,	O
which	O
is	O
then	O
used	O
to	O
obtain	O
a	O
mitotic	O
density.	O
Finally,	O
we	O
evaluated	O
a	O
two-stage	O
object-detection	O
pipeline	O
based	O
on	O
state-of-the-art	O
architectures	O
to	O
identify	O
individual	O
mitotic	O
figures.	O
We	O
found	O
that	O
the	O
predictions	O
by	O
all	O
models	O
were,	O
on	O
average,	O
better	O
than	O
those	O
of	O
the	O
experts.	O
The	O
two-stage	O
object	O
detector	O
performed	O
best	O
and	O
outperformed	O
most	O
of	O
the	O
human	O
pathologists	O
on	O
the	O
majority	O
of	O
tumor	O
cases.	O
The	O
correlation	O
between	O
the	O
predicted	O
and	O
the	O
ground	O
truth	O
mitotic	O
count	O
was	O
also	O
best	O
for	O
this	O
approach	O
(0.963	O
to	O
0.979).	O
Further,	O
we	O
found	O
considerable	O
differences	O
in	O
position	O
selection	O
between	O
pathologists,	O
which	O
could	O
partially	O
explain	O
the	O
high	O
variance	O
that	O
has	O
been	O
reported	O
for	O
the	O
manual	O
mitotic	O
count.	O

Incremental	B-RESEARCH_PROBLEM
Learning	E-RESEARCH_PROBLEM
(IL)	O
is	O
an	O
interesting	O
AI	O
problem	O
when	O
the	O
algorithm	O
isassumed	O
to	O
work	O
on	O
a	O
budget.	O
This	O
is	O
especially	O
true	O
when	O
IL	O
is	O
modeled	O
using	O
adeep	O
learning	O
approach,	O
where	O
two	O
com-	O
plex	O
challenges	O
arise	O
due	O
to	O
limitedmemory,	O
which	O
induces	O
catastrophic	O
forgetting	O
and	O
delays	O
related	O
to	O
theretraining	O
needed	O
in	O
order	O
to	O
incorpo-	O
rate	O
new	O
classes.	O
Here	O
we	O
introduceDeeSIL,	O
an	O
adaptation	O
of	O
a	O
known	O
transfer	O
learning	O
scheme	O
that	O
combines	O
a	O
fixeddeep	O
representation	O
used	O
as	O
feature	O
extractor	O
and	O
learning	O
independent	O
shallowclassifiers	O
to	O
in-	O
crease	O
recognition	O
capacity.	O
This	O
scheme	O
tackles	O
the	O
twoaforementioned	O
challenges	O
since	O
it	O
works	O
well	O
with	O
a	O
limited	O
memory	O
budget	O
andeach	O
new	O
concept	O
can	O
be	O
added	O
within	O
a	O
minute.	O
Moreover,	O
since	O
no	O
deep	O
re-training	O
is	O
needed	O
when	O
the	O
model	O
is	O
incremented,	O
DeeSIL	O
can	O
integrate	O
largeramounts	O
of	O
initial	O
data	O
that	O
provide	O
more	O
transferable	O
features.	O
Performance	O
isevaluated	O
on	O
ImageNet	O
LSVRC	O
2012	O
against	O
three	O
state	O
of	O
the	O
art	O
algorithms.Results	O
show	O
that,	O
at	O
scale,	O
DeeSIL	O
performance	O
is	O
23	O
and	O
33	O
points	O
higher	O
thanthe	O
best	O
baseline	O
when	O
using	O
the	O
same	O
and	O
more	O
initial	O
data	O
respectively.	O

Anomalies	O
in	O
images	O
occur	O
in	O
various	O
scales	O
from	O
a	O
small	O
hole	O
on	O
a	O
carpet	O
to	O
a	O
large	O
stain.	O
However,	O
anomaly	O
detection	O
based	O
on	O
sparse	O
coding,	O
one	O
of	O
the	O
widely	O
used	O
anomaly	O
detection	O
methods,	O
has	O
an	O
issue	O
in	O
dealing	O
with	O
anomalies	O
that	O
are	O
out	O
of	O
the	O
patch	O
size	O
employed	O
to	O
sparsely	O
represent	O
images.	O
A	O
large	O
anomaly	O
can	O
be	O
considered	O
normal	O
if	O
seen	O
in	O
a	O
small	O
scale,	O
but	O
it	O
is	O
not	O
easy	O
to	O
determine	O
a	O
single	O
scale	O
(patch	O
size)	O
that	O
works	O
well	O
for	O
all	O
images.	O
Then,	O
we	O
propose	O
to	O
incorporate	O
multi-scale	O
features	O
to	O
sparse	O
coding	O
and	O
improve	O
the	O
performance	O
of	O
anomaly	O
detection.	O
The	O
proposed	O
method,	O
multi-layer	O
feature	O
sparse	O
coding	O
(MLF-SC),	O
employs	O
a	O
neural	O
network	O
for	O
feature	O
extraction,	O
and	O
feature	O
maps	O
from	O
intermediate	O
layers	O
of	O
the	O
network	O
are	O
given	O
to	O
sparse	O
coding,	O
whereas	O
the	O
standard	O
sparse-coding-based	O
anomaly	O
detection	O
method	O
directly	O
works	O
on	O
given	O
images.	O
We	O
show	O
that	O
MLF-SC	O
outperforms	O
state-of-the-art	O
anomaly	O
detection	O
methods	O
including	O
those	O
employing	O
deep	O
learning.	O
Our	O
target	O
data	O
are	O
the	O
texture	O
categories	O
of	O
the	O
MVTec	O
Anomaly	B-RESEARCH_PROBLEM
Detection	E-RESEARCH_PROBLEM
(MVTec	O
AD)	O
dataset,	O
which	O
is	O
a	O
modern	O
benchmark	O
dataset	O
consisting	O
of	O
images	O
from	O
the	O
real	O
world.	O
Our	O
idea	O
can	O
be	O
a	O
simple	O
and	O
practical	O
option	O
to	O
deal	O
with	O
practical	O
data.	O

Selfie-based	O
biometrics	O
has	O
great	O
potential	O
for	O
a	O
wide	O
range	O
of	O
applications	O
from	O
marketing	O
to	O
higher	O
security	O
environments	O
like	O
online	O
banking.	O
This	O
is	O
now	O
especially	O
relevant	O
since	O
e.g.	O
periocular	O
verification	O
is	O
contactless,	O
and	O
thereby	O
safe	O
to	O
use	O
in	O
pandemics	O
such	O
as	O
COVID-19.	O
However,	O
selfie-based	O
biometrics	O
faces	O
some	O
challenges	O
since	O
there	O
is	O
limited	O
control	O
over	O
the	O
data	O
acquisition	O
conditions.	O
Therefore,	O
super-resolution	O
has	O
to	O
be	O
used	O
to	O
increase	O
the	O
quality	O
of	O
the	O
captured	O
images.	O
Most	O
of	O
the	O
state	O
of	O
the	O
art	O
super-resolution	O
methods	O
use	O
deep	O
networks	O
with	O
large	O
filters,	O
thereby	O
needing	O
to	O
train	O
and	O
store	O
a	O
correspondingly	O
large	O
number	O
of	O
parameters,	O
and	O
making	O
their	O
use	O
difficult	O
for	O
mobile	O
devices	O
commonly	O
used	O
for	O
selfie-based.	O
In	O
order	O
to	O
achieve	O
an	O
efficient	O
super-resolution	O
method,	O
we	O
propose	O
an	O
Efficient	O
Single	O
Image	B-RESEARCH_PROBLEM
Super-Resolution	E-RESEARCH_PROBLEM
(ESISR)	O
algorithm,	O
which	O
takes	O
into	O
account	O
a	O
trade-off	O
between	O
the	O
efficiency	O
of	O
the	O
deep	O
neural	O
network	O
and	O
the	O
size	O
of	O
its	O
filters.	O
To	O
that	O
end,	O
the	O
method	O
implements	O
a	O
novel	O
loss	O
function	O
based	O
on	O
the	O
Sharpness	O
metric.	O
This	O
metric	O
turns	O
out	O
to	O
be	O
more	O
suitable	O
for	O
increasing	O
the	O
quality	O
of	O
the	O
eye	O
images.	O
Our	O
method	O
drastically	O
reduces	O
the	O
number	O
of	O
parameters	O
when	O
compared	O
with	O
Deep	O
CNNs	O
with	O
Skip	O
Connection	O
and	O
Network	O
(DCSCN):	O
from	O
2,170,142	O
to	O
28,654	O
parameters	O
when	O
the	O
image	O
size	O
is	O
increased	O
by	O
a	O
factor	O
of	O
x3.	O
Furthermore,	O
the	O
proposed	O
method	O
keeps	O
the	O
sharp	O
quality	O
of	O
the	O
images,	O
which	O
is	O
highly	O
relevant	O
for	O
biometric	O
recognition	O
purposes.	O
The	O
results	O
on	O
remote	O
verification	O
systems	O
with	O
raw	O
images	O
reached	O
an	O
Equal	O
Error	O
Rate	O
(EER)	O
of	O
8.7%	O
for	O
FaceNet	O
and	O
10.05%	O
for	O
VGGFace.	O
Where	O
embedding	O
vectors	O
were	O
used	O
from	O
periocular	O
images	O
the	O
best	O
results	O
reached	O
an	O
EER	O
of	O
8.9%	O
(x3)	O
for	O
FaceNet	O
and	O
9.90%	O
(x4)	O
for	O
VGGFace.	O

Deep	O
learning	O
methods	O
have	O
proven	O
extremely	O
effective	O
at	O
performing	O
a	O
variety	O
of	O
medical	O
image	O
analysis	O
tasks.	O
With	O
their	O
potential	O
use	O
in	O
clinical	O
routine,	O
their	O
lack	O
of	O
transparency	O
has	O
however	O
been	O
one	O
of	O
their	O
few	O
weak	O
points,	O
raising	O
concerns	O
regarding	O
their	O
behavior	O
and	O
failure	O
modes.	O
While	O
most	O
research	O
to	O
infer	O
model	O
behavior	O
has	O
focused	O
on	O
indirect	O
strategies	O
that	O
estimate	O
prediction	O
uncertainties	O
and	O
visualize	O
model	O
support	O
in	O
the	O
input	O
image	O
space,	O
the	O
ability	O
to	O
explicitly	O
query	O
a	O
prediction	O
model	O
regarding	O
its	O
image	O
content	O
offers	O
a	O
more	O
direct	O
way	O
to	O
determine	O
the	O
behavior	O
of	O
trained	O
models.	O
To	O
this	O
end,	O
we	O
present	O
a	O
novel	O
Visual	B-RESEARCH_PROBLEM
Question	I-RESEARCH_PROBLEM
Answering	E-RESEARCH_PROBLEM
approach	O
that	O
allows	O
an	O
image	O
to	O
be	O
queried	O
by	O
means	O
of	O
a	O
written	O
question.	O
Experiments	O
on	O
a	O
variety	O
of	O
medical	O
and	O
natural	O
image	O
datasets	O
show	O
that	O
by	O
fusing	O
image	O
and	O
question	O
features	O
in	O
a	O
novel	O
way,	O
the	O
proposed	O
approach	O
achieves	O
an	O
equal	O
or	O
higher	O
accuracy	O
compared	O
to	O
current	O
methods.	O

Semantic	B-RESEARCH_PROBLEM
Segmentation	E-RESEARCH_PROBLEM
is	O
a	O
crucial	O
component	O
in	O
the	O
perception	O
systems	O
of	O
many	O
applications,	O
such	O
as	O
robotics	O
and	O
autonomous	O
driving	O
that	O
rely	O
on	O
accurate	O
environmental	O
perception	O
and	O
understanding.	O
In	O
literature,	O
several	O
approaches	O
are	O
introduced	O
to	O
attempt	O
LiDAR	O
semantic	O
segmentation	O
task,	O
such	O
as	O
projection-based	O
(range-view	O
or	O
birds-eye-view),	O
and	O
voxel-based	O
approaches.	O
However,	O
they	O
either	O
abandon	O
the	O
valuable	O
3D	O
topology	O
and	O
geometric	O
relations	O
and	O
suffer	O
from	O
information	O
loss	O
introduced	O
in	O
the	O
projection	O
process	O
or	O
are	O
inefficient.	O
Therefore,	O
there	O
is	O
a	O
need	O
for	O
accurate	O
models	O
capable	O
of	O
processing	O
the	O
3D	O
driving-scene	O
point	O
cloud	O
in	O
3D	O
space.	O
In	O
this	O
paper,	O
we	O
propose	O
S3Net,	O
a	O
novel	O
convolutional	O
neural	O
network	O
for	O
LiDAR	O
point	O
cloud	O
semantic	O
segmentation.	O
It	O
adopts	O
an	O
encoder-decoder	O
backbone	O
that	O
consists	O
of	O
Sparse	O
Intra-channel	O
Attention	O
Module	O
(SIntraAM),	O
and	O
Sparse	O
Inter-channel	O
Attention	O
Module	O
(SInterAM)	O
to	O
emphasize	O
the	O
fine	O
details	O
of	O
both	O
within	O
each	O
feature	O
map	O
and	O
among	O
nearby	O
feature	O
maps.	O
To	O
extract	O
the	O
global	O
contexts	O
in	O
deeper	O
layers,	O
we	O
introduce	O
Sparse	O
Residual	O
Tower	O
based	O
upon	O
sparse	O
convolution	O
that	O
suits	O
varying	O
sparsity	O
of	O
LiDAR	O
point	O
cloud.	O
In	O
addition,	O
geo-aware	O
anisotrophic	O
loss	O
is	O
leveraged	O
to	O
emphasize	O
the	O
semantic	O
boundaries	O
and	O
penalize	O
the	O
noise	O
within	O
each	O
predicted	O
regions,	O
leading	O
to	O
a	O
robust	O
prediction.	O
Our	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
method	O
leads	O
to	O
a	O
large	O
improvement	O
(12\%)	O
compared	O
to	O
its	O
baseline	O
counterpart	O
(MinkNet42	O
\cite{choy20194d})	O
on	O
SemanticKITTI	O
\cite{DBLP:conf/iccv/BehleyGMQBSG19}	O
test	O
set	O
and	O
achieves	O
state-of-the-art	O
mIoU	O
accuracy	O
of	O
semantic	O
segmentation	O
approaches.	O

This	O
paper	O
describes	O
the	O
submission	O
to	O
the	O
IWSLT	O
2021	O
Low-Resource	O
Speech	O
Translation	S-RESEARCH_PROBLEM
Shared	O
Task	O
by	O
IMS	O
team.	O
We	O
utilize	O
state-of-the-art	O
models	O
combined	O
with	O
several	O
data	O
augmentation,	O
multi-task	O
and	O
transfer	O
learning	O
approaches	O
for	O
the	O
automatic	O
speech	O
recognition	O
(ASR)	O
and	O
machine	O
translation	O
(MT)	O
steps	O
of	O
our	O
cascaded	O
system.	O
Moreover,	O
we	O
also	O
explore	O
the	O
feasibility	O
of	O
a	O
full	O
end-to-end	O
speech	O
translation	O
(ST)	O
model	O
in	O
the	O
case	O
of	O
very	O
constrained	O
amount	O
of	O
ground	O
truth	O
labeled	O
data.	O
Our	O
best	O
system	O
achieves	O
the	O
best	O
performance	O
among	O
all	O
submitted	O
systems	O
for	O
Congolese	O
Swahili	O
to	O
English	O
and	O
French	O
with	O
BLEU	O
scores	O
7.7	O
and	O
13.7	O
respectively,	O
and	O
the	O
second	O
best	O
result	O
for	O
Coastal	O
Swahili	O
to	O
English	O
with	O
BLEU	O
score	O
14.9.	O

In	O
machine	O
translation	O
it	O
is	O
common	O
phenomenon	O
that	O
machine-readabledictionaries	O
and	O
standard	O
parsing	O
rules	O
are	O
not	O
enough	O
to	O
ensure	O
accuracy	O
inparsing	O
and	O
translating	O
English	O
phrases	O
into	O
Korean	O
language,	O
which	O
is	O
revealedin	O
misleading	O
translation	O
results	O
due	O
to	O
consequent	O
structural	O
and	O
semanticambiguities.	O
This	O
paper	O
aims	O
to	O
suggest	O
a	O
solution	O
to	O
structural	O
and	O
semanticambiguities	O
due	O
to	O
the	O
idiomaticity	O
and	O
non-grammaticalness	O
of	O
phrases	O
commonlyused	O
in	O
English	O
language	O
by	O
applying	O
bilingual	O
phrase	O
database	O
inEnglish-Korean	O
Machine	B-RESEARCH_PROBLEM
Translation	E-RESEARCH_PROBLEM
(EKMT).	O
This	O
paper	O
firstly	O
clarifies	O
whatthe	O
phrase	O
unit	O
in	O
EKMT	O
is	O
based	O
on	O
the	O
definition	O
of	O
the	O
English	O
phrase,secondly	O
clarifies	O
what	O
kind	O
of	O
language	O
unit	O
can	O
be	O
the	O
target	O
of	O
the	O
phrasedatabase	O
for	O
EKMT,	O
thirdly	O
suggests	O
a	O
way	O
to	O
build	O
the	O
phrase	O
database	O
bypresenting	O
the	O
format	O
of	O
the	O
phrase	O
database	O
with	O
examples,	O
and	O
finallydiscusses	O
briefly	O
the	O
method	O
to	O
apply	O
this	O
bilingual	O
phrase	O
database	O
to	O
theEKMT	O
for	O
structural	O
and	O
semantic	O
disambiguation.	O

Fine-Grained	B-RESEARCH_PROBLEM
Visual	I-RESEARCH_PROBLEM
Categorization	E-RESEARCH_PROBLEM
(FGVC)	O
is	O
a	O
challenging	O
topic	O
in	O
computer	O
vision.	O
It	O
is	O
a	O
problem	O
characterized	O
by	O
large	O
intra-class	O
differences	O
and	O
subtle	O
inter-class	O
differences.	O
In	O
this	O
paper,	O
we	O
tackle	O
this	O
problem	O
in	O
a	O
weakly	O
supervised	O
manner,	O
where	O
neural	O
network	O
models	O
are	O
getting	O
fed	O
with	O
additional	O
data	O
using	O
a	O
data	O
augmentation	O
technique	O
through	O
a	O
visual	O
attention	O
mechanism.	O
We	O
perform	O
domain	O
adaptive	O
knowledge	O
transfer	O
via	O
fine-tuning	O
on	O
our	O
base	O
network	O
model.	O
We	O
perform	O
our	O
experiment	O
on	O
six	O
challenging	O
and	O
commonly	O
used	O
FGVC	O
datasets,	O
and	O
we	O
show	O
competitive	O
improvement	O
on	O
accuracies	O
by	O
using	O
attention-aware	O
data	O
augmentation	O
techniques	O
with	O
features	O
derived	O
from	O
deep	O
learning	O
model	O
InceptionV3,	O
pre-trained	O
on	O
large	O
scale	O
datasets.	O
Our	O
method	O
outperforms	O
competitor	O
methods	O
on	O
multiple	O
FGVC	O
datasets	O
and	O
showed	O
competitive	O
results	O
on	O
other	O
datasets.	O
Experimental	O
studies	O
show	O
that	O
transfer	O
learning	O
from	O
large	O
scale	O
datasets	O
can	O
be	O
utilized	O
effectively	O
with	O
visual	O
attention	O
based	O
data	O
augmentation,	O
which	O
can	O
obtain	O
state-of-the-art	O
results	O
on	O
several	O
FGVC	O
datasets.	O
We	O
present	O
a	O
comprehensive	O
analysis	O
of	O
our	O
experiments.	O
Our	O
method	O
achieves	O
state-of-the-art	O
results	O
in	O
multiple	O
fine-grained	O
classification	O
datasets	O
including	O
challenging	O
CUB200-2011	O
bird,	O
Flowers-102,	O
and	O
FGVC-Aircrafts	O
datasets.	O

Although	O
Generative	O
Adversarial	O
Networks	O
have	O
shown	O
remarkable	O
performance	O
in	O
image	O
generation,	O
there	O
are	O
some	O
challenges	O
in	O
image	O
realism	O
and	O
convergence	O
speed.	O
The	O
results	O
of	O
some	O
models	O
display	O
the	O
imbalances	O
of	O
quality	O
within	O
a	O
generated	O
image,	O
in	O
which	O
some	O
defective	O
parts	O
appear	O
compared	O
with	O
other	O
regions.	O
Different	O
from	O
general	O
single	O
global	O
optimization	O
methods,	O
we	O
introduce	O
an	O
adaptive	O
global	O
and	O
local	O
bilevel	B-RESEARCH_PROBLEM
optimization	E-RESEARCH_PROBLEM
model(GL-GAN).	O
The	O
model	O
achieves	O
the	O
generation	O
of	O
high-resolution	O
images	O
in	O
a	O
complementary	O
and	O
promoting	O
way,	O
where	O
global	O
optimization	O
is	O
to	O
optimize	O
the	O
whole	O
images	O
and	O
local	O
is	O
only	O
to	O
optimize	O
the	O
low-quality	O
areas.	O
With	O
a	O
simple	O
network	O
structure,	O
GL-GAN	O
is	O
allowed	O
to	O
effectively	O
avoid	O
the	O
nature	O
of	O
imbalance	O
by	O
local	O
bilevel	B-RESEARCH_PROBLEM
optimization	E-RESEARCH_PROBLEM
,	O
which	O
is	O
accomplished	O
by	O
first	O
locating	O
low-quality	O
areas	O
and	O
then	O
optimizing	O
them.	O
Moreover,	O
by	O
using	O
feature	O
map	O
cues	O
from	O
discriminator	O
output,	O
we	O
propose	O
the	O
adaptive	O
local	O
and	O
global	O
optimization	O
method(Ada-OP)	O
for	O
specific	O
implementation	O
and	O
find	O
that	O
it	O
boosts	O
the	O
convergence	O
speed.	O
Compared	O
with	O
the	O
current	O
GAN	O
methods,	O
our	O
model	O
has	O
shown	O
impressive	O
performance	O
on	O
CelebA,	O
CelebA-HQ	O
and	O
LSUN	O
datasets.	O

Manual	B-RESEARCH_PROBLEM
acquisition	I-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
semantic	I-RESEARCH_PROBLEM
constraints	E-RESEARCH_PROBLEM
in	O
broad	O
domains	O
is	O
very	O
expensive.	O
This	O
paper	O
presents	O
an	O
automatic	O
scheme	O
for	O
collecting	O
statistics	O
on	O
cooccurrence	O
patterns	O
in	O
a	O
large	O
corpus	O
.	O
To	O
a	O
large	O
extent,	O
these	O
statistics	O
reflect	O
semantic	O
constraints	O
and	O
thus	O
are	O
used	O
to	O
disambiguate	O
anaphora	O
references	O
and	O
syntactic	O
ambiguities	O
.	O
The	O
scheme	O
was	O
implemented	O
by	O
gathering	O
statistics	O
on	O
the	O
output	O
of	O
other	O
linguistic	O
tools.	O
An	O
experiment	O
was	O
performed	O
to	O
resolve	O
references	O
of	O
the	O
pronoun	O
"it"	O
in	O
sentences	O
that	O
were	O
randomly	O
selected	O
from	O
the	O
corpus	O
.	O
The	O
results	O
of	O
the	O
experiment	O
show	O
that	O
in	O
most	O
of	O
the	O
cases	O
the	O
cooccurrence	O
statistics	O
indeed	O
reflect	O
the	O
semantic	O
constraints	O
and	O
thus	O
provide	O
a	O
basis	O
for	O
a	O
useful	O
disambiguation	O
tool	O
.	O

The	O
compact	B-RESEARCH_PROBLEM
description	I-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
a	I-RESEARCH_PROBLEM
video	I-RESEARCH_PROBLEM
sequence	E-RESEARCH_PROBLEM
through	O
a	O
single	O
image	O
map	O
and	O
a	O
dominant	O
motion	O
has	O
applications	O
in	O
several	O
domains,	O
including	O
video	B-RESEARCH_PROBLEM
browsing	I-RESEARCH_PROBLEM
and	I-RESEARCH_PROBLEM
retrieval	E-RESEARCH_PROBLEM
,	O
compression	S-RESEARCH_PROBLEM
,	O
mosaicing	S-RESEARCH_PROBLEM
,	O
and	O
visual	B-RESEARCH_PROBLEM
summarization	E-RESEARCH_PROBLEM
.	O
Building	O
such	O
a	O
representation	O
requires	O
the	O
capability	O
to	O
register	O
all	O
the	O
frames	O
with	O
respect	O
to	O
the	O
dominant	O
object	O
in	O
the	O
scene,	O
a	O
task	O
which	O
has	O
been,	O
in	O
the	O
past,	O
addressed	O
through	O
temporally	O
localized	O
motion	O
estimates.	O
In	O
this	O
paper,	O
we	O
show	O
how	O
the	O
lack	O
of	O
temporal	O
consistency	O
associated	O
with	O
such	O
estimates	O
can	O
undermine	O
the	O
validity	O
of	O
the	O
dominant	O
motion	O
assumption,	O
leading	O
to	O
oscillation	O
between	O
different	O
scene	O
interpretations	O
and	O
poor	O
registration.	O
To	O
avoid	O
this	O
oscillation,	O
we	O
augment	O
the	O
motion	O
model	O
with	O
a	O
generic	O
temporal	O
constraint	O
which	O
increases	O
the	O
robustness	O
against	O
competing	O
interpretations,	O
leading	O
to	O
more	O
meaningful	O
content	B-RESEARCH_PROBLEM
summarization	E-RESEARCH_PROBLEM
.	O

This	O
work	O
presents	O
a	O
real-time	O
system	O
for	O
multiple	B-RESEARCH_PROBLEM
object	I-RESEARCH_PROBLEM
tracking	I-RESEARCH_PROBLEM
in	I-RESEARCH_PROBLEM
dynamic	I-RESEARCH_PROBLEM
scenes	E-RESEARCH_PROBLEM
.	O
A	O
unique	O
characteristic	O
of	O
the	O
system	O
is	O
its	O
ability	O
to	O
cope	O
with	O
long-duration	O
and	O
complete	O
occlusion	O
without	O
a	O
prior	O
knowledge	O
about	O
the	O
shape	O
or	O
motion	O
of	O
objects.	O
The	O
system	O
produces	O
good	O
segment	O
and	O
tracking	S-RESEARCH_PROBLEM
results	O
at	O
a	O
frame	O
rate	O
of	O
15-20	O
fps	O
for	O
image	O
size	O
of	O
320x240,	O
as	O
demonstrated	O
by	O
extensive	O
experiments	O
performed	O
using	O
video	O
sequences	O
under	O
different	O
conditions	O
indoor	O
and	O
outdoor	O
with	O
long-duration	O
and	O
complete	O
occlusions	O
in	O
changing	O
background.	O

A	O
recognition	O
scheme	O
that	O
scales	O
efficiently	O
to	O
a	O
large	O
number	O
of	O
objects	O
is	O
presented.	O
The	O
efficiency	O
and	O
quality	O
is	O
exhibited	O
in	O
a	O
live	O
demonstration	O
that	O
recognizes	O
CD-covers	O
from	O
a	O
database	O
of	O
40000	O
images	O
of	O
popular	O
music	O
CD's.	O
The	O
scheme	O
builds	O
upon	O
popular	O
techniques	O
of	O
indexing	O
descriptors	O
extracted	O
from	O
local	O
regions,	O
and	O
is	O
robust	O
to	O
background	O
clutter	O
and	O
occlusion.	O
The	O
local	O
region	O
descriptors	O
are	O
hierarchically	O
quantized	O
in	O
a	O
vocabulary	O
tree.	O
The	O
vocabulary	O
tree	O
allows	O
a	O
larger	O
and	O
more	O
discriminatory	O
vocabulary	O
to	O
be	O
used	O
efficiently,	O
which	O
we	O
show	O
experimentally	O
leads	O
to	O
a	O
dramatic	O
improvement	O
in	O
retrieval	S-RESEARCH_PROBLEM
quality.	O
The	O
most	O
significant	O
property	O
of	O
the	O
scheme	O
is	O
that	O
the	O
tree	O
directly	O
defines	O
the	O
quantization.	O
The	O
quantization	O
and	O
the	O
indexing	O
are	O
therefore	O
fully	O
integrated,	O
essentially	O
being	O
one	O
and	O
the	O
same.	O
The	O
recognition	O
quality	O
is	O
evaluated	O
through	O
retrieval	O
on	O
a	O
database	O
with	O
ground	O
truth,	O
showing	O
the	O
power	O
of	O
the	O
vocabulary	O
tree	O
approach,	O
going	O
as	O
high	O
as	O
1	O
million	O
images.	O

We	O
present	O
a	O
new	O
approach	O
for	O
building	O
an	O
efficient	O
and	O
robust	O
classifier	O
for	O
the	O
two	O
class	B-RESEARCH_PROBLEM
problem	E-RESEARCH_PROBLEM
,	O
that	O
localizes	O
objects	O
that	O
may	O
appear	O
in	O
the	O
image	O
under	O
different	O
orien-tations.	O
In	O
contrast	O
to	O
other	O
works	O
that	O
address	O
this	O
problem	O
using	O
multiple	O
classifiers,	O
each	O
one	O
specialized	O
for	O
a	O
specific	O
orientation,	O
we	O
propose	O
a	O
simple	O
two-step	O
approach	O
with	O
an	O
estimation	O
stage	O
and	O
a	O
classification	S-RESEARCH_PROBLEM
stage.	O
The	O
estimator	O
yields	O
an	O
initial	O
set	O
of	O
potential	O
object	O
poses	O
that	O
are	O
then	O
validated	O
by	O
the	O
classifier.	O
This	O
methodology	O
allows	O
reducing	O
the	O
time	O
complexity	O
of	O
the	O
algorithm	O
while	O
classification	O
results	O
remain	O
high.	O
The	O
classifier	O
we	O
use	O
in	O
both	O
stages	O
is	O
based	O
on	O
a	O
boosted	O
combination	O
of	O
Random	O
Ferns	O
over	O
local	O
histograms	O
of	O
oriented	O
gradients	O
(HOGs),	O
which	O
we	O
compute	O
during	O
a	O
pre-processing	O
step.	O
Both	O
the	O
use	O
of	O
supervised	O
learning	O
and	O
working	O
on	O
the	O
gradient	O
space	O
makes	O
our	O
approach	O
robust	O
while	O
being	O
efficient	O
at	O
run-time.	O
We	O
show	O
these	O
properties	O
by	O
thorough	O
testing	O
on	O
standard	O
databases	O
and	O
on	O
a	O
new	O
database	O
made	O
of	O
motorbikes	O
under	O
planar	O
rotations,	O
and	O
with	O
challenging	O
conditions	O
such	O
as	O
cluttered	O
backgrounds,	O
changing	O
illumination	O
conditions	O
and	O
partial	O
occlusions.	O

We	O
describe	O
an	O
implementation	O
of	O
data-driven	B-RESEARCH_PROBLEM
selection	E-RESEARCH_PROBLEM
of	O
emphatic	O
facial	O
displays	O
for	O
an	O
embodied	B-RESEARCH_PROBLEM
conversational	I-RESEARCH_PROBLEM
agent	E-RESEARCH_PROBLEM
in	O
a	O
dialogue	B-RESEARCH_PROBLEM
system	E-RESEARCH_PROBLEM
.	O
A	O
corpus	O
of	O
sentences	O
in	O
the	O
domain	O
of	O
the	O
target	O
dialogue	O
system	O
was	O
recorded,	O
and	O
the	O
facial	O
displays	O
used	O
by	O
the	O
speaker	O
were	O
annotated.	O
The	O
data	O
from	O
those	O
recordings	O
was	O
used	O
in	O
a	O
range	O
of	O
models	O
for	O
generating	O
facial	O
displays,	O
each	O
model	O
making	O
use	O
of	O
a	O
different	O
amount	O
of	O
context	O
or	O
choosing	O
displays	O
differently	O
within	O
a	O
context	O
.	O
The	O
models	O
were	O
evaluated	O
in	O
two	O
ways:	O
by	O
cross-validation	O
against	O
the	O
corpus	O
,	O
and	O
by	O
asking	O
users	O
to	O
rate	O
the	O
output.	O
The	O
predictions	O
of	O
the	O
cross-validation	O
study	O
differed	O
from	O
the	O
actual	O
user	O
ratings.	O
While	O
the	O
cross-validation	O
gave	O
the	O
highest	O
scores	O
to	O
models	O
making	O
a	O
majority	O
choice	O
within	O
a	O
context,	O
the	O
user	O
study	O
showed	O
a	O
significant	O
preference	O
for	O
models	O
that	O
produced	O
more	O
variation.	O
This	O
preference	O
was	O
especially	O
strong	O
among	O
the	O
female	O
subjects.	O

In	O
this	O
paper	O
we	O
compare	O
two	O
competing	O
approaches	O
to	O
part-of-speech	B-RESEARCH_PROBLEM
tagging	E-RESEARCH_PROBLEM
,	O
statistical	B-RESEARCH_PROBLEM
and	I-RESEARCH_PROBLEM
constraint-based	I-RESEARCH_PROBLEM
disambiguation	E-RESEARCH_PROBLEM
,	O
using	O
French	O
as	O
our	O
test	O
language	O
.	O
We	O
imposed	O
a	O
time	O
limit	O
on	O
our	O
experiment:	O
the	O
amount	O
of	O
time	O
spent	O
on	O
the	O
design	O
of	O
our	O
constraint	O
system	O
was	O
about	O
the	O
same	O
as	O
the	O
time	O
we	O
used	O
to	O
train	O
and	O
test	O
the	O
easy-to-implement	O
statistical	O
model	O
.	O
We	O
describe	O
the	O
two	O
systems	O
and	O
compare	O
the	O
results.	O
The	O
accuracy	O
of	O
the	O
statistical	O
method	O
is	O
reasonably	O
good,	O
comparable	O
to	O
taggers	O
for	O
English	O
.	O
But	O
the	O
constraint-based	O
tagger	O
seems	O
to	O
be	O
superior	O
even	O
with	O
the	O
limited	O
time	O
we	O
allowed	O
ourselves	O
for	O
rule	O
development	O
.	O

Our	O
goal	O
is	O
to	O
learn	O
a	O
Mahalanobis	B-RESEARCH_PROBLEM
distance	E-RESEARCH_PROBLEM
by	O
minimizing	O
a	O
loss	O
defined	O
on	O
the	O
weighted	O
sum	O
of	O
the	O
precision	O
at	O
different	O
ranks.	O
Our	O
core	O
motivation	O
is	O
that	O
minimizing	O
a	O
weighted	O
rank	O
loss	O
is	O
a	O
natural	O
criterion	O
for	O
many	O
problems	O
in	O
computer	B-RESEARCH_PROBLEM
vision	E-RESEARCH_PROBLEM
such	O
as	O
person	B-RESEARCH_PROBLEM
re-identification	E-RESEARCH_PROBLEM
.	O
We	O
propose	O
a	O
novel	O
metric	O
learning	O
formulation	O
called	O
Weighted	O
Approximate	O
Rank	O
Component	O
Analysis	O
(WARCA).	O
We	O
then	O
derive	O
a	O
scalable	O
stochastic	O
gradient	O
descent	O
algorithm	O
for	O
the	O
resulting	O
learning	O
problem.	O
We	O
also	O
derive	O
an	O
efficient	O
non-linear	O
extension	O
of	O
WARCA	O
by	O
using	O
the	O
kernel	O
trick.	O
Kernel	O
space	O
embedding	O
decouples	O
the	O
training	O
and	O
prediction	O
costs	O
from	O
the	O
data	O
dimension	O
and	O
enables	O
us	O
to	O
plug	O
inarbitrary	O
distance	O
measures	O
which	O
are	O
more	O
natural	O
for	O
the	O
features.	O
We	O
also	O
address	O
a	O
more	O
general	O
problem	O
of	O
matrix	O
rank	O
degeneration	O
&	O
non-isolated	O
minima	O
in	O
the	O
low-rank	B-RESEARCH_PROBLEM
matrix	I-RESEARCH_PROBLEM
optimization	E-RESEARCH_PROBLEM
by	O
using	O
new	O
type	O
of	O
regularizer	O
which	O
approximately	O
enforces	O
the	O
or-thonormality	O
of	O
the	O
learned	O
matrix	O
very	O
efficiently.	O
We	O
validate	O
this	O
new	O
method	O
on	O
nine	O
standard	O
person	O
re-identification	O
datasets	O
including	O
two	O
large	O
scale	O
Market-1501	O
and	O
CUHK03	O
datasets	O
and	O
show	O
that	O
we	O
improve	O
upon	O
the	O
current	O
state-of-the-art	O
methods	O
on	O
all	O
of	O
them.	O

In	O
this	O
paper,	O
we	O
use	O
the	O
information	O
redundancy	O
in	O
multilingual	O
input	O
to	O
correct	O
errors	O
in	O
machine	B-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
and	O
thus	O
improve	O
the	O
quality	O
of	O
multilingual	B-RESEARCH_PROBLEM
summaries	E-RESEARCH_PROBLEM
.	O
We	O
consider	O
the	O
case	O
of	O
multi-document	B-RESEARCH_PROBLEM
summarization	E-RESEARCH_PROBLEM
,	O
where	O
the	O
input	O
documents	O
are	O
in	O
Arabic	O
,	O
and	O
the	O
output	O
summary	O
is	O
in	O
English	O
.	O
Typically,	O
information	O
that	O
makes	O
it	O
to	O
a	O
summary	O
appears	O
in	O
many	O
different	O
lexical-syntactic	O
forms	O
in	O
the	O
input	O
documents	O
.	O
Further,	O
the	O
use	O
of	O
multiple	O
machine	O
translation	O
systems	O
provides	O
yet	O
more	O
redundancy	O
,	O
yielding	O
different	O
ways	O
to	O
realize	O
that	O
information	O
in	O
English	O
.	O
We	O
demonstrate	O
how	O
errors	O
in	O
the	O
machine	B-RESEARCH_PROBLEM
translations	E-RESEARCH_PROBLEM
of	O
the	O
input	O
Arabic	O
documents	O
can	O
be	O
corrected	O
by	O
identifying	O
and	O
generating	O
from	O
such	O
redundancy	O
,	O
focusing	O
on	O
noun	O
phrases	O
.	O

This	O
paper	O
presents	O
a	O
word	O
segmentation	O
system	O
in	O
France	O
Telecom	O
R&D	O
Beijing,	O
which	O
uses	O
a	O
unified	O
approach	O
to	O
word	B-RESEARCH_PROBLEM
breaking	E-RESEARCH_PROBLEM
and	O
OOV	B-RESEARCH_PROBLEM
identification	E-RESEARCH_PROBLEM
.	O
The	O
output	O
can	O
be	O
customized	O
to	O
meet	O
different	O
segmentation	O
standards	O
through	O
the	O
application	O
of	O
an	O
ordered	O
list	O
of	O
transformation.	O
The	O
system	O
participated	O
in	O
all	O
the	O
tracks	O
of	O
the	O
segmentation	O
bakeoff	O
--	O
PK-open	O
,	O
PK-closed	O
,	O
AS-open	O
,	O
AS-closed	O
,	O
HK-open	O
,	O
HK-closed	O
,	O
MSR-open	O
and	O
MSR-	O
closed	O
--	O
and	O
achieved	O
the	O
state-of-the-art	O
performance	O
in	O
MSR-open	O
,	O
MSR-close	O
and	O
PK-open	O
tracks.	O
Analysis	O
of	O
the	O
results	O
shows	O
that	O
each	O
component	O
of	O
the	O
system	O
contributed	O
to	O
the	O
scores	O
.	O

In	O
this	O
paper,	O
we	O
propose	O
a	O
novel	O
algorithm	O
to	O
detect/compensate	O
on-line	B-RESEARCH_PROBLEM
interference	I-RESEARCH_PROBLEM
effects	E-RESEARCH_PROBLEM
when	O
integrating	O
Global	B-RESEARCH_PROBLEM
Navigation	I-RESEARCH_PROBLEM
Satellite	I-RESEARCH_PROBLEM
System	I-RESEARCH_PROBLEM
(GNSS)	E-RESEARCH_PROBLEM
and	O
Inertial	B-RESEARCH_PROBLEM
Navigation	I-RESEARCH_PROBLEM
System	I-RESEARCH_PROBLEM
(INS)	E-RESEARCH_PROBLEM
.	O
The	O
GNSS/INS	B-RESEARCH_PROBLEM
coupling	E-RESEARCH_PROBLEM
is	O
usually	O
performed	O
by	O
an	O
Extended	O
Kalman	O
Filter	O
(EKF)	O
which	O
yields	O
an	O
accurate	B-RESEARCH_PROBLEM
and	I-RESEARCH_PROBLEM
robust	I-RESEARCH_PROBLEM
localization	E-RESEARCH_PROBLEM
.	O
However	O
,	O
interference	O
cause	O
the	O
GNSS	O
measurement	O
noise	O
to	O
increase	O
unexpectedly,	O
hence	O
degrade	O
the	O
positioning	O
accuracy.	O
In	O
this	O
context	O
,	O
our	O
contribution	O
is	O
twofold.	O
We	O
first	O
study	O
the	O
impact	O
of	O
the	O
GNSS	O
noise	O
inflation	O
on	O
the	O
covariance	O
of	O
the	O
EKF	O
outputs	O
so	O
as	O
to	O
compute	O
a	O
least	O
square	O
estimate	O
of	O
the	O
potential	O
variance	O
jumps.	O
Then,	O
this	O
estimation	O
is	O
used	O
in	O
a	O
Bayesian	O
test	O
which	O
decides	O
whether	O
interference	O
are	O
corrupting	O
the	O
GNSS	O
signal	O
or	O
not.	O
It	O
allows	O
us	O
to	O
estimate	O
their	O
times	O
of	O
occurrence	O
as	O
well.	O
In	O
this	O
way,	O
the	O
impaired	O
measurements	O
can	O
be	O
discarded	O
while	O
their	O
impact	O
on	O
the	O
navigation	B-RESEARCH_PROBLEM
solution	E-RESEARCH_PROBLEM
can	O
be	O
compensated.	O
The	O
results	O
show	O
the	O
performance	O
of	O
the	O
proposed	O
approach	O
on	O
simulated	O
data.	O

We	O
present	O
a	O
single-image	O
highlight	O
removal	O
method	O
that	O
incorporates	O
illumination-based	O
constraints	O
into	O
image	B-RESEARCH_PROBLEM
in-painting	E-RESEARCH_PROBLEM
.	O
Unlike	O
occluded	O
image	O
regions	O
filled	O
by	O
traditional	O
inpainting	S-RESEARCH_PROBLEM
,	O
highlight	O
pixels	O
contain	O
some	O
useful	O
information	O
for	O
guiding	O
the	O
inpainting	B-RESEARCH_PROBLEM
process	E-RESEARCH_PROBLEM
.	O
Constraints	O
provided	O
by	O
observed	O
pixel	O
colors,	O
highlight	O
color	O
analysis	O
and	O
illumination	O
color	O
uniformity	O
are	O
employed	O
in	O
our	O
method	O
to	O
improve	O
estimation	O
of	O
the	O
underlying	O
diffuse	O
color.	O
The	O
inclusion	O
of	O
these	O
illumination	O
constraints	O
allows	O
for	O
better	O
recovery	O
of	O
shading	O
and	O
textures	O
by	O
inpainting.	O
Experimental	O
results	O
are	O
given	O
to	O
demonstrate	O
the	O
performance	O
of	O
our	O
method.	O

This	O
paper	O
presents	O
an	O
approach	O
to	O
localizing	B-RESEARCH_PROBLEM
functional	I-RESEARCH_PROBLEM
objects	E-RESEARCH_PROBLEM
in	O
surveillance	O
videos	O
without	O
domain	O
knowledge	O
about	O
semantic	O
object	O
classes	O
that	O
may	O
appear	O
in	O
the	O
scene.	O
Functional	O
objects	O
do	O
not	O
have	O
discriminative	O
appearance	O
and	O
shape,	O
but	O
they	O
affect	O
behavior	O
of	O
people	O
in	O
the	O
scene.	O
For	O
example,	O
they	O
"	O
attract	O
"	O
people	O
to	O
approach	O
them	O
for	O
satisfying	O
certain	O
needs	O
(e.g.,	O
vending	O
machines	O
could	O
quench	O
thirst),	O
or	O
"	O
repel	O
"	O
people	O
to	O
avoid	O
them	O
(e.g.,	O
grass	O
lawns).	O
Therefore,	O
functional	O
objects	O
can	O
be	O
viewed	O
as	O
"	O
dark	O
matter	O
"	O
,	O
emanating	O
"	O
dark	O
energy	O
"	O
that	O
affects	O
people's	O
trajectories	O
in	O
the	O
video.	O
To	O
detect	O
"	O
dark	O
matter	O
"	O
and	O
infer	O
their	O
"	O
dark	O
energy	O
"	O
field,	O
we	O
extend	O
the	O
La-grangian	O
mechanics.	O
People	O
are	O
treated	O
as	O
particle-agents	O
with	O
latent	O
intents	O
to	O
approach	O
"	O
dark	O
matter	O
"	O
and	O
thus	O
satisfy	O
their	O
needs,	O
where	O
their	O
motions	O
are	O
subject	O
to	O
a	O
composite	O
"	O
dark	O
energy	O
"	O
field	O
of	O
all	O
functional	O
objects	O
in	O
the	O
scene.	O
We	O
make	O
the	O
assumption	O
that	O
people	O
take	O
globally	O
optimal	O
paths	O
toward	O
the	O
intended	O
"	O
dark	O
matter	O
"	O
while	O
avoiding	O
latent	O
obstacles.	O
A	O
Bayesian	O
framework	O
is	O
used	O
to	O
probabilistically	O
model:	O
people's	O
trajectories	O
and	O
intents,	O
constraint	O
map	O
of	O
the	O
scene,	O
and	O
locations	O
of	O
functional	O
objects.	O
A	O
data-driven	O
Markov	O
Chain	O
Monte	O
Carlo	O
(MCMC)	O
process	O
is	O
used	O
for	O
inference	S-RESEARCH_PROBLEM
.	O
Our	O
evaluation	O
on	O
videos	O
of	O
public	O
squares	O
and	O
courtyards	O
demonstrates	O
our	O
effectiveness	O
in	O
localizing	B-RESEARCH_PROBLEM
functional	I-RESEARCH_PROBLEM
objects	E-RESEARCH_PROBLEM
and	O
predicting	B-RESEARCH_PROBLEM
people's	I-RESEARCH_PROBLEM
trajectories	E-RESEARCH_PROBLEM
in	O
unobserved	O
parts	O
of	O
the	O
video	O
footage.	O

Is	O
it	O
possible	O
to	O
use	O
out-of-domain	O
acoustic	O
training	O
data	O
to	O
improve	O
a	O
speech	O
recognizer's	O
performance	O
on	O
a	O
speciic,	O
independent	O
application?	O
In	O
our	O
experiments,	O
we	O
use	O
Wallstreet	O
Journal	O
(WSJ)	O
data	O
to	O
train	O
a	O
recognizer,	O
which	O
is	O
adapted	O
and	O
evaluated	O
in	O
the	O
Phonebook	O
domain.	O
Apart	O
from	O
their	O
common	O
language	O
(US	O
English),	O
the	O
two	O
corpora	O
diier	O
in	O
many	O
important	O
respects:	O
microphone	O
vs.	O
telephone	O
channel,	O
continuous	O
speech	O
vs.	O
isolated	O
words,	O
mismatch	O
i	O
n	O
s	O
p	O
e	O
a	O
k	O
i	O
n	O
g	O
r	O
a	O
t	O
e.	O
This	O
paper	O
deals	O
with	O
two	O
questions.	O
First,	O
starting	O
from	O
the	O
WSJ-trained	O
recognizer,	O
how	O
much	O
adaptation	O
data	O
(taken	O
from	O
the	O
Phonebook	O
training	O
corpus)	O
is	O
necessary	O
to	O
achieve	O
a	O
reasonable	O
recognition	S-RESEARCH_PROBLEM
performance	O
in	O
spite	O
of	O
the	O
high	O
degree	O
of	O
mismatch?	O
Second,	O
is	O
it	O
possible	O
to	O
improve	O
the	O
recognition	S-RESEARCH_PROBLEM
performance	O
of	O
a	O
Phonebook-trained	O
baseline	O
acoustic	O
model	O
by	O
using	O
additional	O
out-of-domain	O
training	O
data?	O
The	O
paper	O
describes	O
the	O
adaptation	O
and	O
normalization	O
techniques	O
used	O
to	O
bridge	O
the	O
mismatch	O
b	O
e-tween	O
the	O
two	O
corpora.	O

This	O
paper	O
develops	O
a	O
new	O
approach	O
for	O
extremely	O
fast	B-RESEARCH_PROBLEM
detection	E-RESEARCH_PROBLEM
in	O
domains	O
where	O
the	O
distribution	O
of	O
positive	O
and	O
negative	O
examples	O
is	O
highly	O
skewed	O
(e.g.	O
face	B-RESEARCH_PROBLEM
detection	E-RESEARCH_PROBLEM
or	O
database	B-RESEARCH_PROBLEM
retrieval	E-RESEARCH_PROBLEM
).	O
In	O
such	O
domains	O
a	O
cascade	O
of	O
simple	O
classifiers	O
each	O
trained	O
to	O
achieve	O
high	O
detection	O
rates	O
and	O
modest	O
false	O
positive	O
rates	O
can	O
yield	O
a	O
final	O
detector	O
with	O
many	O
desirable	O
features:	O
including	O
high	O
detection	O
rates,	O
very	O
low	O
false	O
positive	O
rates,	O
and	O
fast	O
performance.	O
Achieving	O
extremely	O
high	O
detection	O
rates,	O
rather	O
than	O
low	O
error,	O
is	O
not	O
a	O
task	O
typically	O
addressed	O
by	O
machine	O
learning	O
algorithms.	O
We	O
propose	O
a	O
new	O
variant	O
of	O
AdaBoost	O
as	O
a	O
mechanism	O
for	O
training	O
the	O
simple	O
classifiers	O
used	O
in	O
the	O
cascade.	O
Experimental	O
results	O
in	O
the	O
domain	O
of	O
face	B-RESEARCH_PROBLEM
detection	E-RESEARCH_PROBLEM
show	O
the	O
training	O
algorithm	O
yields	O
significant	O
improvements	O
in	O
performance	O
over	O
conventional	O
AdaBoost.	O
The	O
final	O
face	O
detection	O
system	O
can	O
process	O
15	O
frames	O
per	O
second,	O
achieves	O
over	O
90%	O
detection,	O
and	O
a	O
false	O
positive	O
rate	O
of	O
1	O
in	O
a	O
1,000,000.	O

Previous	O
research	O
has	O
demonstrated	O
the	O
utility	O
of	O
clustering	O
in	O
inducing	B-RESEARCH_PROBLEM
semantic	I-RESEARCH_PROBLEM
verb	I-RESEARCH_PROBLEM
classes	E-RESEARCH_PROBLEM
from	O
undisambiguated	O
corpus	O
data	O
.	O
We	O
describe	O
a	O
new	O
approach	O
which	O
involves	O
clustering	B-RESEARCH_PROBLEM
subcategorization	I-RESEARCH_PROBLEM
frame	I-RESEARCH_PROBLEM
(SCF)	I-RESEARCH_PROBLEM
distributions	E-RESEARCH_PROBLEM
using	O
the	O
Information	O
Bottleneck	O
and	O
nearest	O
neighbour	O
methods.	O
In	O
contrast	O
to	O
previous	O
work,	O
we	O
particularly	O
focus	O
on	O
clustering	B-RESEARCH_PROBLEM
polysemic	I-RESEARCH_PROBLEM
verbs	E-RESEARCH_PROBLEM
.	O
A	O
novel	O
evaluation	O
scheme	O
is	O
proposed	O
which	O
accounts	O
for	O
the	O
effect	O
of	O
polysemy	O
on	O
the	O
clusters	O
,	O
offering	O
us	O
a	O
good	O
insight	O
into	O
the	O
potential	O
and	O
limitations	O
of	O
semantically	B-RESEARCH_PROBLEM
classifying	I-RESEARCH_PROBLEM
undisambiguated	I-RESEARCH_PROBLEM
SCF	I-RESEARCH_PROBLEM
data	E-RESEARCH_PROBLEM
.	O

This	O
paper	O
concerns	O
the	O
discourse	B-RESEARCH_PROBLEM
understanding	I-RESEARCH_PROBLEM
process	E-RESEARCH_PROBLEM
in	O
spoken	O
dialogue	O
systems	O
.	O
This	O
process	O
enables	O
the	O
system	O
to	O
understand	O
user	O
utterances	O
based	O
on	O
the	O
context	O
of	O
a	O
dialogue	O
.	O
Since	O
multiple	O
candidates	O
for	O
the	O
understanding	O
result	O
can	O
be	O
obtained	O
for	O
a	O
user	O
utterance	O
due	O
to	O
the	O
ambiguity	O
of	O
speech	O
understanding	O
,	O
it	O
is	O
not	O
appropriate	O
to	O
decide	O
on	O
a	O
single	O
understanding	O
result	O
after	O
each	O
user	O
utterance	O
.	O
By	O
holding	O
multiple	O
candidates	O
for	O
understanding	O
results	O
and	O
resolving	O
the	O
ambiguity	O
as	O
the	O
dialogue	O
progresses,	O
the	O
discourse	O
understanding	O
accuracy	O
can	O
be	O
improved.	O
This	O
paper	O
proposes	O
a	O
method	O
for	O
resolving	O
this	O
ambiguity	O
based	O
on	O
statistical	O
information	O
obtained	O
from	O
dialogue	O
corpora	O
.	O
Unlike	O
conventional	O
methods	O
that	O
use	O
hand-crafted	O
rules	O
,	O
the	O
proposed	O
method	O
enables	O
easy	O
design	O
of	O
the	O
discourse	B-RESEARCH_PROBLEM
understanding	I-RESEARCH_PROBLEM
process	E-RESEARCH_PROBLEM
.	O
Experiment	O
results	O
have	O
shown	O
that	O
a	O
system	O
that	O
exploits	O
the	O
proposed	O
method	O
performs	O
sufficiently	O
and	O
that	O
holding	O
multiple	O
candidates	O
for	O
understanding	O
results	O
is	O
effective.	O

In	O
this	O
paper	O
we	O
describe	O
a	O
novel	O
data	O
structure	O
for	O
phrase-based	B-RESEARCH_PROBLEM
statistical	I-RESEARCH_PROBLEM
machine	I-RESEARCH_PROBLEM
translation	E-RESEARCH_PROBLEM
which	O
allows	O
for	O
the	O
retrieval	B-RESEARCH_PROBLEM
of	I-RESEARCH_PROBLEM
arbitrarily	I-RESEARCH_PROBLEM
long	I-RESEARCH_PROBLEM
phrases	E-RESEARCH_PROBLEM
while	O
simultaneously	O
using	O
less	O
memory	O
than	O
is	O
required	O
by	O
current	O
decoder	O
implementations.	O
We	O
detail	O
the	O
computational	O
complexity	O
and	O
average	O
retrieval	O
times	O
for	O
looking	O
up	O
phrase	O
translations	O
in	O
our	O
suffix	O
array-based	O
data	O
structure	O
.	O
We	O
show	O
how	O
sampling	O
can	O
be	O
used	O
to	O
reduce	O
the	O
retrieval	O
time	O
by	O
orders	O
of	O
magnitude	O
with	O
no	O
loss	O
in	O
translation	O
quality	O
.	O

Topical	B-RESEARCH_PROBLEM
blog	I-RESEARCH_PROBLEM
post	I-RESEARCH_PROBLEM
retrieval	E-RESEARCH_PROBLEM
is	O
the	O
task	O
of	O
ranking	B-RESEARCH_PROBLEM
blog	I-RESEARCH_PROBLEM
posts	E-RESEARCH_PROBLEM
with	O
respect	O
to	O
their	O
relevance	O
for	O
a	O
given	O
topic	O
.	O
To	O
improve	O
topical	B-RESEARCH_PROBLEM
blog	I-RESEARCH_PROBLEM
post	I-RESEARCH_PROBLEM
retrieval	E-RESEARCH_PROBLEM
we	O
incorporate	O
textual	O
credibility	O
indicators	O
in	O
the	O
retrieval	O
process	O
.	O
We	O
consider	O
two	O
groups	O
of	O
indicators	O
:	O
post	O
level	O
(determined	O
using	O
information	O
about	O
individual	O
blog	O
posts	O
only)	O
and	O
blog	O
level	O
(determined	O
using	O
information	O
from	O
the	O
underlying	O
blogs	O
).	O
We	O
describe	O
how	O
to	O
estimate	O
these	O
indicators	O
and	O
how	O
to	O
integrate	O
them	O
into	O
a	O
retrieval	O
approach	O
based	O
on	O
language	O
models	O
.	O
Experiments	O
on	O
the	O
TREC	O
Blog	O
track	O
test	O
set	O
show	O
that	O
both	O
groups	O
of	O
credibility	O
indicators	O
significantly	O
improve	O
retrieval	O
effectiveness	O
;	O
the	O
best	O
performance	O
is	O
achieved	O
when	O
combining	O
them.	O

The	O
TIPSTER	O
Architecture	O
has	O
been	O
designed	O
to	O
enable	O
a	O
variety	O
of	O
different	O
text	B-RESEARCH_PROBLEM
applications	E-RESEARCH_PROBLEM
to	O
use	O
a	O
set	O
of	O
common	O
text	O
processing	O
modules	O
.	O
Since	O
user	O
interfaces	O
work	O
best	O
when	O
customized	O
for	O
particular	O
applications	O
,	O
it	O
is	O
appropriator	O
that	O
no	O
particular	O
user	O
interface	O
styles	O
or	O
conventions	O
are	O
described	O
in	O
the	O
TIPSTER	O
Architecture	O
specification	O
.	O
However,	O
the	O
Computing	O
Research	O
Laboratory	O
(CRL)	O
has	O
constructed	O
several	O
TIPSTER	B-RESEARCH_PROBLEM
applications	E-RESEARCH_PROBLEM
that	O
use	O
a	O
common	O
set	O
of	O
configurable	O
Graphical	O
User	O
Interface	O
(GUI)	O
functions	O
.	O
These	O
GUIs	O
were	O
constructed	O
using	O
CRL's	O
TIPSTER	O
User	O
Interface	O
Toolkit	O
(TUIT)	O
.	O
TUIT	O
is	O
a	O
software	O
library	O
that	O
can	O
be	O
used	O
to	O
construct	O
multilingual	O
TIPSTER	O
user	O
interfaces	O
for	O
a	O
set	O
of	O
common	O
user	O
tasks.	O
CRL	O
developed	O
TUIT	O
to	O
support	O
their	O
work	O
to	O
integrate	O
TIPSTER	O
modules	O
for	O
the	O
6	O
and	O
12	O
month	O
TIPSTER	O
II	O
demonstrations	O
as	O
well	O
as	O
their	O
Oleada	O
and	O
Temple	O
demonstration	O
projects.	O
This	O
paper	O
briefly	O
describes	O
TUIT	O
and	O
its	O
capabilities.	O
